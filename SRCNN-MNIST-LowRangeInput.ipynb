{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SRCNN (MNIST)\n",
    "![image](https://i.imgur.com/a9dbceh.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data set : 50000, Test data Set : 10000\n"
     ]
    }
   ],
   "source": [
    "import os, sys, time\n",
    "import numpy as np\n",
    "import scipy.ndimage, scipy.misc\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "slim = tf.contrib.slim\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"\n",
    "\n",
    "\n",
    "\n",
    "def unpickle(file):\n",
    "    with open(file, 'rb') as f:\n",
    "        data = pickle.load(f, encoding='latin1')\n",
    "        return data\n",
    "\n",
    "def load_cifar10_data(data_dir):\n",
    "    train_data = None\n",
    "    train_labels = []\n",
    "    \n",
    "    for i in range(1,6):\n",
    "        data_dic = unpickle(data_dir + \"/data_batch_{}\".format(i))\n",
    "        if i==1:\n",
    "            train_data = data_dic['data']\n",
    "        else:\n",
    "            train_data = np.vstack((train_data, data_dic['data']))\n",
    "        train_labels += data_dic['labels']\n",
    "    test_data_dic = unpickle(data_dir + \"/test_batch\")\n",
    "    test_data = test_data_dic['data']\n",
    "    test_labels = test_data_dic['labels']\n",
    "    \n",
    "    train_data = train_data.reshape((len(train_data), 3, 32, 32))\n",
    "    train_data = np.rollaxis(train_data, 1, 4)\n",
    "    train_labels = np.array(train_labels)\n",
    "    \n",
    "    test_data = test_data.reshape((len(test_data), 3, 32, 32))\n",
    "    test_data = np.rollaxis(test_data, 1, 4)\n",
    "    test_labels = np.array(test_labels)\n",
    "    \n",
    "    return train_data, train_labels, test_data, test_labels\n",
    "\n",
    "data_dir = '/ideaHome/Dropbox/SJ/ML/Cifar10/Data/cifar-10-batches-py'\n",
    "trImg, train_labels, teImg, test_labels = load_cifar10_data(data_dir)\n",
    "\n",
    "\n",
    "print(\"Training data set : %3d, Test data Set : %3d\" %(trImg.shape[0], teImg.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=mnist.test.images[0]\n",
    "np.max(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def toLR(image, scale=2.):\n",
    "    if len(image.shape)==4:\n",
    "        num_sample = image.shape[0]\n",
    "        images = np.zeros([image.shape[0], int(image.shape[1]/scale), int(image.shape[2]/scale), image.shape[3]])\n",
    "        for i in range(num_sample):\n",
    "            images[i,:,:,0] = scipy.misc.imresize(image[i,:,:,0], 1/scale,'bicubic')\n",
    "        return images\n",
    "    else:\n",
    "        return scipy.misc.imresize(image, 1/scale, 'bicubic')\n",
    "    \n",
    "\n",
    "def Bicubic(image, scale=2):\n",
    "    if len(image.shape)==4:\n",
    "        bicImg=np.zeros([image.shape[0], image.shape[1]*scale, image.shape[2]*scale, image.shape[3]])\n",
    "        for i in range(image.shape[0]):\n",
    "            bicImg[i,:,:,:] = scipy.ndimage.interpolation.zoom(image[i,:,:,:], [scale, scale, 1], prefilter=False)\n",
    "    else:\n",
    "        bicImg = scipy.ndimage.interpolation.zoom(image, [scale,scale, 1], prefilter=False)\n",
    "    return bicImg\n",
    "\n",
    "def _phase_shift(I, r):\n",
    "    # Helper function with main phase shift operation\n",
    "    bsize, a, b, c = I.get_shape().as_list()\n",
    "    X = tf.reshape(I, (-1, a, b, r, r))\n",
    "    X = tf.transpose(X, (0, 1, 2, 4, 3))  # bsize, a, b, 1, 1\n",
    "    X = tf.split(X, a, 1)  # a, [bsize, b, r, r]\n",
    "    X = tf.concat([tf.squeeze(x) for x in X], axis=2)  # bsize, b, a*r, r\n",
    "    X = tf.split(X, b, 1)  # b, [bsize, a*r, r]\n",
    "    X = tf.concat([tf.squeeze(x) for x in X], axis=2)  # bsize, a*r, b*r\n",
    "    return tf.reshape(X, (-1, a*r, b*r, 1))\n",
    "\n",
    "def PS(X, r, color=False):\n",
    "  # Main OP that you can arbitrarily use in you tensorflow code\n",
    "    if color:\n",
    "        Xc = tf.split(X,3,3) #(3, 3, X)\n",
    "        X = tf.concat([_phase_shift(x, r) for x in Xc], axis=3)\n",
    "    else:\n",
    "        X = _phase_shift(X, r)\n",
    "    return X\n",
    "\n",
    "def squash(s, axis=-1, epsilon=1e-7, name=None):\n",
    "    with tf.name_scope(name, default_name=\"squash\"):\n",
    "        squared_norm = tf.reduce_sum(tf.square(s), axis=axis, keep_dims=True)\n",
    "        safe_norm = tf.sqrt(squared_norm + epsilon)\n",
    "        squash_factor = squared_norm / (1. + squared_norm)\n",
    "        unit_vector = s / safe_norm\n",
    "    return squash_factor * unit_vector\n",
    "\n",
    "def safe_norm(s, axis=-1, epsilon=1e-7, keep_dims=False, name=None):\n",
    "    with tf.name_scope(name, default_name=\"safe_norm\"):\n",
    "        squared_norm = tf.reduce_sum(tf.square(s), axis=axis,\n",
    "                                     keep_dims=keep_dims)\n",
    "        return tf.sqrt(squared_norm + epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SRCNN(object):\n",
    "    def __init__(self, mode):\n",
    "        self.LR_dim = (28,28,1)\n",
    "        self.HR_dim = (28,28,1)\n",
    "        self.batch_size = 32\n",
    "        self.mode = mode\n",
    "\n",
    "        print('The model is generated')\n",
    "        \n",
    "    def model(self, img):\n",
    "        with slim.arg_scope([slim.conv2d], stride=[1,1], activation_fn = tf.nn.relu, padding='SAME',\n",
    "                                                   weights_initializer=tf.contrib.layers.xavier_initializer()):\n",
    "            self.layer1 = slim.conv2d(inputs=img, num_outputs=64, kernel_size=[9,9], scope='layer1')\n",
    "            self.layer2 = slim.conv2d(inputs=self.layer1, num_outputs=32, kernel_size=[1,1], scope='layer2')\n",
    "            self.layer3 = slim.conv2d(inputs=self.layer2, num_outputs=1, kernel_size=[5,5], scope='layer', activation_fn=tf.nn.sigmoid)\n",
    "            out = self.layer3\n",
    "        return out\n",
    "    \n",
    "    def loss(self, SR, HR):\n",
    "        loss = tf.reduce_mean(tf.square(SR - HR))\n",
    "        return loss\n",
    "    \n",
    "    def build(self):\n",
    "        if self.mode == 'bicubic':\n",
    "            self.LRImg = tf.placeholder(tf.float32, [None, 28, 28, 1], 'LRImgBicubic')\n",
    "        elif self.mode == 'pixelshuffle':\n",
    "            self.LRImg = tf.placeholder(tf.float32, [None, 14, 14, 1], 'LRImgPixelShuffle')\n",
    "        else:\n",
    "            print ('undefined mode')\n",
    "        self.HRImg = tf.placeholder(tf.float32, [None, 28, 28, 1], 'HRImg')\n",
    "        self.SRImg = self.model(self.LRImg)\n",
    "        self.LOSS = self.loss(self.SRImg, self.HRImg)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def _phase_shift(I, r):\n",
    "        # Helper function with main phase shift operation\n",
    "        bsize, a, b, c = I.get_shape().as_list()\n",
    "        X = tf.reshape(I, (bsize, a, b, r, r))\n",
    "        X = tf.transpose(X, (0, 1, 2, 4, 3))  # bsize, a, b, 1, 1\n",
    "        X = tf.split(X, a, 1)  # a, [bsize, b, r, r]\n",
    "        X = tf.concat([tf.squeeze(x) for x in X], asix=2)  # bsize, b, a*r, r\n",
    "        X = tf.split(X, b, 1)  # b, [bsize, a*r, r]\n",
    "        X = tf.concat([tf.squeeze(x) for x in X], axis=2)  # bsize, a*r, b*r\n",
    "        return tf.reshape(X, (bsize, a*r, b*r, 1))\n",
    "\n",
    "    def PS(X, r, color=False):\n",
    "      # Main OP that you can arbitrarily use in you tensorflow code\n",
    "        if color:\n",
    "            Xc = tf.split(X,3,3) #(3, 3, X)\n",
    "            X = tf.concat([_phase_shift(x, r) for x in Xc], axis=3)\n",
    "        else:\n",
    "            X = _phase_shift(X, r)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is generated\n",
      "---------\n",
      "Variables: name (type shape) [size]\n",
      "---------\n",
      "layer1/weights:0 (float32_ref 9x9x1x64) [5184, bytes: 20736]\n",
      "layer1/biases:0 (float32_ref 64) [64, bytes: 256]\n",
      "layer2/weights:0 (float32_ref 1x1x64x32) [2048, bytes: 8192]\n",
      "layer2/biases:0 (float32_ref 32) [32, bytes: 128]\n",
      "layer/weights:0 (float32_ref 5x5x32x1) [800, bytes: 3200]\n",
      "layer/biases:0 (float32_ref 1) [1, bytes: 4]\n",
      "Total size of variables: 8129\n",
      "Total bytes of variables: 32516\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8129, 32516)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "model = SRCNN('bicubic')\n",
    "model.build()\n",
    "\n",
    "t_vars = tf.trainable_variables()\n",
    "slim.model_analyzer.analyze_vars(t_vars, print_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = tf.placeholder(tf.float32, shape=[])\n",
    "optm = tf.train.AdamOptimizer(learning_rate=lr).minimize(model.LOSS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config) \n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/SRCNN/MNIST_psnr_21-09\n"
     ]
    }
   ],
   "source": [
    "saver=tf.train.Saver()\n",
    "saver.restore(sess, 'checkpoints/SRCNN/MNIST_psnr_21-09')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/scipy/misc/pilutil.py:482: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if issubdtype(ts, int):\n",
      "/usr/local/lib/python3.5/dist-packages/scipy/misc/pilutil.py:485: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  elif issubdtype(type(size), float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   0, avg_PSNR: 17.146224, time for epoch: 40.19\n",
      "epoch:   1, avg_PSNR: 21.530375, time for epoch: 39.28\n",
      "epoch:   2, avg_PSNR: 23.294265, time for epoch: 39.07\n",
      "epoch:   3, avg_PSNR: 24.194388, time for epoch: 39.58\n",
      "epoch:   4, avg_PSNR: 24.699941, time for epoch: 39.29\n",
      "epoch:   5, avg_PSNR: 25.034243, time for epoch: 39.44\n",
      "epoch:   6, avg_PSNR: 25.273047, time for epoch: 39.32\n",
      "epoch:   7, avg_PSNR: 25.448740, time for epoch: 39.52\n",
      "epoch:   8, avg_PSNR: 25.576479, time for epoch: 39.19\n",
      "epoch:   9, avg_PSNR: 25.707916, time for epoch: 39.27\n",
      "epoch:  10, avg_PSNR: 25.809218, time for epoch: 39.28\n",
      "epoch:  11, avg_PSNR: 25.892648, time for epoch: 39.21\n",
      "epoch:  12, avg_PSNR: 25.975913, time for epoch: 39.86\n",
      "epoch:  13, avg_PSNR: 26.018982, time for epoch: 39.31\n",
      "epoch:  14, avg_PSNR: 26.099161, time for epoch: 39.28\n",
      "epoch:  15, avg_PSNR: 26.143056, time for epoch: 39.30\n",
      "epoch:  16, avg_PSNR: 26.174099, time for epoch: 38.90\n",
      "epoch:  17, avg_PSNR: 26.219216, time for epoch: 39.07\n",
      "epoch:  18, avg_PSNR: 26.254926, time for epoch: 39.20\n",
      "epoch:  19, avg_PSNR: 26.286881, time for epoch: 39.38\n",
      "epoch:  20, avg_PSNR: 26.326400, time for epoch: 38.96\n",
      "epoch:  21, avg_PSNR: 26.345107, time for epoch: 39.22\n",
      "epoch:  22, avg_PSNR: 26.373081, time for epoch: 39.77\n",
      "epoch:  23, avg_PSNR: 26.393604, time for epoch: 39.48\n",
      "epoch:  24, avg_PSNR: 26.418315, time for epoch: 39.55\n",
      "epoch:  25, avg_PSNR: 26.472935, time for epoch: 38.78\n",
      "epoch:  26, avg_PSNR: 26.449514, time for epoch: 39.29\n",
      "epoch:  27, avg_PSNR: 26.483044, time for epoch: 39.27\n",
      "epoch:  28, avg_PSNR: 26.510727, time for epoch: 39.05\n",
      "epoch:  29, avg_PSNR: 26.529474, time for epoch: 39.09\n",
      "epoch:  30, avg_PSNR: 26.547475, time for epoch: 39.33\n",
      "epoch:  31, avg_PSNR: 26.558685, time for epoch: 39.12\n",
      "epoch:  32, avg_PSNR: 26.575338, time for epoch: 39.04\n",
      "epoch:  33, avg_PSNR: 26.595580, time for epoch: 39.32\n",
      "epoch:  34, avg_PSNR: 26.620270, time for epoch: 38.96\n",
      "epoch:  35, avg_PSNR: 26.631201, time for epoch: 40.26\n",
      "epoch:  36, avg_PSNR: 26.635412, time for epoch: 41.49\n",
      "epoch:  37, avg_PSNR: 26.657446, time for epoch: 42.08\n",
      "epoch:  38, avg_PSNR: 26.659330, time for epoch: 41.81\n",
      "epoch:  39, avg_PSNR: 26.682910, time for epoch: 41.75\n",
      "epoch:  40, avg_PSNR: 26.714539, time for epoch: 42.00\n",
      "epoch:  41, avg_PSNR: 26.696849, time for epoch: 42.05\n",
      "epoch:  42, avg_PSNR: 26.723928, time for epoch: 41.69\n",
      "epoch:  43, avg_PSNR: 26.734186, time for epoch: 42.10\n",
      "epoch:  44, avg_PSNR: 26.749130, time for epoch: 42.05\n",
      "epoch:  45, avg_PSNR: 26.745937, time for epoch: 41.84\n",
      "epoch:  46, avg_PSNR: 26.775099, time for epoch: 41.82\n",
      "epoch:  47, avg_PSNR: 26.769930, time for epoch: 41.91\n",
      "epoch:  48, avg_PSNR: 26.796907, time for epoch: 41.89\n",
      "epoch:  49, avg_PSNR: 26.790343, time for epoch: 41.60\n",
      "epoch:  50, avg_PSNR: 26.812207, time for epoch: 39.21\n",
      "epoch:  51, avg_PSNR: 26.819209, time for epoch: 39.18\n",
      "epoch:  52, avg_PSNR: 26.835603, time for epoch: 39.23\n",
      "epoch:  53, avg_PSNR: 26.837609, time for epoch: 41.20\n",
      "epoch:  54, avg_PSNR: 26.845710, time for epoch: 41.36\n",
      "epoch:  55, avg_PSNR: 26.847855, time for epoch: 41.97\n",
      "epoch:  56, avg_PSNR: 26.866689, time for epoch: 39.10\n",
      "epoch:  57, avg_PSNR: 26.863402, time for epoch: 39.64\n",
      "epoch:  58, avg_PSNR: 26.888187, time for epoch: 41.77\n",
      "epoch:  59, avg_PSNR: 26.891279, time for epoch: 41.70\n",
      "epoch:  60, avg_PSNR: 26.908171, time for epoch: 40.90\n",
      "epoch:  61, avg_PSNR: 26.894128, time for epoch: 41.80\n",
      "epoch:  62, avg_PSNR: 26.915108, time for epoch: 40.05\n",
      "epoch:  63, avg_PSNR: 26.918078, time for epoch: 39.35\n",
      "epoch:  64, avg_PSNR: 26.926812, time for epoch: 39.64\n",
      "epoch:  65, avg_PSNR: 26.938746, time for epoch: 39.40\n",
      "epoch:  66, avg_PSNR: 26.933318, time for epoch: 40.33\n",
      "epoch:  67, avg_PSNR: 26.955209, time for epoch: 41.52\n",
      "epoch:  68, avg_PSNR: 26.956442, time for epoch: 40.47\n",
      "epoch:  69, avg_PSNR: 26.961773, time for epoch: 41.63\n",
      "epoch:  70, avg_PSNR: 26.963628, time for epoch: 41.40\n",
      "epoch:  71, avg_PSNR: 26.977614, time for epoch: 39.95\n",
      "epoch:  72, avg_PSNR: 26.987307, time for epoch: 38.91\n",
      "epoch:  73, avg_PSNR: 26.979502, time for epoch: 39.01\n",
      "epoch:  74, avg_PSNR: 26.991118, time for epoch: 40.23\n",
      "epoch:  75, avg_PSNR: 27.000966, time for epoch: 40.61\n",
      "epoch:  76, avg_PSNR: 27.002772, time for epoch: 38.95\n",
      "epoch:  77, avg_PSNR: 27.021695, time for epoch: 39.09\n",
      "epoch:  78, avg_PSNR: 27.011898, time for epoch: 39.33\n",
      "epoch:  79, avg_PSNR: 27.028648, time for epoch: 39.45\n",
      "epoch:  80, avg_PSNR: 27.026012, time for epoch: 39.04\n",
      "epoch:  81, avg_PSNR: 27.032516, time for epoch: 39.07\n",
      "epoch:  82, avg_PSNR: 27.039392, time for epoch: 39.99\n",
      "epoch:  83, avg_PSNR: 27.048736, time for epoch: 41.53\n",
      "epoch:  84, avg_PSNR: 27.049370, time for epoch: 39.01\n",
      "epoch:  85, avg_PSNR: 27.057032, time for epoch: 39.07\n",
      "epoch:  86, avg_PSNR: 27.065322, time for epoch: 39.46\n",
      "epoch:  87, avg_PSNR: 27.072368, time for epoch: 39.38\n",
      "epoch:  88, avg_PSNR: 27.068839, time for epoch: 39.29\n",
      "epoch:  89, avg_PSNR: 27.080962, time for epoch: 39.13\n",
      "epoch:  90, avg_PSNR: 27.070131, time for epoch: 39.18\n",
      "epoch:  91, avg_PSNR: 27.095218, time for epoch: 39.03\n",
      "epoch:  92, avg_PSNR: 27.084631, time for epoch: 39.27\n",
      "epoch:  93, avg_PSNR: 27.093471, time for epoch: 39.36\n",
      "epoch:  94, avg_PSNR: 27.103460, time for epoch: 39.23\n",
      "epoch:  95, avg_PSNR: 27.109864, time for epoch: 39.20\n",
      "epoch:  96, avg_PSNR: 27.107108, time for epoch: 39.35\n",
      "epoch:  97, avg_PSNR: 27.109897, time for epoch: 39.41\n",
      "epoch:  98, avg_PSNR: 27.122736, time for epoch: 39.20\n",
      "epoch:  99, avg_PSNR: 27.124169, time for epoch: 39.15\n",
      "epoch: 100, avg_PSNR: 27.125463, time for epoch: 39.64\n",
      "epoch: 101, avg_PSNR: 27.142928, time for epoch: 39.39\n",
      "epoch: 102, avg_PSNR: 27.122913, time for epoch: 39.38\n",
      "epoch: 103, avg_PSNR: 27.143762, time for epoch: 39.42\n",
      "epoch: 104, avg_PSNR: 27.141778, time for epoch: 39.97\n",
      "epoch: 105, avg_PSNR: 27.158365, time for epoch: 41.53\n",
      "epoch: 106, avg_PSNR: 27.147017, time for epoch: 40.62\n",
      "epoch: 107, avg_PSNR: 27.160591, time for epoch: 41.87\n",
      "epoch: 108, avg_PSNR: 27.160296, time for epoch: 39.21\n",
      "epoch: 109, avg_PSNR: 27.166015, time for epoch: 39.06\n",
      "epoch: 110, avg_PSNR: 27.162771, time for epoch: 39.34\n",
      "epoch: 111, avg_PSNR: 27.168937, time for epoch: 39.43\n",
      "epoch: 112, avg_PSNR: 27.185900, time for epoch: 39.04\n",
      "epoch: 113, avg_PSNR: 27.178873, time for epoch: 39.09\n",
      "epoch: 114, avg_PSNR: 27.188038, time for epoch: 39.41\n",
      "epoch: 115, avg_PSNR: 27.177379, time for epoch: 39.13\n",
      "epoch: 116, avg_PSNR: 27.182889, time for epoch: 39.11\n",
      "epoch: 117, avg_PSNR: 27.215641, time for epoch: 39.31\n",
      "epoch: 118, avg_PSNR: 27.190120, time for epoch: 39.35\n",
      "epoch: 119, avg_PSNR: 27.203370, time for epoch: 39.42\n",
      "epoch: 120, avg_PSNR: 27.208406, time for epoch: 39.41\n",
      "epoch: 121, avg_PSNR: 27.212303, time for epoch: 39.31\n",
      "epoch: 122, avg_PSNR: 27.218343, time for epoch: 39.79\n",
      "epoch: 123, avg_PSNR: 27.212493, time for epoch: 39.21\n",
      "epoch: 124, avg_PSNR: 27.218737, time for epoch: 39.52\n",
      "epoch: 125, avg_PSNR: 27.224073, time for epoch: 39.36\n",
      "epoch: 126, avg_PSNR: 27.218613, time for epoch: 39.34\n",
      "epoch: 127, avg_PSNR: 27.236810, time for epoch: 39.35\n",
      "epoch: 128, avg_PSNR: 27.228420, time for epoch: 39.46\n",
      "epoch: 129, avg_PSNR: 27.247697, time for epoch: 39.19\n",
      "epoch: 130, avg_PSNR: 27.233054, time for epoch: 39.05\n",
      "epoch: 131, avg_PSNR: 27.236764, time for epoch: 39.13\n",
      "epoch: 132, avg_PSNR: 27.243465, time for epoch: 39.24\n",
      "epoch: 133, avg_PSNR: 27.256027, time for epoch: 39.50\n",
      "epoch: 134, avg_PSNR: 27.250169, time for epoch: 39.58\n",
      "epoch: 135, avg_PSNR: 27.254241, time for epoch: 39.20\n",
      "epoch: 136, avg_PSNR: 27.255661, time for epoch: 39.51\n",
      "epoch: 137, avg_PSNR: 27.263169, time for epoch: 39.42\n",
      "epoch: 138, avg_PSNR: 27.267895, time for epoch: 39.43\n",
      "epoch: 139, avg_PSNR: 27.262908, time for epoch: 39.22\n",
      "epoch: 140, avg_PSNR: 27.271802, time for epoch: 39.34\n",
      "epoch: 141, avg_PSNR: 27.277560, time for epoch: 39.10\n",
      "epoch: 142, avg_PSNR: 27.274084, time for epoch: 39.49\n",
      "epoch: 143, avg_PSNR: 27.288659, time for epoch: 39.37\n",
      "epoch: 144, avg_PSNR: 27.280914, time for epoch: 39.38\n",
      "epoch: 145, avg_PSNR: 27.281276, time for epoch: 39.16\n",
      "epoch: 146, avg_PSNR: 27.287757, time for epoch: 39.15\n",
      "epoch: 147, avg_PSNR: 27.288002, time for epoch: 38.90\n",
      "epoch: 148, avg_PSNR: 27.304755, time for epoch: 39.15\n",
      "epoch: 149, avg_PSNR: 27.298232, time for epoch: 39.13\n",
      "epoch: 150, avg_PSNR: 27.302633, time for epoch: 39.25\n",
      "epoch: 151, avg_PSNR: 27.299741, time for epoch: 39.49\n",
      "epoch: 152, avg_PSNR: 27.310613, time for epoch: 39.16\n",
      "epoch: 153, avg_PSNR: 27.305555, time for epoch: 39.03\n",
      "epoch: 154, avg_PSNR: 27.310261, time for epoch: 39.27\n",
      "epoch: 155, avg_PSNR: 27.317493, time for epoch: 39.46\n",
      "epoch: 156, avg_PSNR: 27.323078, time for epoch: 39.34\n",
      "epoch: 157, avg_PSNR: 27.311370, time for epoch: 39.37\n",
      "epoch: 158, avg_PSNR: 27.317775, time for epoch: 39.20\n",
      "epoch: 159, avg_PSNR: 27.332599, time for epoch: 39.00\n",
      "epoch: 160, avg_PSNR: 27.326815, time for epoch: 39.18\n",
      "epoch: 161, avg_PSNR: 27.334248, time for epoch: 39.21\n",
      "epoch: 162, avg_PSNR: 27.330653, time for epoch: 39.00\n",
      "epoch: 163, avg_PSNR: 27.338059, time for epoch: 38.91\n",
      "epoch: 164, avg_PSNR: 27.341809, time for epoch: 39.38\n",
      "epoch: 165, avg_PSNR: 27.338322, time for epoch: 39.22\n",
      "epoch: 166, avg_PSNR: 27.350070, time for epoch: 39.12\n",
      "epoch: 167, avg_PSNR: 27.337301, time for epoch: 38.83\n",
      "epoch: 168, avg_PSNR: 27.353247, time for epoch: 39.26\n",
      "epoch: 169, avg_PSNR: 27.342339, time for epoch: 39.59\n",
      "epoch: 170, avg_PSNR: 27.361779, time for epoch: 39.30\n",
      "epoch: 171, avg_PSNR: 27.360099, time for epoch: 39.32\n",
      "epoch: 172, avg_PSNR: 27.360620, time for epoch: 39.10\n",
      "epoch: 173, avg_PSNR: 27.359337, time for epoch: 39.21\n",
      "epoch: 174, avg_PSNR: 27.360787, time for epoch: 39.14\n",
      "epoch: 175, avg_PSNR: 27.368028, time for epoch: 41.24\n",
      "epoch: 176, avg_PSNR: 27.376764, time for epoch: 41.60\n",
      "epoch: 177, avg_PSNR: 27.367427, time for epoch: 39.90\n",
      "epoch: 178, avg_PSNR: 27.367095, time for epoch: 39.20\n",
      "epoch: 179, avg_PSNR: 27.377137, time for epoch: 41.72\n",
      "epoch: 180, avg_PSNR: 27.383236, time for epoch: 40.17\n",
      "epoch: 181, avg_PSNR: 27.391550, time for epoch: 39.22\n",
      "epoch: 182, avg_PSNR: 27.371123, time for epoch: 39.51\n",
      "epoch: 183, avg_PSNR: 27.387537, time for epoch: 39.49\n",
      "epoch: 184, avg_PSNR: 27.387623, time for epoch: 39.26\n",
      "epoch: 185, avg_PSNR: 27.388979, time for epoch: 39.16\n",
      "epoch: 186, avg_PSNR: 27.398747, time for epoch: 40.55\n",
      "epoch: 187, avg_PSNR: 27.394536, time for epoch: 40.93\n",
      "epoch: 188, avg_PSNR: 27.398606, time for epoch: 40.88\n",
      "epoch: 189, avg_PSNR: 27.393342, time for epoch: 41.81\n",
      "epoch: 190, avg_PSNR: 27.402765, time for epoch: 41.67\n",
      "epoch: 191, avg_PSNR: 27.405276, time for epoch: 41.23\n",
      "epoch: 192, avg_PSNR: 27.412667, time for epoch: 41.32\n",
      "epoch: 193, avg_PSNR: 27.402982, time for epoch: 41.16\n",
      "epoch: 194, avg_PSNR: 27.421061, time for epoch: 41.66\n",
      "epoch: 195, avg_PSNR: 27.408701, time for epoch: 41.74\n",
      "epoch: 196, avg_PSNR: 27.416707, time for epoch: 40.31\n",
      "epoch: 197, avg_PSNR: 27.412951, time for epoch: 39.47\n",
      "epoch: 198, avg_PSNR: 27.420433, time for epoch: 39.47\n",
      "epoch: 199, avg_PSNR: 27.427309, time for epoch: 39.14\n",
      "epoch: 200, avg_PSNR: 27.426992, time for epoch: 38.98\n",
      "epoch: 201, avg_PSNR: 27.423820, time for epoch: 39.29\n",
      "epoch: 202, avg_PSNR: 27.435298, time for epoch: 41.15\n",
      "epoch: 203, avg_PSNR: 27.431766, time for epoch: 41.22\n",
      "epoch: 204, avg_PSNR: 27.425793, time for epoch: 41.20\n",
      "epoch: 205, avg_PSNR: 27.434974, time for epoch: 39.17\n",
      "epoch: 206, avg_PSNR: 27.441730, time for epoch: 39.07\n",
      "epoch: 207, avg_PSNR: 27.436424, time for epoch: 39.07\n",
      "epoch: 208, avg_PSNR: 27.448692, time for epoch: 38.92\n",
      "epoch: 209, avg_PSNR: 27.432570, time for epoch: 39.55\n",
      "epoch: 210, avg_PSNR: 27.454271, time for epoch: 39.69\n",
      "epoch: 211, avg_PSNR: 27.443289, time for epoch: 41.40\n",
      "epoch: 212, avg_PSNR: 27.438352, time for epoch: 41.75\n",
      "epoch: 213, avg_PSNR: 27.462975, time for epoch: 41.78\n",
      "epoch: 214, avg_PSNR: 27.456865, time for epoch: 39.11\n",
      "epoch: 215, avg_PSNR: 27.466727, time for epoch: 41.20\n",
      "epoch: 216, avg_PSNR: 27.452553, time for epoch: 41.36\n",
      "epoch: 217, avg_PSNR: 27.459367, time for epoch: 41.42\n",
      "epoch: 218, avg_PSNR: 27.467942, time for epoch: 39.37\n",
      "epoch: 219, avg_PSNR: 27.456871, time for epoch: 39.26\n",
      "epoch: 220, avg_PSNR: 27.467908, time for epoch: 39.42\n",
      "epoch: 221, avg_PSNR: 27.459066, time for epoch: 39.05\n",
      "epoch: 222, avg_PSNR: 27.474651, time for epoch: 39.41\n",
      "epoch: 223, avg_PSNR: 27.468642, time for epoch: 39.28\n",
      "epoch: 224, avg_PSNR: 27.469151, time for epoch: 39.27\n",
      "epoch: 225, avg_PSNR: 27.479090, time for epoch: 39.58\n",
      "epoch: 226, avg_PSNR: 27.476419, time for epoch: 39.03\n",
      "epoch: 227, avg_PSNR: 27.461576, time for epoch: 39.72\n",
      "epoch: 228, avg_PSNR: 27.487499, time for epoch: 41.97\n",
      "epoch: 229, avg_PSNR: 27.473589, time for epoch: 41.84\n",
      "epoch: 230, avg_PSNR: 27.485005, time for epoch: 39.73\n",
      "epoch: 231, avg_PSNR: 27.488881, time for epoch: 39.79\n",
      "epoch: 232, avg_PSNR: 27.488462, time for epoch: 41.53\n",
      "epoch: 233, avg_PSNR: 27.482655, time for epoch: 40.24\n",
      "epoch: 234, avg_PSNR: 27.492325, time for epoch: 41.78\n",
      "epoch: 235, avg_PSNR: 27.492776, time for epoch: 40.36\n",
      "epoch: 236, avg_PSNR: 27.491219, time for epoch: 41.85\n",
      "epoch: 237, avg_PSNR: 27.493086, time for epoch: 41.86\n",
      "epoch: 238, avg_PSNR: 27.494145, time for epoch: 41.23\n",
      "epoch: 239, avg_PSNR: 27.503171, time for epoch: 41.89\n",
      "epoch: 240, avg_PSNR: 27.493038, time for epoch: 40.38\n",
      "epoch: 241, avg_PSNR: 27.505277, time for epoch: 42.00\n",
      "epoch: 242, avg_PSNR: 27.507651, time for epoch: 42.02\n",
      "epoch: 243, avg_PSNR: 27.506402, time for epoch: 42.11\n",
      "epoch: 244, avg_PSNR: 27.499976, time for epoch: 41.65\n",
      "epoch: 245, avg_PSNR: 27.515949, time for epoch: 39.28\n",
      "epoch: 246, avg_PSNR: 27.499988, time for epoch: 39.43\n",
      "epoch: 247, avg_PSNR: 27.517279, time for epoch: 39.29\n",
      "epoch: 248, avg_PSNR: 27.509741, time for epoch: 39.21\n",
      "epoch: 249, avg_PSNR: 27.513934, time for epoch: 39.16\n",
      "epoch: 250, avg_PSNR: 27.513468, time for epoch: 38.95\n",
      "epoch: 251, avg_PSNR: 27.512284, time for epoch: 39.61\n",
      "epoch: 252, avg_PSNR: 27.526632, time for epoch: 42.99\n",
      "epoch: 253, avg_PSNR: 27.517927, time for epoch: 41.54\n",
      "epoch: 254, avg_PSNR: 27.509897, time for epoch: 43.33\n",
      "epoch: 255, avg_PSNR: 27.522931, time for epoch: 40.46\n",
      "epoch: 256, avg_PSNR: 27.530011, time for epoch: 39.50\n",
      "epoch: 257, avg_PSNR: 27.519403, time for epoch: 39.56\n",
      "epoch: 258, avg_PSNR: 27.522832, time for epoch: 39.53\n",
      "epoch: 259, avg_PSNR: 27.537176, time for epoch: 39.30\n",
      "epoch: 260, avg_PSNR: 27.533287, time for epoch: 39.48\n",
      "epoch: 261, avg_PSNR: 27.537141, time for epoch: 39.21\n",
      "epoch: 262, avg_PSNR: 27.532537, time for epoch: 39.52\n",
      "epoch: 263, avg_PSNR: 27.530430, time for epoch: 39.57\n",
      "epoch: 264, avg_PSNR: 27.540544, time for epoch: 39.62\n",
      "epoch: 265, avg_PSNR: 27.544503, time for epoch: 39.86\n",
      "epoch: 266, avg_PSNR: 27.536407, time for epoch: 39.74\n",
      "epoch: 267, avg_PSNR: 27.542011, time for epoch: 39.57\n",
      "epoch: 268, avg_PSNR: 27.550407, time for epoch: 39.41\n",
      "epoch: 269, avg_PSNR: 27.531828, time for epoch: 39.53\n",
      "epoch: 270, avg_PSNR: 27.548669, time for epoch: 39.86\n",
      "epoch: 271, avg_PSNR: 27.545906, time for epoch: 39.42\n",
      "epoch: 272, avg_PSNR: 27.543717, time for epoch: 39.42\n",
      "epoch: 273, avg_PSNR: 27.556260, time for epoch: 39.48\n",
      "epoch: 274, avg_PSNR: 27.543313, time for epoch: 39.83\n",
      "epoch: 275, avg_PSNR: 27.555979, time for epoch: 39.77\n",
      "epoch: 276, avg_PSNR: 27.554837, time for epoch: 39.46\n",
      "epoch: 277, avg_PSNR: 27.550967, time for epoch: 39.75\n",
      "epoch: 278, avg_PSNR: 27.564759, time for epoch: 39.57\n",
      "epoch: 279, avg_PSNR: 27.551736, time for epoch: 39.50\n",
      "epoch: 280, avg_PSNR: 27.557764, time for epoch: 39.58\n",
      "epoch: 281, avg_PSNR: 27.563266, time for epoch: 39.87\n",
      "epoch: 282, avg_PSNR: 27.560952, time for epoch: 39.44\n",
      "epoch: 283, avg_PSNR: 27.566162, time for epoch: 39.51\n",
      "epoch: 284, avg_PSNR: 27.561547, time for epoch: 39.87\n",
      "epoch: 285, avg_PSNR: 27.579413, time for epoch: 39.46\n",
      "epoch: 286, avg_PSNR: 27.551252, time for epoch: 39.29\n",
      "epoch: 287, avg_PSNR: 27.574307, time for epoch: 39.72\n",
      "epoch: 288, avg_PSNR: 27.576803, time for epoch: 39.79\n",
      "epoch: 289, avg_PSNR: 27.563098, time for epoch: 39.86\n",
      "epoch: 290, avg_PSNR: 27.582189, time for epoch: 39.43\n",
      "epoch: 291, avg_PSNR: 27.574025, time for epoch: 39.59\n",
      "epoch: 292, avg_PSNR: 27.578370, time for epoch: 39.56\n",
      "epoch: 293, avg_PSNR: 27.576147, time for epoch: 39.37\n",
      "epoch: 294, avg_PSNR: 27.580593, time for epoch: 39.17\n",
      "epoch: 295, avg_PSNR: 27.578227, time for epoch: 39.60\n",
      "epoch: 296, avg_PSNR: 27.581115, time for epoch: 39.38\n",
      "epoch: 297, avg_PSNR: 27.583062, time for epoch: 39.58\n",
      "epoch: 298, avg_PSNR: 27.589157, time for epoch: 39.47\n",
      "epoch: 299, avg_PSNR: 27.574218, time for epoch: 39.18\n",
      "epoch: 300, avg_PSNR: 27.595121, time for epoch: 39.45\n",
      "epoch: 301, avg_PSNR: 27.584730, time for epoch: 39.14\n",
      "epoch: 302, avg_PSNR: 27.585272, time for epoch: 39.51\n",
      "epoch: 303, avg_PSNR: 27.588670, time for epoch: 39.44\n",
      "epoch: 304, avg_PSNR: 27.598119, time for epoch: 39.29\n",
      "epoch: 305, avg_PSNR: 27.595309, time for epoch: 39.20\n",
      "epoch: 306, avg_PSNR: 27.591796, time for epoch: 39.74\n",
      "epoch: 307, avg_PSNR: 27.594530, time for epoch: 39.46\n",
      "epoch: 308, avg_PSNR: 27.603330, time for epoch: 39.56\n",
      "epoch: 309, avg_PSNR: 27.597444, time for epoch: 39.49\n",
      "epoch: 310, avg_PSNR: 27.602486, time for epoch: 39.90\n",
      "epoch: 311, avg_PSNR: 27.601733, time for epoch: 39.54\n",
      "epoch: 312, avg_PSNR: 27.615866, time for epoch: 39.44\n",
      "epoch: 313, avg_PSNR: 27.598138, time for epoch: 39.54\n",
      "epoch: 314, avg_PSNR: 27.609142, time for epoch: 39.59\n",
      "epoch: 315, avg_PSNR: 27.600852, time for epoch: 39.28\n",
      "epoch: 316, avg_PSNR: 27.614453, time for epoch: 39.40\n",
      "epoch: 317, avg_PSNR: 27.602321, time for epoch: 39.66\n",
      "epoch: 318, avg_PSNR: 27.609089, time for epoch: 39.54\n",
      "epoch: 319, avg_PSNR: 27.613023, time for epoch: 39.70\n",
      "epoch: 320, avg_PSNR: 27.617396, time for epoch: 39.40\n",
      "epoch: 321, avg_PSNR: 27.628162, time for epoch: 39.55\n",
      "epoch: 322, avg_PSNR: 27.605499, time for epoch: 39.54\n",
      "epoch: 323, avg_PSNR: 27.622240, time for epoch: 39.50\n",
      "epoch: 324, avg_PSNR: 27.615801, time for epoch: 39.39\n",
      "epoch: 325, avg_PSNR: 27.620191, time for epoch: 39.59\n",
      "epoch: 326, avg_PSNR: 27.621332, time for epoch: 39.49\n",
      "epoch: 327, avg_PSNR: 27.625894, time for epoch: 39.59\n",
      "epoch: 328, avg_PSNR: 27.616171, time for epoch: 39.49\n",
      "epoch: 329, avg_PSNR: 27.634182, time for epoch: 39.51\n",
      "epoch: 330, avg_PSNR: 27.628089, time for epoch: 39.49\n",
      "epoch: 331, avg_PSNR: 27.608552, time for epoch: 39.36\n",
      "epoch: 332, avg_PSNR: 27.644896, time for epoch: 39.49\n",
      "epoch: 333, avg_PSNR: 27.622342, time for epoch: 39.63\n",
      "epoch: 334, avg_PSNR: 27.626511, time for epoch: 39.49\n",
      "epoch: 335, avg_PSNR: 27.641989, time for epoch: 39.54\n",
      "epoch: 336, avg_PSNR: 27.634560, time for epoch: 39.38\n",
      "epoch: 337, avg_PSNR: 27.634183, time for epoch: 39.52\n",
      "epoch: 338, avg_PSNR: 27.636306, time for epoch: 39.30\n",
      "epoch: 339, avg_PSNR: 27.650137, time for epoch: 39.65\n",
      "epoch: 340, avg_PSNR: 27.627675, time for epoch: 39.29\n",
      "epoch: 341, avg_PSNR: 27.638700, time for epoch: 39.72\n",
      "epoch: 342, avg_PSNR: 27.644079, time for epoch: 39.65\n",
      "epoch: 343, avg_PSNR: 27.636844, time for epoch: 39.90\n",
      "epoch: 344, avg_PSNR: 27.664003, time for epoch: 39.19\n",
      "epoch: 345, avg_PSNR: 27.630030, time for epoch: 39.19\n",
      "epoch: 346, avg_PSNR: 27.643603, time for epoch: 39.50\n",
      "epoch: 347, avg_PSNR: 27.655712, time for epoch: 39.22\n",
      "epoch: 348, avg_PSNR: 27.639303, time for epoch: 39.73\n",
      "epoch: 349, avg_PSNR: 27.655157, time for epoch: 39.47\n",
      "epoch: 350, avg_PSNR: 27.651664, time for epoch: 39.49\n",
      "epoch: 351, avg_PSNR: 27.649061, time for epoch: 39.25\n",
      "epoch: 352, avg_PSNR: 27.658449, time for epoch: 39.71\n",
      "epoch: 353, avg_PSNR: 27.649533, time for epoch: 39.71\n",
      "epoch: 354, avg_PSNR: 27.674869, time for epoch: 39.86\n",
      "epoch: 355, avg_PSNR: 27.644562, time for epoch: 39.72\n",
      "epoch: 356, avg_PSNR: 27.661116, time for epoch: 39.38\n",
      "epoch: 357, avg_PSNR: 27.653062, time for epoch: 39.40\n",
      "epoch: 358, avg_PSNR: 27.663997, time for epoch: 39.64\n",
      "epoch: 359, avg_PSNR: 27.657973, time for epoch: 39.63\n",
      "epoch: 360, avg_PSNR: 27.658604, time for epoch: 39.78\n",
      "epoch: 361, avg_PSNR: 27.664499, time for epoch: 39.48\n",
      "epoch: 362, avg_PSNR: 27.667990, time for epoch: 39.41\n",
      "epoch: 363, avg_PSNR: 27.664899, time for epoch: 39.27\n",
      "epoch: 364, avg_PSNR: 27.676472, time for epoch: 39.40\n",
      "epoch: 365, avg_PSNR: 27.656112, time for epoch: 39.83\n",
      "epoch: 366, avg_PSNR: 27.679351, time for epoch: 39.35\n",
      "epoch: 367, avg_PSNR: 27.670697, time for epoch: 39.48\n",
      "epoch: 368, avg_PSNR: 27.663457, time for epoch: 39.57\n",
      "epoch: 369, avg_PSNR: 27.677334, time for epoch: 39.68\n",
      "epoch: 370, avg_PSNR: 27.668836, time for epoch: 39.23\n",
      "epoch: 371, avg_PSNR: 27.683771, time for epoch: 39.34\n",
      "epoch: 372, avg_PSNR: 27.666562, time for epoch: 39.52\n",
      "epoch: 373, avg_PSNR: 27.682704, time for epoch: 39.59\n",
      "epoch: 374, avg_PSNR: 27.678996, time for epoch: 39.75\n",
      "epoch: 375, avg_PSNR: 27.676304, time for epoch: 39.18\n",
      "epoch: 376, avg_PSNR: 27.690573, time for epoch: 39.55\n",
      "epoch: 377, avg_PSNR: 27.670263, time for epoch: 39.50\n",
      "epoch: 378, avg_PSNR: 27.688442, time for epoch: 39.31\n",
      "epoch: 379, avg_PSNR: 27.687373, time for epoch: 39.76\n",
      "epoch: 380, avg_PSNR: 27.684319, time for epoch: 39.41\n",
      "epoch: 381, avg_PSNR: 27.687361, time for epoch: 39.54\n",
      "epoch: 382, avg_PSNR: 27.689806, time for epoch: 39.57\n",
      "epoch: 383, avg_PSNR: 27.678507, time for epoch: 39.65\n",
      "epoch: 384, avg_PSNR: 27.693144, time for epoch: 39.49\n",
      "epoch: 385, avg_PSNR: 27.690228, time for epoch: 39.52\n",
      "epoch: 386, avg_PSNR: 27.693647, time for epoch: 39.80\n",
      "epoch: 387, avg_PSNR: 27.685734, time for epoch: 39.57\n",
      "epoch: 388, avg_PSNR: 27.697777, time for epoch: 39.58\n",
      "epoch: 389, avg_PSNR: 27.696607, time for epoch: 39.34\n",
      "epoch: 390, avg_PSNR: 27.691538, time for epoch: 39.45\n",
      "epoch: 391, avg_PSNR: 27.700551, time for epoch: 40.00\n",
      "epoch: 392, avg_PSNR: 27.697479, time for epoch: 39.53\n",
      "epoch: 393, avg_PSNR: 27.703578, time for epoch: 39.62\n",
      "epoch: 394, avg_PSNR: 27.702954, time for epoch: 39.58\n",
      "epoch: 395, avg_PSNR: 27.694417, time for epoch: 39.54\n",
      "epoch: 396, avg_PSNR: 27.709060, time for epoch: 39.90\n",
      "epoch: 397, avg_PSNR: 27.702706, time for epoch: 39.82\n",
      "epoch: 398, avg_PSNR: 27.706158, time for epoch: 39.39\n",
      "epoch: 399, avg_PSNR: 27.700923, time for epoch: 39.93\n",
      "epoch: 400, avg_PSNR: 27.703991, time for epoch: 39.49\n",
      "epoch: 401, avg_PSNR: 27.710890, time for epoch: 39.54\n",
      "epoch: 402, avg_PSNR: 27.711891, time for epoch: 39.92\n",
      "epoch: 403, avg_PSNR: 27.705001, time for epoch: 39.99\n",
      "epoch: 404, avg_PSNR: 27.705989, time for epoch: 39.79\n",
      "epoch: 405, avg_PSNR: 27.727757, time for epoch: 39.49\n",
      "epoch: 406, avg_PSNR: 27.697369, time for epoch: 39.47\n",
      "epoch: 407, avg_PSNR: 27.725104, time for epoch: 39.45\n",
      "epoch: 408, avg_PSNR: 27.717657, time for epoch: 39.76\n",
      "epoch: 409, avg_PSNR: 27.718720, time for epoch: 39.98\n",
      "epoch: 410, avg_PSNR: 27.712224, time for epoch: 39.76\n",
      "epoch: 411, avg_PSNR: 27.722317, time for epoch: 39.64\n",
      "epoch: 412, avg_PSNR: 27.719481, time for epoch: 39.58\n",
      "epoch: 413, avg_PSNR: 27.722479, time for epoch: 39.48\n",
      "epoch: 414, avg_PSNR: 27.718453, time for epoch: 39.22\n",
      "epoch: 415, avg_PSNR: 27.730933, time for epoch: 39.52\n",
      "epoch: 416, avg_PSNR: 27.717943, time for epoch: 39.67\n",
      "epoch: 417, avg_PSNR: 27.724397, time for epoch: 39.48\n",
      "epoch: 418, avg_PSNR: 27.707038, time for epoch: 39.88\n",
      "epoch: 419, avg_PSNR: 27.744337, time for epoch: 39.89\n",
      "epoch: 420, avg_PSNR: 27.740266, time for epoch: 39.54\n",
      "epoch: 421, avg_PSNR: 27.715246, time for epoch: 39.52\n",
      "epoch: 422, avg_PSNR: 27.725778, time for epoch: 39.63\n",
      "epoch: 423, avg_PSNR: 27.738302, time for epoch: 39.59\n",
      "epoch: 424, avg_PSNR: 27.732918, time for epoch: 39.39\n",
      "epoch: 425, avg_PSNR: 27.731220, time for epoch: 39.70\n",
      "epoch: 426, avg_PSNR: 27.734902, time for epoch: 39.32\n",
      "epoch: 427, avg_PSNR: 27.733334, time for epoch: 39.64\n",
      "epoch: 428, avg_PSNR: 27.739176, time for epoch: 39.71\n",
      "epoch: 429, avg_PSNR: 27.735236, time for epoch: 39.62\n",
      "epoch: 430, avg_PSNR: 27.741456, time for epoch: 39.46\n",
      "epoch: 431, avg_PSNR: 27.746727, time for epoch: 39.45\n",
      "epoch: 432, avg_PSNR: 27.730148, time for epoch: 39.34\n",
      "epoch: 433, avg_PSNR: 27.741743, time for epoch: 39.75\n",
      "epoch: 434, avg_PSNR: 27.744620, time for epoch: 39.43\n",
      "epoch: 435, avg_PSNR: 27.739978, time for epoch: 39.36\n",
      "epoch: 436, avg_PSNR: 27.739902, time for epoch: 40.16\n",
      "epoch: 437, avg_PSNR: 27.753406, time for epoch: 39.28\n",
      "epoch: 438, avg_PSNR: 27.747449, time for epoch: 39.98\n",
      "epoch: 439, avg_PSNR: 27.741890, time for epoch: 39.73\n",
      "epoch: 440, avg_PSNR: 27.754485, time for epoch: 39.55\n",
      "epoch: 441, avg_PSNR: 27.747411, time for epoch: 39.69\n",
      "epoch: 442, avg_PSNR: 27.750660, time for epoch: 39.58\n",
      "epoch: 443, avg_PSNR: 27.753167, time for epoch: 39.41\n",
      "epoch: 444, avg_PSNR: 27.745891, time for epoch: 39.52\n",
      "epoch: 445, avg_PSNR: 27.752572, time for epoch: 39.74\n",
      "epoch: 446, avg_PSNR: 27.755540, time for epoch: 39.58\n",
      "epoch: 447, avg_PSNR: 27.751685, time for epoch: 39.62\n",
      "epoch: 448, avg_PSNR: 27.756834, time for epoch: 39.40\n",
      "epoch: 449, avg_PSNR: 27.754627, time for epoch: 39.54\n",
      "epoch: 450, avg_PSNR: 27.773721, time for epoch: 39.45\n",
      "epoch: 451, avg_PSNR: 27.747265, time for epoch: 39.78\n",
      "epoch: 452, avg_PSNR: 27.759769, time for epoch: 39.35\n",
      "epoch: 453, avg_PSNR: 27.752968, time for epoch: 39.70\n",
      "epoch: 454, avg_PSNR: 27.767195, time for epoch: 39.19\n",
      "epoch: 455, avg_PSNR: 27.755991, time for epoch: 39.58\n",
      "epoch: 456, avg_PSNR: 27.763427, time for epoch: 39.68\n",
      "epoch: 457, avg_PSNR: 27.764277, time for epoch: 39.33\n",
      "epoch: 458, avg_PSNR: 27.763242, time for epoch: 39.58\n",
      "epoch: 459, avg_PSNR: 27.770256, time for epoch: 39.35\n",
      "epoch: 460, avg_PSNR: 27.761870, time for epoch: 39.61\n",
      "epoch: 461, avg_PSNR: 27.776845, time for epoch: 39.41\n",
      "epoch: 462, avg_PSNR: 27.766344, time for epoch: 39.74\n",
      "epoch: 463, avg_PSNR: 27.767820, time for epoch: 39.43\n",
      "epoch: 464, avg_PSNR: 27.769962, time for epoch: 39.56\n",
      "epoch: 465, avg_PSNR: 27.768434, time for epoch: 39.64\n",
      "epoch: 466, avg_PSNR: 27.771157, time for epoch: 39.83\n",
      "epoch: 467, avg_PSNR: 27.774015, time for epoch: 39.72\n",
      "epoch: 468, avg_PSNR: 27.776035, time for epoch: 39.59\n",
      "epoch: 469, avg_PSNR: 27.777979, time for epoch: 39.59\n",
      "epoch: 470, avg_PSNR: 27.771887, time for epoch: 39.56\n",
      "epoch: 471, avg_PSNR: 27.772089, time for epoch: 39.59\n",
      "epoch: 472, avg_PSNR: 27.786573, time for epoch: 39.33\n",
      "epoch: 473, avg_PSNR: 27.775828, time for epoch: 39.46\n",
      "epoch: 474, avg_PSNR: 27.780501, time for epoch: 39.70\n",
      "epoch: 475, avg_PSNR: 27.779775, time for epoch: 39.63\n",
      "epoch: 476, avg_PSNR: 27.777406, time for epoch: 39.48\n",
      "epoch: 477, avg_PSNR: 27.791179, time for epoch: 39.12\n",
      "epoch: 478, avg_PSNR: 27.774206, time for epoch: 39.12\n",
      "epoch: 479, avg_PSNR: 27.782858, time for epoch: 39.21\n",
      "epoch: 480, avg_PSNR: 27.786029, time for epoch: 39.51\n",
      "epoch: 481, avg_PSNR: 27.777470, time for epoch: 39.59\n",
      "epoch: 482, avg_PSNR: 27.790259, time for epoch: 39.51\n",
      "epoch: 483, avg_PSNR: 27.786729, time for epoch: 39.69\n",
      "epoch: 484, avg_PSNR: 27.791043, time for epoch: 39.44\n",
      "epoch: 485, avg_PSNR: 27.781699, time for epoch: 39.21\n",
      "epoch: 486, avg_PSNR: 27.800083, time for epoch: 39.50\n",
      "epoch: 487, avg_PSNR: 27.783224, time for epoch: 39.75\n",
      "epoch: 488, avg_PSNR: 27.786462, time for epoch: 39.67\n",
      "epoch: 489, avg_PSNR: 27.793124, time for epoch: 39.33\n",
      "epoch: 490, avg_PSNR: 27.801173, time for epoch: 39.48\n",
      "epoch: 491, avg_PSNR: 27.786251, time for epoch: 39.65\n",
      "epoch: 492, avg_PSNR: 27.791977, time for epoch: 39.29\n",
      "epoch: 493, avg_PSNR: 27.801715, time for epoch: 39.53\n",
      "epoch: 494, avg_PSNR: 27.804859, time for epoch: 39.52\n",
      "epoch: 495, avg_PSNR: 27.774218, time for epoch: 39.66\n",
      "epoch: 496, avg_PSNR: 27.815972, time for epoch: 39.42\n",
      "epoch: 497, avg_PSNR: 27.782821, time for epoch: 39.62\n",
      "epoch: 498, avg_PSNR: 27.809609, time for epoch: 39.81\n",
      "epoch: 499, avg_PSNR: 27.809787, time for epoch: 39.50\n"
     ]
    }
   ],
   "source": [
    "batch_size=32\n",
    "total_iter = int(trImg.shape[0]/batch_size)-1\n",
    "learing_rate = 1e-5\n",
    "for epoch in range(500):\n",
    "    avg_psnr = 0\n",
    "    cnt=0\n",
    "    start_time = time.time()\n",
    "    for batch in range(total_iter):\n",
    "        trImg, _= mnist.train.next_batch(batch_size)\n",
    "        trImg = np.reshape(trImg, [-1, 28, 28, 1])\n",
    "        LRImg = Bicubic(toLR(trImg))\n",
    "        HRImg = trImg\n",
    "        cnt+=1\n",
    "        \n",
    "        _, loss = sess.run([optm, model.LOSS], feed_dict={model.LRImg:LRImg, model.HRImg: HRImg, lr:learing_rate})\n",
    "        psnr = 20*np.log10(1./np.sqrt(loss))\n",
    "        print (\"\\rbatch: {}/{} ({:.1f}%) psnr: {:.5f}\".format(batch, total_iter, batch*100/total_iter, psnr), end=\"\")\n",
    "        avg_psnr+=psnr\n",
    "    if epoch % 10 == 5:\n",
    "        learing_rate*=1\n",
    "    print ('\\repoch: %3d, avg_PSNR: %4f, time for epoch: %.2f' %(epoch, avg_psnr/(cnt+1e-8), time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'checkpoints/SRCNN/MNIST_psnr_27-8_sigmoid'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "saver.save(sess, 'checkpoints/SRCNN/MNIST_psnr_27-8_sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/scipy/misc/pilutil.py:482: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if issubdtype(ts, int):\n",
      "/usr/local/lib/python3.5/dist-packages/scipy/misc/pilutil.py:485: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  elif issubdtype(type(size), float):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f358278a828>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3582864390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "showimg = mnist.test.images[0:32,:]\n",
    "hrimg = np.reshape(showimg, [-1, 28, 28, 1])\n",
    "lrimg = toLR(hrimg)\n",
    "lrimgbi=Bicubic(lrimg)\n",
    "srimg=sess.run(model.layer3, feed_dict={model.LRImg:lrimgbi})\n",
    "index=3\n",
    "\n",
    "plt.figure(figsize=[20,5])\n",
    "plt.subplot(1,3,1)\n",
    "plt.axis('off')\n",
    "plt.title('LR')\n",
    "plt.imshow(lrimg[index,:,:,0], cmap='gray')\n",
    "plt.subplot(1,3,2)\n",
    "plt.axis('off')\n",
    "plt.title('HR')\n",
    "plt.imshow(hrimg[index,:,:,0], cmap='gray')\n",
    "plt.subplot(1,3,3)\n",
    "plt.axis('off')\n",
    "plt.title('SR')\n",
    "plt.imshow(srimg[index,:,:,0], cmap='gray')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
