{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SRCapsNet - FCN + PS(MNIST)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "Training data set : 50000, Test data Set : 10000\n"
     ]
    }
   ],
   "source": [
    "import os, sys, time\n",
    "import numpy as np\n",
    "import scipy.ndimage, scipy.misc\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "slim = tf.contrib.slim\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"\n",
    "\n",
    "\n",
    "\n",
    "def unpickle(file):\n",
    "    with open(file, 'rb') as f:\n",
    "        data = pickle.load(f, encoding='latin1')\n",
    "        return data\n",
    "\n",
    "def load_cifar10_data(data_dir):\n",
    "    train_data = None\n",
    "    train_labels = []\n",
    "    \n",
    "    for i in range(1,6):\n",
    "        data_dic = unpickle(data_dir + \"/data_batch_{}\".format(i))\n",
    "        if i==1:\n",
    "            train_data = data_dic['data']\n",
    "        else:\n",
    "            train_data = np.vstack((train_data, data_dic['data']))\n",
    "        train_labels += data_dic['labels']\n",
    "    test_data_dic = unpickle(data_dir + \"/test_batch\")\n",
    "    test_data = test_data_dic['data']\n",
    "    test_labels = test_data_dic['labels']\n",
    "    \n",
    "    train_data = train_data.reshape((len(train_data), 3, 32, 32))\n",
    "    train_data = np.rollaxis(train_data, 1, 4)\n",
    "    train_labels = np.array(train_labels)\n",
    "    \n",
    "    test_data = test_data.reshape((len(test_data), 3, 32, 32))\n",
    "    test_data = np.rollaxis(test_data, 1, 4)\n",
    "    test_labels = np.array(test_labels)\n",
    "    \n",
    "    return train_data, train_labels, test_data, test_labels\n",
    "\n",
    "data_dir = '/ideaHome/Dropbox/SJ/ML/Cifar10/Data/cifar-10-batches-py'\n",
    "trImg, train_labels, teImg, test_labels = load_cifar10_data(data_dir)\n",
    "\n",
    "\n",
    "print(\"Training data set : %3d, Test data Set : %3d\" %(trImg.shape[0], teImg.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-8bf8ae5a5303>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def toLR(image, scale=2.):\n",
    "    if len(image.shape)==4:\n",
    "        num_sample = image.shape[0]\n",
    "        images = np.zeros([image.shape[0], int(image.shape[1]/scale), int(image.shape[2]/scale), image.shape[3]])\n",
    "        for i in range(num_sample):\n",
    "            images[i,:,:,0] = scipy.misc.imresize(image[i,:,:,0], 1/scale,'bicubic')\n",
    "        return images\n",
    "    else:\n",
    "        return scipy.misc.imresize(image, 1/scale, 'bicubic')\n",
    "    \n",
    "\n",
    "def Bicubic(image, scale=2):\n",
    "    if len(image.shape)==4:\n",
    "        bicImg = scipy.ndimage.interpolation.zoom(image, [1, scale, scale, 1], prefilter=False)\n",
    "    else:\n",
    "        bicImg = scipy.ndimage.interpolation.zoom(image, [scale,scale, 1], prefilter=False)\n",
    "    return bicImg\n",
    "\n",
    "def _phase_shift(I, r):\n",
    "    # Helper function with main phase shift operation\n",
    "    bsize, a, b, c = I.get_shape().as_list()\n",
    "    X = tf.reshape(I, (-1, a, b, r, r))\n",
    "    X = tf.transpose(X, (0, 1, 2, 4, 3))  # bsize, a, b, 1, 1\n",
    "    X = tf.split(X, a, 1)  # a, [bsize, b, r, r]\n",
    "    X = tf.concat([tf.squeeze(x) for x in X], axis=2)  # bsize, b, a*r, r\n",
    "    X = tf.split(X, b, 1)  # b, [bsize, a*r, r]\n",
    "    X = tf.concat([tf.squeeze(x) for x in X], axis=2)  # bsize, a*r, b*r\n",
    "    return tf.reshape(X, (-1, a*r, b*r, 1))\n",
    "\n",
    "def PS(X, r, color=False):\n",
    "  # Main OP that you can arbitrarily use in you tensorflow code\n",
    "    if color:\n",
    "        Xc = tf.split(X,3,3) #(3, 3, X)\n",
    "        X = tf.concat([_phase_shift(x, r) for x in Xc], axis=3)\n",
    "    else:\n",
    "        X = _phase_shift(X, r)\n",
    "    return X\n",
    "\n",
    "def squash(s, axis=-1, epsilon=1e-7, name=None):\n",
    "    with tf.name_scope(name, default_name=\"squash\"):\n",
    "        squared_norm = tf.reduce_sum(tf.square(s), axis=axis, keep_dims=True)\n",
    "        safe_norm = tf.sqrt(squared_norm + epsilon)\n",
    "        squash_factor = squared_norm / (1. + squared_norm)\n",
    "        unit_vector = s / safe_norm\n",
    "    return squash_factor * unit_vector\n",
    "\n",
    "def safe_norm(s, axis=-1, epsilon=1e-7, keep_dims=False, name=None):\n",
    "    with tf.name_scope(name, default_name=\"safe_norm\"):\n",
    "        squared_norm = tf.reduce_sum(tf.square(s), axis=axis,\n",
    "                                     keep_dims=keep_dims)\n",
    "        return tf.sqrt(squared_norm + epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SRCapsNet(object):\n",
    "    def __init__(self, mode):\n",
    "        self.LR_dim = (None, 28,28,1)\n",
    "        self.HR_dim = (None, 28,28,1)\n",
    "        self.batch_size = 32\n",
    "        self.mode = mode\n",
    "        \n",
    "        self.routing_iter = 2\n",
    "        self.caps1_num = 3*3*32\n",
    "        self.caps1_dim = 8\n",
    "        self.caps2_vec = 10\n",
    "        self.caps2_num = 4*4*self.caps2_vec\n",
    "        self.caps2_dim = 8\n",
    "        \n",
    "        self.W_init = tf.random_normal(shape=(1, self.caps1_num, self.caps2_num, self.caps2_dim, self.caps1_dim), \n",
    "                                      stddev = 0.1, dtype=tf.float32, name='W_init')\n",
    "        self.W = tf.Variable(self.W_init, name='w')\n",
    "        \n",
    "        print('The model is generated')\n",
    "        \n",
    "    def model(self, img):\n",
    "        with slim.arg_scope([slim.conv2d],kernel_size=[5,5], stride=[1,1], activation_fn = tf.nn.leaky_relu,\n",
    "                            padding='valid',weights_initializer=tf.contrib.layers.xavier_initializer()):\n",
    "            \n",
    "            self.conv1 = slim.conv2d(inputs=img, num_outputs=256, scope='conv1')\n",
    "            print(self.conv1)\n",
    "            self.conv2 = slim.conv2d(inputs=self.conv1, num_outputs=256,stride=[2,2], scope='conv2')\n",
    "        batch_size = tf.shape(img)[0]    \n",
    "        self.caps1 = tf.reshape(self.conv2, [batch_size, self.caps1_num, self.caps1_dim], name='caps1_reshape')\n",
    "        self.caps1_squash = squash(self.caps1, name='caps1_squash')\n",
    "            \n",
    "            \n",
    "        self.W_tiled = tf.tile(self.W, [batch_size, 1, 1, 1, 1], name='W_tiled')\n",
    "            \n",
    "        self.caps1_expanded = tf.expand_dims(self.caps1_squash, -1, name='caps1_expanded')\n",
    "        self.caps1_expanded2 = tf.expand_dims(self.caps1_expanded, 2, name='caps1_expanded2')\n",
    "        self.caps1_tiled = tf.tile(self.caps1_expanded2, [1, 1, self.caps2_num, 1, 1], name='caps1_tiled')\n",
    "        self.caps2_in = tf.matmul(self.W_tiled, self.caps1_tiled, name='caps2_in')\n",
    "        self.b_ij = tf.zeros([batch_size, self.caps1_num, self.caps2_num, 1, 1], name='b_ij')\n",
    "        for i in range(self.routing_iter):\n",
    "            if i>0:\n",
    "                self.b_ij = tf.add(self.b_ij, agreement)\n",
    "            self.c_ij = tf.nn.softmax(self.b_ij, dim=2, name='c_ij')\n",
    "            self.s_j = tf.reduce_sum(tf.multiply(self.c_ij, self.caps2_in), axis=1, keep_dims=True, name='s_j')\n",
    "            self.v_j = squash(self.s_j, axis=-2, name='v_j')\n",
    "            if i<self.routing_iter-1:\n",
    "                self.v_j_tiled = tf.tile(self.v_j, [1, self.caps1_num, 1, 1, 1], name='v_j_tiled')\n",
    "                agreement = tf.matmul(self.caps2_in, self.v_j_tiled, transpose_a=True, name='agreement')\n",
    "\n",
    "        self.caps2_out = self.v_j\n",
    "        self.caps2_reshape = tf.reshape(self.caps2_out, [-1,4,4,self.caps2_vec * self.caps2_dim], name='caps2_reshape')\n",
    "        \n",
    "        with slim.arg_scope([slim.conv2d],kernel_size=[3,3], stride=[1,1], activation_fn = tf.nn.leaky_relu,\n",
    "                            padding='same',weights_initializer=tf.contrib.layers.xavier_initializer()):\n",
    "            self.conv3 = slim.conv2d(inputs=self.caps2_reshape, num_outputs=180, scope='conv3')\n",
    "            self.conv4 = slim.conv2d(inputs=self.conv3, num_outputs=49, scope='conv4', activation_fn=tf.nn.sigmoid)\n",
    "        #self.for_PS = tf.reshape(self.fc3, [-1, 14, 14, 1])\n",
    "        \n",
    "        self.out_layer = PS(self.conv4, 7, False)\n",
    "        #self.conv3 = slim.conv2d(inputs=self.caps2_reshape, num_outputs=12, scope='conv3', activation_fn=None)\n",
    "        #self.out_layer = PS(self.conv3, 2, True)\n",
    "\n",
    "        out = self.out_layer\n",
    "        return out\n",
    "    \n",
    "    def loss(self, SR, HR):\n",
    "        loss = tf.reduce_mean(tf.square(SR - HR), name='loss')\n",
    "        return loss\n",
    "    \n",
    "    def build(self):\n",
    "        if self.mode == 'bicubic':\n",
    "            self.LRImg = tf.placeholder(tf.float32, [None, 28, 28, 1], 'LRImgBicubic')\n",
    "        elif self.mode == 'pixelshuffle':\n",
    "            self.LRImg = tf.placeholder(tf.float32, [None, 14, 14, 1], 'LRImgPixelShuffle')\n",
    "        else:\n",
    "            print ('undefined mode')\n",
    "        self.HRImg = tf.placeholder(tf.float32, [None, 28, 28, 1], 'HRImg')\n",
    "        self.SRImg = self.model(self.LRImg)\n",
    "        self.LOSS = self.loss(self.SRImg, self.HRImg)\n",
    "    \n",
    "   \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is generated\n",
      "Tensor(\"conv1/LeakyRelu/Maximum:0\", shape=(?, 10, 10, 256), dtype=float32)\n",
      "---------\n",
      "Variables: name (type shape) [size]\n",
      "---------\n",
      "w:0 (float32_ref 1x288x160x8x8) [2949120, bytes: 11796480]\n",
      "conv1/weights:0 (float32_ref 5x5x1x256) [6400, bytes: 25600]\n",
      "conv1/biases:0 (float32_ref 256) [256, bytes: 1024]\n",
      "conv2/weights:0 (float32_ref 5x5x256x256) [1638400, bytes: 6553600]\n",
      "conv2/biases:0 (float32_ref 256) [256, bytes: 1024]\n",
      "conv3/weights:0 (float32_ref 3x3x80x180) [129600, bytes: 518400]\n",
      "conv3/biases:0 (float32_ref 180) [180, bytes: 720]\n",
      "conv4/weights:0 (float32_ref 3x3x180x49) [79380, bytes: 317520]\n",
      "conv4/biases:0 (float32_ref 49) [49, bytes: 196]\n",
      "Total size of variables: 4803641\n",
      "Total bytes of variables: 19214564\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4803641, 19214564)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "model = SRCapsNet('pixelshuffle')\n",
    "model.build()\n",
    "\n",
    "t_vars = tf.trainable_variables()\n",
    "slim.model_analyzer.analyze_vars(t_vars, print_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optm = tf.train.AdamOptimizer(learning_rate=1e-3).minimize(model.LOSS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialization complete\n"
     ]
    }
   ],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config) \n",
    "sess.run(tf.global_variables_initializer())\n",
    "print('initialization complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/scipy/misc/pilutil.py:482: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if issubdtype(ts, int):\n",
      "/usr/local/lib/python3.5/dist-packages/scipy/misc/pilutil.py:485: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  elif issubdtype(type(size), float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   0, avg_PSNR: 16.520808, time: 1117.3\n",
      "epoch:   1, avg_PSNR: 21.343556, time: 1113.4\n",
      "epoch:   2, avg_PSNR: 22.876342, time: 1113.8\n",
      "epoch:   3, avg_PSNR: 23.715369, time: 1118.3\n",
      "epoch:   4, avg_PSNR: 24.269267, time: 1124.2\n",
      "epoch:   5, avg_PSNR: 24.678574, time: 1129.9\n",
      "epoch:   6, avg_PSNR: 25.017739, time: 1137.1\n",
      "epoch:   7, avg_PSNR: 25.319409, time: 1139.7\n",
      "epoch:   8, avg_PSNR: 25.639054, time: 1140.8\n",
      "epoch:   9, avg_PSNR: 25.873761, time: 1139.4\n",
      "epoch:  10, avg_PSNR: 26.080381, time: 1149.7\n",
      "epoch:  11, avg_PSNR: 26.245373, time: 1145.3\n",
      "epoch:  12, avg_PSNR: 26.404112, time: 1144.7\n",
      "epoch:  13, avg_PSNR: 26.540965, time: 1143.9\n",
      "epoch:  14, avg_PSNR: 26.683294, time: 1133.5\n",
      "epoch:  15, avg_PSNR: 26.793624, time: 1133.3\n",
      "epoch:  16, avg_PSNR: 26.909214, time: 1151.1\n",
      "epoch:  17, avg_PSNR: 27.015871, time: 1145.0\n",
      "epoch:  18, avg_PSNR: 27.107670, time: 1163.0\n",
      "epoch:  19, avg_PSNR: 27.207965, time: 1136.5\n",
      "epoch:  20, avg_PSNR: 27.279448, time: 1141.7\n",
      "epoch:  21, avg_PSNR: 27.366250, time: 1144.9\n",
      "epoch:  22, avg_PSNR: 27.442464, time: 1140.3\n",
      "epoch:  23, avg_PSNR: 27.516645, time: 1161.4\n",
      "epoch:  24, avg_PSNR: 27.583944, time: 1162.3\n",
      "epoch:  25, avg_PSNR: 27.656915, time: 1145.1\n",
      "epoch:  26, avg_PSNR: 27.719962, time: 1137.1\n",
      "epoch:  27, avg_PSNR: 27.784031, time: 1137.5\n",
      "epoch:  28, avg_PSNR: 27.844082, time: 1139.0\n",
      "epoch:  29, avg_PSNR: 27.891843, time: 1137.0\n",
      "epoch:  30, avg_PSNR: 27.958851, time: 1125.3\n",
      "epoch:  31, avg_PSNR: 28.005796, time: 1130.0\n",
      "epoch:  32, avg_PSNR: 28.062903, time: 1140.6\n",
      "epoch:  33, avg_PSNR: 28.113480, time: 1132.5\n",
      "epoch:  34, avg_PSNR: 28.172941, time: 1124.2\n",
      "epoch:  35, avg_PSNR: 28.203501, time: 1127.6\n",
      "epoch:  36, avg_PSNR: 28.258039, time: 1132.7\n",
      "epoch:  37, avg_PSNR: 28.298809, time: 1127.7\n",
      "epoch:  38, avg_PSNR: 28.351203, time: 1126.1\n",
      "epoch:  39, avg_PSNR: 28.392106, time: 1138.2\n",
      "epoch:  40, avg_PSNR: 28.434123, time: 1128.2\n",
      "epoch:  41, avg_PSNR: 28.477090, time: 1147.6\n",
      "epoch:  42, avg_PSNR: 28.515856, time: 1135.7\n",
      "epoch:  43, avg_PSNR: 28.557205, time: 1138.1\n",
      "epoch:  44, avg_PSNR: 28.601916, time: 1140.6\n",
      "epoch:  45, avg_PSNR: 28.633334, time: 1139.1\n",
      "epoch:  46, avg_PSNR: 28.671746, time: 1135.3\n",
      "epoch:  47, avg_PSNR: 28.712521, time: 1134.0\n",
      "epoch:  48, avg_PSNR: 28.747319, time: 1145.6\n",
      "epoch:  49, avg_PSNR: 28.780168, time: 1150.9\n",
      "epoch:  50, avg_PSNR: 28.809949, time: 1140.2\n",
      "epoch:  51, avg_PSNR: 28.851803, time: 1133.8\n",
      "epoch:  52, avg_PSNR: 28.881949, time: 1133.3\n",
      "epoch:  53, avg_PSNR: 28.916314, time: 1132.6\n",
      "epoch:  54, avg_PSNR: 28.957734, time: 1133.4\n",
      "epoch:  55, avg_PSNR: 28.979451, time: 1136.3\n",
      "epoch:  56, avg_PSNR: 29.014808, time: 1140.7\n",
      "epoch:  57, avg_PSNR: 29.043749, time: 1137.3\n",
      "epoch:  58, avg_PSNR: 29.073250, time: 1147.6\n",
      "epoch:  59, avg_PSNR: 29.104870, time: 1150.2\n",
      "epoch:  60, avg_PSNR: 29.137260, time: 1147.0\n",
      "epoch:  61, avg_PSNR: 29.161661, time: 1143.6\n",
      "epoch:  62, avg_PSNR: 29.197025, time: 1152.0\n",
      "epoch:  63, avg_PSNR: 29.220281, time: 1160.5\n",
      "epoch:  64, avg_PSNR: 29.250276, time: 1162.7\n",
      "epoch:  65, avg_PSNR: 29.274877, time: 1155.8\n",
      "epoch:  66, avg_PSNR: 29.305851, time: 1147.5\n",
      "epoch:  67, avg_PSNR: 29.328330, time: 1145.5\n",
      "epoch:  68, avg_PSNR: 29.363694, time: 1149.1\n",
      "epoch:  69, avg_PSNR: 29.389200, time: 1149.8\n",
      "epoch:  70, avg_PSNR: 29.407796, time: 1143.3\n",
      "epoch:  71, avg_PSNR: 29.440183, time: 1138.0\n",
      "epoch:  72, avg_PSNR: 29.463144, time: 1149.8\n",
      "epoch:  73, avg_PSNR: 29.493045, time: 1154.0\n",
      "epoch:  74, avg_PSNR: 29.513302, time: 1144.9\n",
      "epoch:  75, avg_PSNR: 29.542909, time: 1141.5\n",
      "epoch:  76, avg_PSNR: 29.572565, time: 1130.8\n",
      "epoch:  77, avg_PSNR: 29.589133, time: 1148.1\n",
      "epoch:  78, avg_PSNR: 29.613299, time: 1134.8\n",
      "epoch:  79, avg_PSNR: 29.646127, time: 1147.3\n",
      "epoch:  80, avg_PSNR: 29.660099, time: 1149.0\n",
      "epoch:  81, avg_PSNR: 29.694266, time: 1136.3\n",
      "epoch:  82, avg_PSNR: 29.713327, time: 1142.3\n",
      "epoch:  83, avg_PSNR: 29.735679, time: 1184.6\n",
      "epoch:  84, avg_PSNR: 29.760658, time: 1167.7\n",
      "epoch:  85, avg_PSNR: 29.783459, time: 1164.3\n",
      "epoch:  86, avg_PSNR: 29.805087, time: 1181.8\n",
      "epoch:  87, avg_PSNR: 29.829282, time: 1183.8\n",
      "epoch:  88, avg_PSNR: 29.854197, time: 1202.0\n",
      "epoch:  89, avg_PSNR: 29.880294, time: 1279.6\n",
      "epoch:  90, avg_PSNR: 29.895104, time: 1359.9\n",
      "epoch:  91, avg_PSNR: 29.929160, time: 1440.0\n",
      "epoch:  92, avg_PSNR: 29.938974, time: 1394.1\n",
      "epoch:  93, avg_PSNR: 29.967352, time: 1345.0\n",
      "epoch:  94, avg_PSNR: 29.989027, time: 1336.0\n",
      "epoch:  95, avg_PSNR: 30.015052, time: 1351.5\n",
      "epoch:  96, avg_PSNR: 30.029155, time: 1343.5\n",
      "epoch:  97, avg_PSNR: 30.058022, time: 1353.3\n",
      "epoch:  98, avg_PSNR: 30.072797, time: 1347.5\n",
      "epoch:  99, avg_PSNR: 30.101245, time: 1346.3\n"
     ]
    }
   ],
   "source": [
    "batch_size=model.batch_size\n",
    "print('batch_size: {}'.format(batch_size))\n",
    "total_iter = mnist.train.num_examples // batch_size\n",
    "for epoch in range(100):\n",
    "    start_time=time.time()\n",
    "    avg_psnr = 0\n",
    "    for batch in range(total_iter):\n",
    "        trImg, _= mnist.train.next_batch(batch_size)\n",
    "        trImg = np.reshape(trImg, [-1, 28, 28, 1])\n",
    "        LRImg = toLR(trImg)\n",
    "        HRImg = trImg\n",
    "        _, loss = sess.run([optm, model.LOSS], feed_dict={model.LRImg:LRImg, model.HRImg: HRImg})\n",
    "        psnr = 20*np.log10(1./np.sqrt(loss))\n",
    "        print (\"\\r batch: {}/{} ({:.1f}%) psnr: {:.5f}\".format(\n",
    "            batch, total_iter, batch*100/total_iter, psnr) ,end=\"\")\n",
    "        avg_psnr+=psnr\n",
    "    print ('\\repoch: %3d, avg_PSNR: %4f, time: %.1f' %(epoch, avg_psnr/total_iter, time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'checkpoints/SRCapsNet/PS_FullConv_MNIST_psnr_30-10'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver=tf.train.Saver()\n",
    "saver.save(sess, 'checkpoints/SRCapsNet/PS_FullConv_MNIST_psnr_30-10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/scipy/misc/pilutil.py:482: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if issubdtype(ts, int):\n",
      "/usr/local/lib/python3.5/dist-packages/scipy/misc/pilutil.py:485: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  elif issubdtype(type(size), float):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8660b1be80>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8662e530b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "showimg = mnist.test.images[0:32,:]\n",
    "hrimg = np.reshape(showimg, [-1, 28, 28, 1])\n",
    "lrimg = toLR(hrimg)\n",
    "srimg=sess.run(model.out_layer, feed_dict={model.LRImg:lrimg})\n",
    "index=3\n",
    "\n",
    "plt.figure(figsize=[20,5])\n",
    "plt.subplot(1,3,1)\n",
    "plt.axis('off')\n",
    "plt.title('LR')\n",
    "plt.imshow(lrimg[index,:,:,0], cmap='gray')\n",
    "plt.subplot(1,3,2)\n",
    "plt.axis('off')\n",
    "plt.title('HR')\n",
    "plt.imshow(hrimg[index,:,:,0], cmap='gray')\n",
    "plt.subplot(1,3,3)\n",
    "plt.axis('off')\n",
    "plt.title('SR')\n",
    "plt.imshow(srimg[index,:,:,0], cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
