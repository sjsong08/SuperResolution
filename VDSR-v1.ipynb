{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "#import imageio\n",
    "import scipy.ndimage\n",
    "import scipy.misc\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imread(path, index, scale=1, gray=True, is_train=False):\n",
    "    if gray:\n",
    "        image = np.zeros([len(index), image_y, image_x, 1])\n",
    "        cnt=0\n",
    "        for i in (index):\n",
    "            if is_train:\n",
    "                img = scipy.misc.imread(path+str(i).zfill(4)+'x'+str(scale)+'.png', flatten=True, mode='YCbCr').astype(np.float)/255.\n",
    "            else:\n",
    "                img = scipy.misc.imread(path+str(i).zfill(4)+'.png', flatten=True, mode='YCbCr').astype(np.float)/255.\n",
    "            if img.shape[1]<img.shape[0]:\n",
    "                img=img.T\n",
    "            if is_train and img.shape[0]>=540:\n",
    "                image[cnt,:,:,0]=preprocess(img[:int(1080/scale),:int(1920/scale)], scale)\n",
    "                cnt+=1\n",
    "            elif is_train==False and img.shape[0]>=1080:\n",
    "                image[cnt,:,:,0]=img[:int(1080/scale),:int(1920/scale)]\n",
    "                cnt+=1\n",
    "            \n",
    "        return image[:cnt,:,:,:]\n",
    "    else:\n",
    "        image = np.zeros([len(index), image_y, image_x, 3])\n",
    "        cnt=0\n",
    "        for i in (index):\n",
    "            if is_train:\n",
    "                img = scipy.misc.imread(path+str(i).zfill(4)+'x'+str(scale)+'.png', mode='YCbCr').astype(np.float)/255.\n",
    "            else:\n",
    "                img = scipy.misc.imread(path+str(i).zfill(4)+'.png', mode='YCbCr').astype(np.float)/255.\n",
    "            if img.shape[1]<img.shape[0]:\n",
    "                img1=img[:,:,0].T\n",
    "                img2=img[:,:,1].T\n",
    "                img3=img[:,:,2].T\n",
    "                img = np.stack([img1,img2,img3], axis=2)\n",
    "            if is_train:\n",
    "                image[cnt,:,:,:]=preprocess(img[:int(1080/scale),:int(1920/scale),:],scale)\n",
    "            else:\n",
    "                image[cnt,:,:,:]=img[:int(1080/scale),:int(1920/scale),:]\n",
    "            cnt+=1\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image, scale=2, gray=True):\n",
    "    if gray:\n",
    "        return scipy.ndimage.interpolation.zoom(image, (scale/1.), prefilter=False)\n",
    "    else:\n",
    "        image1 = scipy.ndimage.interpolation.zoom(image[:,:,0], (scale/1.), prefilter=False)\n",
    "        image2 = scipy.ndimage.interpolation.zoom(image[:,:,1], (scale/1.), prefilter=False)\n",
    "        image3 = scipy.ndimage.interpolation.zoom(image[:,:,2], (scale/1.), prefilter=False)\n",
    "        imageA = np.stack([image1, image2, image3], axis=2)\n",
    "        return imageA\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imsave(image, path):\n",
    "    return scipy.misc.imsave(path, image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "#device = \"/gpu:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray=True\n",
    "epoch_size = 1000\n",
    "batch_size = 1\n",
    "total_iter = 800/batch_size\n",
    "image_x = 1920\n",
    "image_y = 1080\n",
    "\n",
    "if gray==True:\n",
    "    c_dim=1\n",
    "else:\n",
    "    c_dim=3\n",
    "    \n",
    "learning_rate = 1e-3\n",
    "\n",
    "        \n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, image_y, image_x, c_dim], name='input')\n",
    "Y = tf.placeholder(tf.float32, [None, image_y, image_x, c_dim], name='output')\n",
    "\n",
    "weights = {\n",
    "    'w1' : tf.get_variable('w1',shape=[3,3,1,64], initializer=tf.contrib.layers.xavier_initializer_conv2d()),\n",
    "    'w2' : tf.get_variable('w2',shape=[3,3,64,64], initializer=tf.contrib.layers.xavier_initializer_conv2d()),\n",
    "    'w3' : tf.get_variable('w3',shape=[3,3,64,64], initializer=tf.contrib.layers.xavier_initializer_conv2d()),\n",
    "    'w4' : tf.get_variable('w4',shape=[3,3,64,64], initializer=tf.contrib.layers.xavier_initializer_conv2d()),\n",
    "    'w5' : tf.get_variable('w5',shape=[3,3,64,64], initializer=tf.contrib.layers.xavier_initializer_conv2d()),\n",
    "    'w6' : tf.get_variable('w6',shape=[3,3,64,64], initializer=tf.contrib.layers.xavier_initializer_conv2d()),\n",
    "    'w7' : tf.get_variable('w7',shape=[3,3,64,64], initializer=tf.contrib.layers.xavier_initializer_conv2d()),\n",
    "    'w8' : tf.get_variable('w8',shape=[3,3,64,64], initializer=tf.contrib.layers.xavier_initializer_conv2d()),\n",
    "    'w9' : tf.get_variable('w9',shape=[3,3,64,1], initializer=tf.contrib.layers.xavier_initializer_conv2d())            \n",
    "}\n",
    "biases = {\n",
    "    'b1' : tf.get_variable('b1',shape=[64], initializer=tf.contrib.layers.xavier_initializer_conv2d()),\n",
    "    'b2' : tf.get_variable('b2',shape=[64], initializer=tf.contrib.layers.xavier_initializer_conv2d()),\n",
    "    'b3' : tf.get_variable('b3',shape=[64], initializer=tf.contrib.layers.xavier_initializer_conv2d()),\n",
    "    'b4' : tf.get_variable('b4',shape=[64], initializer=tf.contrib.layers.xavier_initializer_conv2d()),\n",
    "    'b5' : tf.get_variable('b5',shape=[64], initializer=tf.contrib.layers.xavier_initializer_conv2d()),\n",
    "    'b6' : tf.get_variable('b6',shape=[64], initializer=tf.contrib.layers.xavier_initializer_conv2d()),\n",
    "    'b7' : tf.get_variable('b7',shape=[64], initializer=tf.contrib.layers.xavier_initializer_conv2d()),\n",
    "    'b8' : tf.get_variable('b8',shape=[64], initializer=tf.contrib.layers.xavier_initializer_conv2d()),\n",
    "    'b9' : tf.get_variable('b9',shape=[1], initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = tf.nn.relu(tf.nn.conv2d(X, weights['w1'], strides=[1,1,1,1], padding='SAME')+biases['b1'])\n",
    "conv2 = tf.nn.relu(tf.nn.conv2d(conv1, weights['w2'], strides=[1,1,1,1], padding='SAME')+biases['b2'])\n",
    "conv3 = tf.nn.relu(tf.nn.conv2d(conv2, weights['w3'], strides=[1,1,1,1], padding='SAME')+biases['b3'])\n",
    "conv4 = tf.nn.relu(tf.nn.conv2d(conv3, weights['w4'], strides=[1,1,1,1], padding='SAME')+biases['b4'])\n",
    "conv5 = tf.nn.relu(tf.nn.conv2d(conv4, weights['w5'], strides=[1,1,1,1], padding='SAME')+biases['b5'])\n",
    "conv6 = tf.nn.relu(tf.nn.conv2d(conv5, weights['w6'], strides=[1,1,1,1], padding='SAME')+biases['b6'])\n",
    "conv7 = tf.nn.relu(tf.nn.conv2d(conv6, weights['w7'], strides=[1,1,1,1], padding='SAME')+biases['b7'])\n",
    "conv8 = tf.nn.relu(tf.nn.conv2d(conv7, weights['w8'], strides=[1,1,1,1], padding='SAME')+biases['b8'])\n",
    "conv9 = tf.nn.conv2d(conv8, weights['w9'], strides=[1,1,1,1], padding='SAME')+biases['b9']\n",
    "out_residual = tf.add(X,conv9)\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(Y-out_residual))\n",
    "optm = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess_config = tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True))\n",
    "sess = tf.Session(config=sess_config)\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path='subimages/train_bicubic_x2/'\n",
    "label_path='subimages/train_HR/'\n",
    "result_path='results/SRCNN_v1/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  import sys\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epoch_size):\n",
    "    avr_psnr = 0\n",
    "    for i in range(total_iter):\n",
    "\n",
    "        #index = np.random.choice(800, batch_size, replace=False)+1\n",
    "        index = np.random.choice(5, batch_size, replace=False)+1\n",
    "        train_image = imread(path=train_path,index=index,is_train=True,scale=2)\n",
    "        label_image = imread(path=label_path, index=index)\n",
    "\n",
    "        sess.run(optm, feed_dict={X:train_image, Y:label_image})\n",
    "        tr_loss = sess.run(loss, feed_dict={X:train_image, Y:label_image})\n",
    "        psnr = 20*np.log10(1./np.sqrt(tr_loss))\n",
    "        avr_psnr += psnr\n",
    "\n",
    "    print ('epoch: %3d, Avr_PSNR: %4f' %(epoch, avr_psnr/total_iter))\n",
    "    imgOUT = sess.run(out_residual, feed_dict={X:train_image})\n",
    "    for j in range(imgOUT.shape[0]):\n",
    "        imsave(imgOUT[j,:,:,0], result_path+'srcnn'+str(j).zfill(4)+'.png')\n",
    "        imsave(train_image[j,:,:,0], result_path+'interpol_'+str(j).zfill(4)+'.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.imshow(train_image[3,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
