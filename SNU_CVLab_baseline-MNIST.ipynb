{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SNU_CVLab_baseline (MNIST)\n",
    "![image](https://i.imgur.com/1yq56OL.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "Training data set : 50000, Test data Set : 10000\n"
     ]
    }
   ],
   "source": [
    "import os, sys, time\n",
    "import numpy as np\n",
    "import scipy.ndimage, scipy.misc\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "slim = tf.contrib.slim\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"\n",
    "\n",
    "\n",
    "\n",
    "def unpickle(file):\n",
    "    with open(file, 'rb') as f:\n",
    "        data = pickle.load(f, encoding='latin1')\n",
    "        return data\n",
    "\n",
    "def load_cifar10_data(data_dir):\n",
    "    train_data = None\n",
    "    train_labels = []\n",
    "    \n",
    "    for i in range(1,6):\n",
    "        data_dic = unpickle(data_dir + \"/data_batch_{}\".format(i))\n",
    "        if i==1:\n",
    "            train_data = data_dic['data']\n",
    "        else:\n",
    "            train_data = np.vstack((train_data, data_dic['data']))\n",
    "        train_labels += data_dic['labels']\n",
    "    test_data_dic = unpickle(data_dir + \"/test_batch\")\n",
    "    test_data = test_data_dic['data']\n",
    "    test_labels = test_data_dic['labels']\n",
    "    \n",
    "    train_data = train_data.reshape((len(train_data), 3, 32, 32))\n",
    "    train_data = np.rollaxis(train_data, 1, 4)\n",
    "    train_labels = np.array(train_labels)\n",
    "    \n",
    "    test_data = test_data.reshape((len(test_data), 3, 32, 32))\n",
    "    test_data = np.rollaxis(test_data, 1, 4)\n",
    "    test_labels = np.array(test_labels)\n",
    "    \n",
    "    return train_data, train_labels, test_data, test_labels\n",
    "\n",
    "data_dir = '/ideaHome/Dropbox/SJ/ML/Cifar10/Data/cifar-10-batches-py'\n",
    "trImg, train_labels, teImg, test_labels = load_cifar10_data(data_dir)\n",
    "\n",
    "\n",
    "print(\"Training data set : %3d, Test data Set : %3d\" %(trImg.shape[0], teImg.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-8bf8ae5a5303>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def toLR(image, scale=2.):\n",
    "    if len(image.shape)==4:\n",
    "        num_sample = image.shape[0]\n",
    "        images = np.zeros([image.shape[0], int(image.shape[1]/scale), int(image.shape[2]/scale), image.shape[3]])\n",
    "        for i in range(num_sample):\n",
    "            images[i,:,:,0] = scipy.misc.imresize(image[i,:,:,0], 1/scale,'bicubic')\n",
    "        return images\n",
    "    else:\n",
    "        return scipy.misc.imresize(image, 1/scale, 'bicubic')\n",
    "    \n",
    "\n",
    "def Bicubic(image, scale=2):\n",
    "    if len(image.shape)==4:\n",
    "        bicImg = scipy.ndimage.interpolation.zoom(image, [1, scale, scale, 1], prefilter=False)\n",
    "    else:\n",
    "        bicImg = scipy.ndimage.interpolation.zoom(image, [scale,scale, 1], prefilter=False)\n",
    "    return bicImg\n",
    "\n",
    "def _phase_shift(I, r):\n",
    "    # Helper function with main phase shift operation\n",
    "    bsize, a, b, c = I.get_shape().as_list()\n",
    "    X = tf.reshape(I, (-1, a, b, r, r))\n",
    "    X = tf.transpose(X, (0, 1, 2, 4, 3))  # bsize, a, b, 1, 1\n",
    "    X = tf.split(X, a, 1)  # a, [bsize, b, r, r]\n",
    "    X = tf.concat([tf.squeeze(x) for x in X], axis=2)  # bsize, b, a*r, r\n",
    "    X = tf.split(X, b, 1)  # b, [bsize, a*r, r]\n",
    "    X = tf.concat([tf.squeeze(x) for x in X], axis=2)  # bsize, a*r, b*r\n",
    "    return tf.reshape(X, (-1, a*r, b*r, 1))\n",
    "\n",
    "def PS(X, r, color=False):\n",
    "  # Main OP that you can arbitrarily use in you tensorflow code\n",
    "    if color:\n",
    "        Xc = tf.split(X,3,3) #(3, 3, X)\n",
    "        X = tf.concat([_phase_shift(x, r) for x in Xc], axis=3)\n",
    "    else:\n",
    "        X = _phase_shift(X, r)\n",
    "    return X\n",
    "\n",
    "def squash(s, axis=-1, epsilon=1e-7, name=None):\n",
    "    with tf.name_scope(name, default_name=\"squash\"):\n",
    "        squared_norm = tf.reduce_sum(tf.square(s), axis=axis, keep_dims=True)\n",
    "        safe_norm = tf.sqrt(squared_norm + epsilon)\n",
    "        squash_factor = squared_norm / (1. + squared_norm)\n",
    "        unit_vector = s / safe_norm\n",
    "    return squash_factor * unit_vector\n",
    "\n",
    "def safe_norm(s, axis=-1, epsilon=1e-7, keep_dims=False, name=None):\n",
    "    with tf.name_scope(name, default_name=\"safe_norm\"):\n",
    "        squared_norm = tf.reduce_sum(tf.square(s), axis=axis,\n",
    "                                     keep_dims=keep_dims)\n",
    "        return tf.sqrt(squared_norm + epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class CVLab(object):\n",
    "    def __init__(self, mode):\n",
    "        self.LR_dim = (28,28,1)\n",
    "        self.HR_dim = (28,28,1)\n",
    "        self.batch_size = 32\n",
    "        self.mode = mode\n",
    "\n",
    "        print('The model is generated')\n",
    "    def RB(self, in_layer, name='default'):\n",
    "        with slim.arg_scope([slim.conv2d], num_outputs=64, kernel_size=[3,3], stride=[1,1], activation_fn = tf.nn.relu, padding='SAME',\n",
    "                                                   weights_initializer=tf.contrib.layers.xavier_initializer()):\n",
    "            layer1 = slim.conv2d(inputs=in_layer, scope=name+'-conv1')\n",
    "            layer2 = slim.conv2d(inputs=layer1, activation_fn=None, scope=name+'-conv2')\n",
    "            layer3 = tf.add(layer2, in_layer, name=name+'residual')\n",
    "        return layer3\n",
    "        \n",
    "    def model(self, img):\n",
    "        name='a'\n",
    "        self.conv1 = slim.conv2d(inputs=img, num_outputs=64, kernel_size=[3,3], stride=[1,1], activation_fn=None, padding='SAME',\n",
    "                                weights_initializer=tf.contrib.layers.xavier_initializer())    \n",
    "        \n",
    "        \n",
    "        \n",
    "        self.RB1 = self.RB(self.conv1, 'rb1')\n",
    "        self.RB2 = self.RB(self.RB1, 'rb2')\n",
    "        self.RB3 = self.RB(self.RB2, 'rb3')\n",
    "        self.RB4 = self.RB(self.RB3, 'rb4')\n",
    "        self.RB5 = self.RB(self.RB4, 'rb5')\n",
    "        self.RB6 = self.RB(self.RB5, 'rb6')\n",
    "        self.RB7 = self.RB(self.RB6, 'rb7')\n",
    "        self.RB8 = self.RB(self.RB7, 'rb8')\n",
    "        self.RB9 = self.RB(self.RB8, 'rb9')\n",
    "        self.RB10 = self.RB(self.RB9, 'rb10')\n",
    "        self.RB11 = self.RB(self.RB10, 'rb11')\n",
    "        self.RB12 = self.RB(self.RB11, 'rb12')\n",
    "        self.RB13 = self.RB(self.RB12, 'rb13')\n",
    "        self.RB14 = self.RB(self.RB13, 'rb14')\n",
    "        self.RB15 = self.RB(self.RB14, 'rb15')\n",
    "        self.RB16 = self.RB(self.RB15, 'rb16')\n",
    "        \n",
    "        with slim.arg_scope([slim.conv2d], kernel_size=[3,3], stride=[1,1], activation_fn=None, padding='SAME', \n",
    "                           weights_initializer=tf.contrib.layers.xavier_initializer()):\n",
    "            self.conv2 = slim.conv2d(inputs=self.RB16, num_outputs=64)\n",
    "            self.residual = tf.add(self.conv1, self.conv1)\n",
    "            self.conv3 = slim.conv2d(inputs=self.residual, num_outputs=4)\n",
    "        \n",
    "            self.ps = PS(self.conv3, 2, False)\n",
    "            self.conv4 = slim.conv2d(inputs=self.ps, num_outputs=1)\n",
    "        \n",
    "        out = self.conv4\n",
    "        return out\n",
    "    \n",
    "    def loss(self, SR, HR):\n",
    "        #loss = tf.losses.absolute_difference(SR, HR)\n",
    "        loss =tf.reduce_mean(tf.square(SR - HR))#\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def build(self):\n",
    "        if self.mode == 'bicubic':\n",
    "            self.LRImg = tf.placeholder(tf.float32, [None, 28, 28, 1], 'LRImgBicubic')\n",
    "        elif self.mode == 'pixelshuffle':\n",
    "            self.LRImg = tf.placeholder(tf.float32, [None, 14, 14, 1], 'LRImgPixelShuffle')\n",
    "        else:\n",
    "            print ('undefined mode')\n",
    "        self.HRImg = tf.placeholder(tf.float32, [None, 28, 28, 1], 'HRImg')\n",
    "        self.SRImg = self.model(self.LRImg)\n",
    "        self.LOSS = self.loss(self.SRImg, self.HRImg)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def _phase_shift(I, r):\n",
    "        # Helper function with main phase shift operation\n",
    "        bsize, a, b, c = I.get_shape().as_list()\n",
    "        X = tf.reshape(I, (bsize, a, b, r, r))\n",
    "        X = tf.transpose(X, (0, 1, 2, 4, 3))  # bsize, a, b, 1, 1\n",
    "        X = tf.split(X, a, 1)  # a, [bsize, b, r, r]\n",
    "        X = tf.concat([tf.squeeze(x) for x in X], asix=2)  # bsize, b, a*r, r\n",
    "        X = tf.split(X, b, 1)  # b, [bsize, a*r, r]\n",
    "        X = tf.concat([tf.squeeze(x) for x in X], axis=2)  # bsize, a*r, b*r\n",
    "        return tf.reshape(X, (bsize, a*r, b*r, 1))\n",
    "\n",
    "    def PS(X, r, color=False):\n",
    "      # Main OP that you can arbitrarily use in you tensorflow code\n",
    "        if color:\n",
    "            Xc = tf.split(X,3,3) #(3, 3, X)\n",
    "            X = tf.concat([_phase_shift(x, r) for x in Xc], axis=3)\n",
    "        else:\n",
    "            X = _phase_shift(X, r)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is generated\n",
      "---------\n",
      "Variables: name (type shape) [size]\n",
      "---------\n",
      "Conv/weights:0 (float32_ref 3x3x1x64) [576, bytes: 2304]\n",
      "Conv/biases:0 (float32_ref 64) [64, bytes: 256]\n",
      "rb1-conv1/weights:0 (float32_ref 3x3x64x64) [36864, bytes: 147456]\n",
      "rb1-conv1/biases:0 (float32_ref 64) [64, bytes: 256]\n",
      "rb1-conv2/weights:0 (float32_ref 3x3x64x64) [36864, bytes: 147456]\n",
      "rb1-conv2/biases:0 (float32_ref 64) [64, bytes: 256]\n",
      "rb2-conv1/weights:0 (float32_ref 3x3x64x64) [36864, bytes: 147456]\n",
      "rb2-conv1/biases:0 (float32_ref 64) [64, bytes: 256]\n",
      "rb2-conv2/weights:0 (float32_ref 3x3x64x64) [36864, bytes: 147456]\n",
      "rb2-conv2/biases:0 (float32_ref 64) [64, bytes: 256]\n",
      "rb3-conv1/weights:0 (float32_ref 3x3x64x64) [36864, bytes: 147456]\n",
      "rb3-conv1/biases:0 (float32_ref 64) [64, bytes: 256]\n",
      "rb3-conv2/weights:0 (float32_ref 3x3x64x64) [36864, bytes: 147456]\n",
      "rb3-conv2/biases:0 (float32_ref 64) [64, bytes: 256]\n",
      "rb4-conv1/weights:0 (float32_ref 3x3x64x64) [36864, bytes: 147456]\n",
      "rb4-conv1/biases:0 (float32_ref 64) [64, bytes: 256]\n",
      "rb4-conv2/weights:0 (float32_ref 3x3x64x64) [36864, bytes: 147456]\n",
      "rb4-conv2/biases:0 (float32_ref 64) [64, bytes: 256]\n",
      "rb5-conv1/weights:0 (float32_ref 3x3x64x64) [36864, bytes: 147456]\n",
      "rb5-conv1/biases:0 (float32_ref 64) [64, bytes: 256]\n",
      "rb5-conv2/weights:0 (float32_ref 3x3x64x64) [36864, bytes: 147456]\n",
      "rb5-conv2/biases:0 (float32_ref 64) [64, bytes: 256]\n",
      "rb6-conv1/weights:0 (float32_ref 3x3x64x64) [36864, bytes: 147456]\n",
      "rb6-conv1/biases:0 (float32_ref 64) [64, bytes: 256]\n",
      "rb6-conv2/weights:0 (float32_ref 3x3x64x64) [36864, bytes: 147456]\n",
      "rb6-conv2/biases:0 (float32_ref 64) [64, bytes: 256]\n",
      "rb7-conv1/weights:0 (float32_ref 3x3x64x64) [36864, bytes: 147456]\n",
      "rb7-conv1/biases:0 (float32_ref 64) [64, bytes: 256]\n",
      "rb7-conv2/weights:0 (float32_ref 3x3x64x64) [36864, bytes: 147456]\n",
      "rb7-conv2/biases:0 (float32_ref 64) [64, bytes: 256]\n",
      "rb8-conv1/weights:0 (float32_ref 3x3x64x64) [36864, bytes: 147456]\n",
      "rb8-conv1/biases:0 (float32_ref 64) [64, bytes: 256]\n",
      "rb8-conv2/weights:0 (float32_ref 3x3x64x64) [36864, bytes: 147456]\n",
      "rb8-conv2/biases:0 (float32_ref 64) [64, bytes: 256]\n",
      "rb9-conv1/weights:0 (float32_ref 3x3x64x64) [36864, bytes: 147456]\n",
      "rb9-conv1/biases:0 (float32_ref 64) [64, bytes: 256]\n",
      "rb9-conv2/weights:0 (float32_ref 3x3x64x64) [36864, bytes: 147456]\n",
      "rb9-conv2/biases:0 (float32_ref 64) [64, bytes: 256]\n",
      "rb10-conv1/weights:0 (float32_ref 3x3x64x64) [36864, bytes: 147456]\n",
      "rb10-conv1/biases:0 (float32_ref 64) [64, bytes: 256]\n",
      "rb10-conv2/weights:0 (float32_ref 3x3x64x64) [36864, bytes: 147456]\n",
      "rb10-conv2/biases:0 (float32_ref 64) [64, bytes: 256]\n",
      "rb11-conv1/weights:0 (float32_ref 3x3x64x64) [36864, bytes: 147456]\n",
      "rb11-conv1/biases:0 (float32_ref 64) [64, bytes: 256]\n",
      "rb11-conv2/weights:0 (float32_ref 3x3x64x64) [36864, bytes: 147456]\n",
      "rb11-conv2/biases:0 (float32_ref 64) [64, bytes: 256]\n",
      "rb12-conv1/weights:0 (float32_ref 3x3x64x64) [36864, bytes: 147456]\n",
      "rb12-conv1/biases:0 (float32_ref 64) [64, bytes: 256]\n",
      "rb12-conv2/weights:0 (float32_ref 3x3x64x64) [36864, bytes: 147456]\n",
      "rb12-conv2/biases:0 (float32_ref 64) [64, bytes: 256]\n",
      "rb13-conv1/weights:0 (float32_ref 3x3x64x64) [36864, bytes: 147456]\n",
      "rb13-conv1/biases:0 (float32_ref 64) [64, bytes: 256]\n",
      "rb13-conv2/weights:0 (float32_ref 3x3x64x64) [36864, bytes: 147456]\n",
      "rb13-conv2/biases:0 (float32_ref 64) [64, bytes: 256]\n",
      "rb14-conv1/weights:0 (float32_ref 3x3x64x64) [36864, bytes: 147456]\n",
      "rb14-conv1/biases:0 (float32_ref 64) [64, bytes: 256]\n",
      "rb14-conv2/weights:0 (float32_ref 3x3x64x64) [36864, bytes: 147456]\n",
      "rb14-conv2/biases:0 (float32_ref 64) [64, bytes: 256]\n",
      "rb15-conv1/weights:0 (float32_ref 3x3x64x64) [36864, bytes: 147456]\n",
      "rb15-conv1/biases:0 (float32_ref 64) [64, bytes: 256]\n",
      "rb15-conv2/weights:0 (float32_ref 3x3x64x64) [36864, bytes: 147456]\n",
      "rb15-conv2/biases:0 (float32_ref 64) [64, bytes: 256]\n",
      "rb16-conv1/weights:0 (float32_ref 3x3x64x64) [36864, bytes: 147456]\n",
      "rb16-conv1/biases:0 (float32_ref 64) [64, bytes: 256]\n",
      "rb16-conv2/weights:0 (float32_ref 3x3x64x64) [36864, bytes: 147456]\n",
      "rb16-conv2/biases:0 (float32_ref 64) [64, bytes: 256]\n",
      "Conv_1/weights:0 (float32_ref 3x3x64x64) [36864, bytes: 147456]\n",
      "Conv_1/biases:0 (float32_ref 64) [64, bytes: 256]\n",
      "Conv_2/weights:0 (float32_ref 3x3x64x4) [2304, bytes: 9216]\n",
      "Conv_2/biases:0 (float32_ref 4) [4, bytes: 16]\n",
      "Conv_3/weights:0 (float32_ref 3x3x1x1) [9, bytes: 36]\n",
      "Conv_3/biases:0 (float32_ref 1) [1, bytes: 4]\n",
      "Total size of variables: 1221582\n",
      "Total bytes of variables: 4886328\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1221582, 4886328)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "model = CVLab('pixelshuffle')\n",
    "model.build()\n",
    "\n",
    "t_vars = tf.trainable_variables()\n",
    "slim.model_analyzer.analyze_vars(t_vars, print_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "learning_rate=tf.placeholder(tf.float32, shape=[])\n",
    "optm = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(model.LOSS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config) \n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "saver=tf.train.Saver()\n",
    "#saver.restore(sess, 'checkpoints/SRCNN/MNIST_psnr_21-09')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/scipy/misc/pilutil.py:482: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if issubdtype(ts, int):\n",
      "/usr/local/lib/python3.5/dist-packages/scipy/misc/pilutil.py:485: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  elif issubdtype(type(size), float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   0, avg_PSNR: 8.729271, time for epoch: 34.36\n",
      "epoch:   1, avg_PSNR: 17.951242, time for epoch: 33.88\n",
      "epoch:   2, avg_PSNR: 19.512859, time for epoch: 33.79\n",
      "epoch:   3, avg_PSNR: 20.321439, time for epoch: 33.76\n",
      "epoch:   4, avg_PSNR: 20.645167, time for epoch: 33.64\n",
      "epoch:   5, avg_PSNR: 20.879574, time for epoch: 33.69\n",
      "epoch:   6, avg_PSNR: 20.962673, time for epoch: 33.78\n",
      "epoch:   7, avg_PSNR: 21.042132, time for epoch: 33.68\n",
      "epoch:   8, avg_PSNR: 21.063483, time for epoch: 33.71\n",
      "epoch:   9, avg_PSNR: 21.096282, time for epoch: 33.67\n",
      "epoch:  10, avg_PSNR: 21.108185, time for epoch: 33.58\n",
      "epoch:  11, avg_PSNR: 21.123264, time for epoch: 33.80\n",
      "epoch:  12, avg_PSNR: 21.130716, time for epoch: 33.92\n",
      "epoch:  13, avg_PSNR: 21.139215, time for epoch: 33.81\n",
      "epoch:  14, avg_PSNR: 21.130944, time for epoch: 33.82\n",
      "epoch:  15, avg_PSNR: 21.147092, time for epoch: 33.91\n",
      "epoch:  16, avg_PSNR: 21.144146, time for epoch: 33.85\n",
      "epoch:  17, avg_PSNR: 21.146582, time for epoch: 33.89\n",
      "epoch:  18, avg_PSNR: 21.150012, time for epoch: 33.78\n",
      "epoch:  19, avg_PSNR: 21.146514, time for epoch: 33.73\n",
      "epoch:  20, avg_PSNR: 21.144393, time for epoch: 33.55\n",
      "epoch:  21, avg_PSNR: 21.151678, time for epoch: 33.69\n",
      "epoch:  22, avg_PSNR: 21.147082, time for epoch: 33.69\n",
      "epoch:  23, avg_PSNR: 21.152259, time for epoch: 33.71\n",
      "epoch:  24, avg_PSNR: 21.149063, time for epoch: 33.85\n",
      "epoch:  25, avg_PSNR: 21.154235, time for epoch: 33.66\n",
      "epoch:  26, avg_PSNR: 21.141024, time for epoch: 33.75\n",
      "epoch:  27, avg_PSNR: 21.159437, time for epoch: 33.82\n",
      "epoch:  28, avg_PSNR: 21.141896, time for epoch: 33.87\n",
      "epoch:  29, avg_PSNR: 21.150423, time for epoch: 33.90\n",
      "epoch:  30, avg_PSNR: 21.148324, time for epoch: 33.81\n",
      "epoch:  31, avg_PSNR: 21.153166, time for epoch: 33.82\n",
      "epoch:  32, avg_PSNR: 21.149818, time for epoch: 33.87\n",
      "epoch:  33, avg_PSNR: 21.150105, time for epoch: 33.95\n",
      "epoch:  34, avg_PSNR: 21.153437, time for epoch: 33.81\n",
      "epoch:  35, avg_PSNR: 21.150601, time for epoch: 33.76\n",
      "epoch:  36, avg_PSNR: 21.143575, time for epoch: 34.11\n",
      "epoch:  37, avg_PSNR: 21.154518, time for epoch: 33.81\n",
      "epoch:  38, avg_PSNR: 21.145265, time for epoch: 33.86\n",
      "epoch:  39, avg_PSNR: 21.152597, time for epoch: 34.19\n",
      "epoch:  40, avg_PSNR: 21.142907, time for epoch: 33.88\n",
      "epoch:  41, avg_PSNR: 21.154872, time for epoch: 33.88\n",
      "epoch:  42, avg_PSNR: 21.145761, time for epoch: 34.12\n",
      "epoch:  43, avg_PSNR: 21.151970, time for epoch: 33.81\n",
      "epoch:  44, avg_PSNR: 21.148841, time for epoch: 33.82\n",
      "epoch:  45, avg_PSNR: 21.154729, time for epoch: 33.94\n",
      "epoch:  46, avg_PSNR: 21.145774, time for epoch: 33.94\n",
      "epoch:  47, avg_PSNR: 21.150413, time for epoch: 33.95\n",
      "epoch:  48, avg_PSNR: 21.149870, time for epoch: 33.89\n",
      "epoch:  49, avg_PSNR: 21.150267, time for epoch: 33.94\n",
      "epoch:  50, avg_PSNR: 21.147590, time for epoch: 33.88\n",
      "epoch:  51, avg_PSNR: 21.149620, time for epoch: 33.82\n",
      "epoch:  52, avg_PSNR: 21.150436, time for epoch: 33.87\n",
      "epoch:  53, avg_PSNR: 21.147366, time for epoch: 33.65\n",
      "epoch:  54, avg_PSNR: 21.152665, time for epoch: 34.12\n",
      "epoch:  55, avg_PSNR: 21.147608, time for epoch: 34.05\n",
      "epoch:  56, avg_PSNR: 21.148949, time for epoch: 33.94\n",
      "epoch:  57, avg_PSNR: 21.145098, time for epoch: 33.98\n",
      "epoch:  58, avg_PSNR: 21.156224, time for epoch: 33.77\n",
      "epoch:  59, avg_PSNR: 21.136459, time for epoch: 34.05\n",
      "epoch:  60, avg_PSNR: 21.164594, time for epoch: 33.95\n",
      "epoch:  61, avg_PSNR: 21.144787, time for epoch: 34.10\n",
      "epoch:  62, avg_PSNR: 21.154076, time for epoch: 34.03\n",
      "epoch:  63, avg_PSNR: 21.149355, time for epoch: 34.05\n",
      "epoch:  64, avg_PSNR: 21.147884, time for epoch: 33.84\n",
      "epoch:  65, avg_PSNR: 21.151896, time for epoch: 33.84\n",
      "epoch:  66, avg_PSNR: 21.152215, time for epoch: 34.08\n",
      "epoch:  67, avg_PSNR: 21.146795, time for epoch: 33.82\n",
      "epoch:  68, avg_PSNR: 21.149390, time for epoch: 33.97\n",
      "epoch:  69, avg_PSNR: 21.147674, time for epoch: 33.80\n",
      "epoch:  70, avg_PSNR: 21.157075, time for epoch: 33.90\n",
      "epoch:  71, avg_PSNR: 21.144309, time for epoch: 33.75\n",
      "epoch:  72, avg_PSNR: 21.149645, time for epoch: 33.77\n",
      "epoch:  73, avg_PSNR: 21.153756, time for epoch: 34.11\n",
      "epoch:  74, avg_PSNR: 21.149130, time for epoch: 33.82\n",
      "epoch:  75, avg_PSNR: 21.146591, time for epoch: 34.02\n",
      "epoch:  76, avg_PSNR: 21.149822, time for epoch: 33.71\n",
      "epoch:  77, avg_PSNR: 21.144266, time for epoch: 33.94\n",
      "epoch:  78, avg_PSNR: 21.155095, time for epoch: 33.72\n",
      "epoch:  79, avg_PSNR: 21.145725, time for epoch: 33.96\n",
      "epoch:  80, avg_PSNR: 21.155867, time for epoch: 33.96\n",
      "batch: 5337/6249 (85.4%) psnr: 20.00479"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-185be4146f88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mtrImg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mtrImg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrImg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mLRImg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrImg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.11\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mHRImg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrImg\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m0.11\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mcnt\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-8e21901b3f96>\u001b[0m in \u001b[0;36mtoLR\u001b[0;34m(image, scale)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'bicubic'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/scipy/misc/pilutil.py\u001b[0m in \u001b[0;36mimresize\u001b[0;34m(arr, size, interp, mode)\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpercent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0missubdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m         \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size=8\n",
    "total_iter = int(trImg.shape[0]/batch_size)-1\n",
    "lr=1e-4\n",
    "for epoch in range(500):\n",
    "    avg_psnr = 0\n",
    "    cnt=0\n",
    "    start_time = time.time()\n",
    "    for batch in range(total_iter):\n",
    "        trImg, _= mnist.train.next_batch(batch_size)\n",
    "        trImg = np.reshape(trImg, [-1, 28, 28, 1])\n",
    "        LRImg = toLR(trImg)-0.11\n",
    "        HRImg = trImg - 0.11\n",
    "        cnt+=1\n",
    "        \n",
    "        _, loss = sess.run([optm, model.LOSS], feed_dict={model.LRImg:LRImg, model.HRImg: HRImg, learning_rate:lr})\n",
    "        psnr = 20*np.log10(1./np.sqrt(loss))\n",
    "        print (\"\\rbatch: {}/{} ({:.1f}%) psnr: {:.5f}\".format(batch, total_iter, batch*100/total_iter, psnr), end=\"\")\n",
    "        avg_psnr+=psnr\n",
    "    if epoch%2==0:\n",
    "        lr*=0.5\n",
    "    print ('\\repoch: %3d, avg_PSNR: %4f, time for epoch: %.2f' %(epoch, avg_psnr/(cnt+1e-8), time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/scipy/misc/pilutil.py:482: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if issubdtype(ts, int):\n",
      "/usr/local/lib/python3.5/dist-packages/scipy/misc/pilutil.py:485: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  elif issubdtype(type(size), float):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fbd0c8187f0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbd0cbe5cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "showimg = mnist.test.images[0:32,:]-0.11\n",
    "hrimg = np.reshape(showimg, [-1, 28, 28, 1])\n",
    "lrimg = toLR(hrimg)\n",
    "srimg=sess.run(model.conv4, feed_dict={model.LRImg:lrimg})\n",
    "index=3\n",
    "\n",
    "plt.figure(figsize=[20,5])\n",
    "plt.subplot(1,3,1)\n",
    "plt.axis('off')\n",
    "plt.title('LR')\n",
    "plt.imshow(lrimg[index,:,:,0], cmap='gray')\n",
    "plt.subplot(1,3,2)\n",
    "plt.axis('off')\n",
    "plt.title('HR')\n",
    "plt.imshow(hrimg[index,:,:,0], cmap='gray')\n",
    "plt.subplot(1,3,3)\n",
    "plt.axis('off')\n",
    "plt.title('SR')\n",
    "plt.imshow(srimg[index,:,:,0], cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/scipy/misc/pilutil.py:482: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if issubdtype(ts, int):\n",
      "/usr/local/lib/python3.5/dist-packages/scipy/misc/pilutil.py:485: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  elif issubdtype(type(size), float):\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'CVLab' object has no attribute 'out_layer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-f63d4721e80a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mhrimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshowimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlrimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhrimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msrimg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLRImg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlrimg\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'CVLab' object has no attribute 'out_layer'"
     ]
    }
   ],
   "source": [
    "showimg = mnist.test.images[0:32,:]\n",
    "hrimg = np.reshape(showimg, [-1, 28, 28, 1])\n",
    "lrimg = toLR(hrimg)\n",
    "srimg=sess.run(model.out_layer, feed_dict={model.LRImg:lrimg})\n",
    "index=3\n",
    "\n",
    "plt.figure(figsize=[20,5])\n",
    "plt.subplot(1,3,1)\n",
    "plt.axis('off')\n",
    "plt.title('LR')\n",
    "plt.imshow(lrimg[index,:,:,0], cmap='gray')\n",
    "plt.subplot(1,3,2)\n",
    "plt.axis('off')\n",
    "plt.title('HR')\n",
    "plt.imshow(hrimg[index,:,:,0], cmap='gray')\n",
    "plt.subplot(1,3,3)\n",
    "plt.axis('off')\n",
    "plt.title('SR')\n",
    "plt.imshow(srimg[index,:,:,0], cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'checkpoints/SRCNN/MNIST_psnr_21-09'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "saver.save(sess, 'checkpoints/SRCNN/MNIST_psnr_21-09')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with slim.arg_scope([slim.conv2d], num_outputs=64, kernel_size=[5,5], stride=[1,1], activation_fn = tf.nn.relu, padding='SAME',\n",
    "                                                   weights_initializer=tf.contrib.layers.xavier_initializer()):\n",
    "            self.layer1 = slim.conv2d(inputs=self.conv1, scope='1conv1')\n",
    "            self.layer2 = slim.conv2d(inputs=self.layer1, activation_fn=None, scope=name+'1conv2')\n",
    "            self.layer3 = tf.add(self.layer2, self.conv1, name=name+'1residual')\n",
    "            \n",
    "            self.layer21 = slim.conv2d(inputs=self.layer3, scope='2convtg1')\n",
    "            self.layer22 = slim.conv2d(inputs=self.layer21, activation_fn=None, scope=name+'2conv2')\n",
    "            self.layer23 = tf.add(self.layer22, self.layer3, name=name+'2residual')\n",
    "        \n",
    "            self.layer31 = slim.conv2d(inputs=self.layer23, scope='32conv1')\n",
    "            self.layer32 = slim.conv2d(inputs=self.layer31, activation_fn=None, scope=name+'32conv2')\n",
    "            self.layer33 = tf.add(self.layer32, self.layer23, name=name+'32residual')\n",
    "            \n",
    "            self.layer41 = slim.conv2d(inputs=self.layer33, scope='42conv1')\n",
    "            self.layer42 = slim.conv2d(inputs=self.layer41, activation_fn=None, scope=name+'42conv2')\n",
    "            self.layer43 = tf.add(self.layer42, self.layer33, name=name+'42residual')\n",
    "            \n",
    "            self.layer51 = slim.conv2d(inputs=self.layer43, scope='52conv1')\n",
    "            self.layer52 = slim.conv2d(inputs=self.layer51, activation_fn=None, scope=name+'52conv2')\n",
    "            self.layer53 = tf.add(self.layer52, self.layer43, name=name+'52residual')\n",
    "            \n",
    "            self.layer61 = slim.conv2d(inputs=self.layer53, scope='62conv1')\n",
    "            self.layer62 = slim.conv2d(inputs=self.layer61, activation_fn=None, scope=name+'62conv2')\n",
    "            self.layer63 = tf.add(self.layer62, self.layer53, name=name+'62residual')\n",
    "            \n",
    "            self.layer71 = slim.conv2d(inputs=self.layer63, scope='72conv1')\n",
    "            self.layer72 = slim.conv2d(inputs=self.layer71, activation_fn=None, scope=name+'72conv2')\n",
    "            self.layer73 = tf.add(self.layer72, self.layer63, name=name+'72residual')\n",
    "            \n",
    "            self.layer81 = slim.conv2d(inputs=self.layer73, scope='82conv1')\n",
    "            self.layer82 = slim.conv2d(inputs=self.layer81, activation_fn=None, scope=name+'82conv2')\n",
    "            self.layer83 = tf.add(self.layer82, self.layer73, name=name+'82residual')\n",
    "            \n",
    "            self.layer91 = slim.conv2d(inputs=self.layer83, scope='92conv1')\n",
    "            self.layer92 = slim.conv2d(inputs=self.layer91, activation_fn=None, scope=name+'92conv2')\n",
    "            self.layer93 = tf.add(self.layer92, self.layer83, name=name+'92residual')\n",
    "            \n",
    "            self.layer101 = slim.conv2d(inputs=self.layer93, scope='102conv1')\n",
    "            self.layer102 = slim.conv2d(inputs=self.layer101, activation_fn=None, scope=name+'102conv2')\n",
    "            self.layer103 = tf.add(self.layer102, self.layer93, name=name+'102residual')\n",
    "            \n",
    "            self.layer111 = slim.conv2d(inputs=self.layer103, scope='112conv1')\n",
    "            self.layer112 = slim.conv2d(inputs=self.layer111, activation_fn=None, scope=name+'112conv2')\n",
    "            self.layer113 = tf.add(self.layer112, self.layer103, name=name+'112residual')\n",
    "            \n",
    "            self.layer121 = slim.conv2d(inputs=self.layer113, scope='122conv1')\n",
    "            self.layer122 = slim.conv2d(inputs=self.layer121, activation_fn=None, scope=name+'122conv2')\n",
    "            self.layer123 = tf.add(self.layer122, self.layer113, name=name+'212residual')\n",
    "            \n",
    "            self.layer131 = slim.conv2d(inputs=self.layer123, scope='132conv1')\n",
    "            self.layer132 = slim.conv2d(inputs=self.layer131, activation_fn=None, scope=name+'132conv2')\n",
    "            self.layer133 = tf.add(self.layer132, self.layer123, name=name+'132residual')\n",
    "            \n",
    "            self.layer141 = slim.conv2d(inputs=self.layer133, scope='2conv1')\n",
    "            self.layer142 = slim.conv2d(inputs=self.layer141, activation_fn=None, scope=name+'142conv2')\n",
    "            self.layer143 = tf.add(self.layer142, self.layer133, name=name+'142residual')\n",
    "            \n",
    "            self.layer151 = slim.conv2d(inputs=self.layer143, scope='152conv1')\n",
    "            self.layer152 = slim.conv2d(inputs=self.layer151, activation_fn=None, scope=name+'152conv2')\n",
    "            self.layer153 = tf.add(self.layer152, self.layer143, name=name+'152residual')\n",
    "            \n",
    "            self.layer161 = slim.conv2d(inputs=self.layer153, scope='162conv1')\n",
    "            self.layer162 = slim.conv2d(inputs=self.layer161, activation_fn=None, scope=name+'162conv2')\n",
    "            self.layer163 = tf.add(self.layer162, self.layer153, name=name+'216residual')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
