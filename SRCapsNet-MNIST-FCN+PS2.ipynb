{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SRCapsNet - FCN + PS(MNIST)\n",
    "![image](https://i.imgur.com/FWPkxI5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "routing 2번\n",
    "--> 3번으로 늘리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "Training data set : 50000, Test data Set : 10000\n"
     ]
    }
   ],
   "source": [
    "import os, sys, time\n",
    "import numpy as np\n",
    "import scipy.ndimage, scipy.misc\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "slim = tf.contrib.slim\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"\n",
    "\n",
    "\n",
    "\n",
    "def unpickle(file):\n",
    "    with open(file, 'rb') as f:\n",
    "        data = pickle.load(f, encoding='latin1')\n",
    "        return data\n",
    "\n",
    "def load_cifar10_data(data_dir):\n",
    "    train_data = None\n",
    "    train_labels = []\n",
    "    \n",
    "    for i in range(1,6):\n",
    "        data_dic = unpickle(data_dir + \"/data_batch_{}\".format(i))\n",
    "        if i==1:\n",
    "            train_data = data_dic['data']\n",
    "        else:\n",
    "            train_data = np.vstack((train_data, data_dic['data']))\n",
    "        train_labels += data_dic['labels']\n",
    "    test_data_dic = unpickle(data_dir + \"/test_batch\")\n",
    "    test_data = test_data_dic['data']\n",
    "    test_labels = test_data_dic['labels']\n",
    "    \n",
    "    train_data = train_data.reshape((len(train_data), 3, 32, 32))\n",
    "    train_data = np.rollaxis(train_data, 1, 4)\n",
    "    train_labels = np.array(train_labels)\n",
    "    \n",
    "    test_data = test_data.reshape((len(test_data), 3, 32, 32))\n",
    "    test_data = np.rollaxis(test_data, 1, 4)\n",
    "    test_labels = np.array(test_labels)\n",
    "    \n",
    "    return train_data, train_labels, test_data, test_labels\n",
    "\n",
    "data_dir = '/ideaHome/Dropbox/SJ/ML/Cifar10/Data/cifar-10-batches-py'\n",
    "trImg, train_labels, teImg, test_labels = load_cifar10_data(data_dir)\n",
    "\n",
    "\n",
    "print(\"Training data set : %3d, Test data Set : %3d\" %(trImg.shape[0], teImg.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-8bf8ae5a5303>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def toLR(image, scale=2.):\n",
    "    if len(image.shape)==4:\n",
    "        num_sample = image.shape[0]\n",
    "        images = np.zeros([image.shape[0], int(image.shape[1]/scale), int(image.shape[2]/scale), image.shape[3]])\n",
    "        for i in range(num_sample):\n",
    "            images[i,:,:,0] = scipy.misc.imresize(image[i,:,:,0], 1/scale,'bicubic')\n",
    "        return images\n",
    "    else:\n",
    "        return scipy.misc.imresize(image, 1/scale, 'bicubic')\n",
    "    \n",
    "\n",
    "def Bicubic(image, scale=2):\n",
    "    if len(image.shape)==4:\n",
    "        bicImg = scipy.ndimage.interpolation.zoom(image, [1, scale, scale, 1], prefilter=False)\n",
    "    else:\n",
    "        bicImg = scipy.ndimage.interpolation.zoom(image, [scale,scale, 1], prefilter=False)\n",
    "    return bicImg\n",
    "\n",
    "def _phase_shift(I, r):\n",
    "    # Helper function with main phase shift operation\n",
    "    bsize, a, b, c = I.get_shape().as_list()\n",
    "    X = tf.reshape(I, (-1, a, b, r, r))\n",
    "    X = tf.transpose(X, (0, 1, 2, 4, 3))  # bsize, a, b, 1, 1\n",
    "    X = tf.split(X, a, 1)  # a, [bsize, b, r, r]\n",
    "    X = tf.concat([tf.squeeze(x) for x in X], axis=2)  # bsize, b, a*r, r\n",
    "    X = tf.split(X, b, 1)  # b, [bsize, a*r, r]\n",
    "    X = tf.concat([tf.squeeze(x) for x in X], axis=2)  # bsize, a*r, b*r\n",
    "    return tf.reshape(X, (-1, a*r, b*r, 1))\n",
    "\n",
    "def PS(X, r, color=False):\n",
    "  # Main OP that you can arbitrarily use in you tensorflow code\n",
    "    if color:\n",
    "        Xc = tf.split(X,3,3) #(3, 3, X)\n",
    "        X = tf.concat([_phase_shift(x, r) for x in Xc], axis=3)\n",
    "    else:\n",
    "        X = _phase_shift(X, r)\n",
    "    return X\n",
    "\n",
    "def squash(s, axis=-1, epsilon=1e-7, name=None):\n",
    "    with tf.name_scope(name, default_name=\"squash\"):\n",
    "        squared_norm = tf.reduce_sum(tf.square(s), axis=axis, keep_dims=True)\n",
    "        safe_norm = tf.sqrt(squared_norm + epsilon)\n",
    "        squash_factor = squared_norm / (1. + squared_norm)\n",
    "        unit_vector = s / safe_norm\n",
    "    return squash_factor * unit_vector\n",
    "\n",
    "def safe_norm(s, axis=-1, epsilon=1e-7, keep_dims=False, name=None):\n",
    "    with tf.name_scope(name, default_name=\"safe_norm\"):\n",
    "        squared_norm = tf.reduce_sum(tf.square(s), axis=axis,\n",
    "                                     keep_dims=keep_dims)\n",
    "        return tf.sqrt(squared_norm + epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/scipy/misc/pilutil.py:482: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if issubdtype(ts, int):\n",
      "/usr/local/lib/python3.5/dist-packages/scipy/misc/pilutil.py:485: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  elif issubdtype(type(size), float):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7faa9de328d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faaa5f119e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "testSample = np.reshape(mnist.train.images[0,:], [1,28,28,1])\n",
    "\n",
    "LRtestSample = toLR(testSample)\n",
    "\n",
    "UPtestSample = Bicubic(LRtestSample, 2)\n",
    "plt.figure(figsize=[20.,10])\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(testSample[0,:,:,0], cmap='gray')\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(LRtestSample[0,:,:,0], cmap='gray')\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(UPtestSample[0,:,:,0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SRCapsNet(object):\n",
    "    def __init__(self, mode):\n",
    "        self.LR_dim = (None, 28,28,1)\n",
    "        self.HR_dim = (None, 28,28,1)\n",
    "        self.batch_size = 32\n",
    "        self.mode = mode\n",
    "        \n",
    "        self.routing_iter = 2\n",
    "        self.caps1_num = 3*3*32\n",
    "        self.caps1_dim = 8\n",
    "        self.caps2_vec = 10\n",
    "        self.caps2_num = 1*1*self.caps2_vec\n",
    "        self.caps2_dim = 16\n",
    "        \n",
    "        self.W_init = tf.random_normal(shape=(1, self.caps1_num, self.caps2_num, self.caps2_dim, self.caps1_dim), \n",
    "                                      stddev = 0.1, dtype=tf.float32, name='W_init')\n",
    "        self.W = tf.Variable(self.W_init, name='w')\n",
    "        \n",
    "        print('The model is generated')\n",
    "        \n",
    "    def model(self, img):\n",
    "        with slim.arg_scope([slim.conv2d],kernel_size=[5,5], stride=[1,1], activation_fn = tf.nn.leaky_relu,\n",
    "                            padding='valid',weights_initializer=tf.contrib.layers.xavier_initializer()):\n",
    "            \n",
    "            self.conv1 = slim.conv2d(inputs=img, num_outputs=256, scope='conv1')\n",
    "            print(self.conv1)\n",
    "            self.conv2 = slim.conv2d(inputs=self.conv1, num_outputs=256,stride=[2,2], scope='conv2')\n",
    "        batch_size = tf.shape(img)[0]    \n",
    "        self.caps1 = tf.reshape(self.conv2, [batch_size, self.caps1_num, self.caps1_dim], name='caps1')\n",
    "        self.caps1_squash = squash(self.caps1, name='caps1_squash')\n",
    "            \n",
    "            \n",
    "        self.W_tiled = tf.tile(self.W, [batch_size, 1, 1, 1, 1], name='W_tiled')\n",
    "            \n",
    "        self.caps1_expanded = tf.expand_dims(self.caps1_squash, -1, name='caps1_expanded')\n",
    "        self.caps1_expanded2 = tf.expand_dims(self.caps1_expanded, 2, name='caps1_expanded2')\n",
    "        self.caps1_tiled = tf.tile(self.caps1_expanded2, [1, 1, self.caps2_num, 1, 1], name='caps1_tiled')\n",
    "        self.caps2_in = tf.matmul(self.W_tiled, self.caps1_tiled, name='caps2_in')\n",
    "        self.b_ij = tf.zeros([batch_size, self.caps1_num, self.caps2_num, 1, 1], name='b_ij')\n",
    "        for i in range(self.routing_iter):\n",
    "            if i>0:\n",
    "                self.b_ij = tf.add(self.b_ij, agreement)\n",
    "            self.c_ij = tf.nn.softmax(self.b_ij, dim=2, name='c_ij')\n",
    "            self.s_j = tf.reduce_sum(tf.multiply(self.c_ij, self.caps2_in), axis=1, keep_dims=True, name='s_j')\n",
    "            self.v_j = squash(self.s_j, axis=-2, name='v_j')\n",
    "            if i<self.routing_iter-1:\n",
    "                self.v_j_tiled = tf.tile(self.v_j, [1, self.caps1_num, 1, 1, 1], name='v_j_tiled')\n",
    "                agreement = tf.matmul(self.caps2_in, self.v_j_tiled, transpose_a=True, name='agreement')\n",
    "\n",
    "        self.caps2_out = self.v_j\n",
    "        self.caps2_reshape = tf.reshape(self.caps2_out, [-1, 10*16], name='caps2_reshape')\n",
    "        self.fc1 = slim.fully_connected(inputs=self.caps2_reshape, num_outputs=256, activation_fn=tf.nn.relu, scope='fc1')\n",
    "        self.fc2 = slim.fully_connected(inputs=self.fc1, num_outputs=256, activation_fn=tf.nn.relu, scope='fc2')\n",
    "        self.fc3 = slim.fully_connected(inputs=self.fc2, num_outputs=196, activation_fn=tf.nn.sigmoid, scope='fc3')\n",
    "        self.for_PS = tf.reshape(self.fc3, [-1, 14, 14, 1])\n",
    "        self.conv3 = slim.conv2d(inputs=self.for_PS, num_outputs=4,kernel_size=[5,5], stride=[1,1],\n",
    "                                activation_fn=tf.nn.sigmoid, padding='same', scope='conv3')\n",
    "        self.out_layer = PS(self.conv3, 2, False)\n",
    "        #self.conv3 = slim.conv2d(inputs=self.caps2_reshape, num_outputs=12, scope='conv3', activation_fn=None)\n",
    "        #self.out_layer = PS(self.conv3, 2, True)\n",
    "\n",
    "        out = self.out_layer\n",
    "        return out\n",
    "    \n",
    "    def loss(self, SR, HR):\n",
    "        loss = tf.reduce_mean(tf.square(SR - HR), name='loss')\n",
    "        return loss\n",
    "    \n",
    "    def build(self):\n",
    "        if self.mode == 'bicubic':\n",
    "            self.LRImg = tf.placeholder(tf.float32, [None, 28, 28, 1], 'LRImgBicubic')\n",
    "        elif self.mode == 'pixelshuffle':\n",
    "            self.LRImg = tf.placeholder(tf.float32, [None, 14, 14, 1], 'LRImgPixelShuffle')\n",
    "        else:\n",
    "            print ('undefined mode')\n",
    "        self.HRImg = tf.placeholder(tf.float32, [None, 28, 28, 1], 'HRImg')\n",
    "        self.SRImg = self.model(self.LRImg)\n",
    "        self.LOSS = self.loss(self.SRImg, self.HRImg)\n",
    "    \n",
    "   \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is generated\n",
      "Tensor(\"conv1/LeakyRelu/Maximum:0\", shape=(?, 10, 10, 256), dtype=float32)\n",
      "WARNING:tensorflow:From <ipython-input-3-8e21901b3f96>:41: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From <ipython-input-5-147512e4ba7f>:43: calling softmax (from tensorflow.python.ops.nn_ops) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n",
      "---------\n",
      "Variables: name (type shape) [size]\n",
      "---------\n",
      "w:0 (float32_ref 1x288x10x16x8) [368640, bytes: 1474560]\n",
      "conv1/weights:0 (float32_ref 5x5x1x256) [6400, bytes: 25600]\n",
      "conv1/biases:0 (float32_ref 256) [256, bytes: 1024]\n",
      "conv2/weights:0 (float32_ref 5x5x256x256) [1638400, bytes: 6553600]\n",
      "conv2/biases:0 (float32_ref 256) [256, bytes: 1024]\n",
      "fc1/weights:0 (float32_ref 160x256) [40960, bytes: 163840]\n",
      "fc1/biases:0 (float32_ref 256) [256, bytes: 1024]\n",
      "fc2/weights:0 (float32_ref 256x256) [65536, bytes: 262144]\n",
      "fc2/biases:0 (float32_ref 256) [256, bytes: 1024]\n",
      "fc3/weights:0 (float32_ref 256x196) [50176, bytes: 200704]\n",
      "fc3/biases:0 (float32_ref 196) [196, bytes: 784]\n",
      "conv3/weights:0 (float32_ref 5x5x1x4) [100, bytes: 400]\n",
      "conv3/biases:0 (float32_ref 4) [4, bytes: 16]\n",
      "Total size of variables: 2171436\n",
      "Total bytes of variables: 8685744\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2171436, 8685744)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "model = SRCapsNet('pixelshuffle')\n",
    "model.build()\n",
    "\n",
    "t_vars = tf.trainable_variables()\n",
    "slim.model_analyzer.analyze_vars(t_vars, print_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optm = tf.train.AdamOptimizer(learning_rate=1e-3).minimize(model.LOSS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialization complete\n"
     ]
    }
   ],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config) \n",
    "sess.run(tf.global_variables_initializer())\n",
    "print('initialization complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/scipy/misc/pilutil.py:482: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if issubdtype(ts, int):\n",
      "/usr/local/lib/python3.5/dist-packages/scipy/misc/pilutil.py:485: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  elif issubdtype(type(size), float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   0, avg_PSNR: 12.255308, time: 79.7\n",
      "epoch:   1, avg_PSNR: 15.737684, time: 80.0\n",
      "epoch:   2, avg_PSNR: 17.744392, time: 80.2\n",
      "epoch:   3, avg_PSNR: 19.160014, time: 80.5\n",
      "epoch:   4, avg_PSNR: 20.239774, time: 80.8\n",
      "epoch:   5, avg_PSNR: 21.046463, time: 80.8\n",
      "epoch:   6, avg_PSNR: 21.663950, time: 80.6\n",
      "epoch:   7, avg_PSNR: 22.147963, time: 80.7\n",
      "epoch:   8, avg_PSNR: 22.515244, time: 80.8\n",
      "epoch:   9, avg_PSNR: 22.833566, time: 80.4\n",
      "epoch:  10, avg_PSNR: 23.090701, time: 80.6\n",
      "epoch:  11, avg_PSNR: 23.299408, time: 80.6\n",
      "epoch:  12, avg_PSNR: 23.513851, time: 80.7\n",
      "epoch:  13, avg_PSNR: 23.685791, time: 81.0\n",
      "epoch:  14, avg_PSNR: 23.860051, time: 80.9\n",
      "epoch:  15, avg_PSNR: 23.989287, time: 80.6\n",
      "epoch:  16, avg_PSNR: 24.132154, time: 81.0\n",
      "epoch:  17, avg_PSNR: 24.261895, time: 81.0\n",
      "epoch:  18, avg_PSNR: 24.385149, time: 80.9\n",
      "epoch:  19, avg_PSNR: 24.485842, time: 80.8\n",
      "epoch:  20, avg_PSNR: 24.587327, time: 80.9\n",
      "epoch:  21, avg_PSNR: 24.682001, time: 80.8\n",
      "epoch:  22, avg_PSNR: 24.778334, time: 81.0\n",
      "epoch:  23, avg_PSNR: 24.854515, time: 80.8\n",
      "epoch:  24, avg_PSNR: 24.932847, time: 80.3\n",
      "epoch:  25, avg_PSNR: 25.006839, time: 80.0\n",
      "epoch:  26, avg_PSNR: 25.086495, time: 80.7\n",
      "epoch:  27, avg_PSNR: 25.162622, time: 80.9\n",
      "epoch:  28, avg_PSNR: 25.218850, time: 80.9\n",
      "epoch:  29, avg_PSNR: 25.283919, time: 80.7\n",
      "epoch:  30, avg_PSNR: 25.333242, time: 80.5\n",
      "epoch:  31, avg_PSNR: 25.397887, time: 80.5\n",
      "epoch:  32, avg_PSNR: 25.456864, time: 80.7\n",
      "epoch:  33, avg_PSNR: 25.504163, time: 80.9\n",
      "epoch:  34, avg_PSNR: 25.565207, time: 80.4\n",
      "epoch:  35, avg_PSNR: 25.599634, time: 80.6\n",
      "epoch:  36, avg_PSNR: 25.646253, time: 80.5\n",
      "epoch:  37, avg_PSNR: 25.693698, time: 80.5\n",
      "epoch:  38, avg_PSNR: 25.743635, time: 80.5\n",
      "epoch:  39, avg_PSNR: 25.800763, time: 80.5\n",
      "epoch:  40, avg_PSNR: 25.822668, time: 80.9\n",
      "epoch:  41, avg_PSNR: 25.862818, time: 80.7\n",
      "epoch:  42, avg_PSNR: 25.894820, time: 80.8\n",
      "epoch:  43, avg_PSNR: 25.930714, time: 80.8\n",
      "epoch:  44, avg_PSNR: 25.967840, time: 80.5\n",
      "epoch:  45, avg_PSNR: 26.013405, time: 80.8\n",
      "epoch:  46, avg_PSNR: 26.043854, time: 80.4\n",
      "epoch:  47, avg_PSNR: 26.074976, time: 81.0\n",
      "epoch:  48, avg_PSNR: 26.125340, time: 80.7\n",
      "epoch:  49, avg_PSNR: 26.143824, time: 81.2\n",
      "epoch:  50, avg_PSNR: 26.170668, time: 80.6\n",
      "epoch:  51, avg_PSNR: 26.211105, time: 80.5\n",
      "epoch:  52, avg_PSNR: 26.235489, time: 80.9\n",
      "epoch:  53, avg_PSNR: 26.261539, time: 80.7\n",
      "epoch:  54, avg_PSNR: 26.296709, time: 80.7\n",
      "epoch:  55, avg_PSNR: 26.315944, time: 80.5\n",
      "epoch:  56, avg_PSNR: 26.341916, time: 80.9\n",
      "epoch:  57, avg_PSNR: 26.375482, time: 80.8\n",
      "epoch:  58, avg_PSNR: 26.389114, time: 80.6\n",
      "epoch:  59, avg_PSNR: 26.424944, time: 80.7\n",
      "epoch:  60, avg_PSNR: 26.437864, time: 80.5\n",
      "epoch:  61, avg_PSNR: 26.462932, time: 81.1\n",
      "epoch:  62, avg_PSNR: 26.495832, time: 80.7\n",
      "epoch:  63, avg_PSNR: 26.524657, time: 80.0\n",
      "epoch:  64, avg_PSNR: 26.529008, time: 80.3\n",
      "epoch:  65, avg_PSNR: 26.554522, time: 80.4\n",
      "epoch:  66, avg_PSNR: 26.584299, time: 80.4\n",
      "epoch:  67, avg_PSNR: 26.607474, time: 79.8\n",
      "epoch:  68, avg_PSNR: 26.614334, time: 79.7\n",
      "epoch:  69, avg_PSNR: 26.647040, time: 80.2\n",
      "epoch:  70, avg_PSNR: 26.664306, time: 79.7\n",
      "epoch:  71, avg_PSNR: 26.684432, time: 80.4\n",
      "epoch:  72, avg_PSNR: 26.693411, time: 80.4\n",
      "epoch:  73, avg_PSNR: 26.714208, time: 79.7\n",
      "epoch:  74, avg_PSNR: 26.747691, time: 80.0\n",
      "epoch:  75, avg_PSNR: 26.742088, time: 79.9\n",
      "epoch:  76, avg_PSNR: 26.771643, time: 79.8\n",
      "epoch:  77, avg_PSNR: 26.786748, time: 79.8\n",
      "epoch:  78, avg_PSNR: 26.809904, time: 79.9\n",
      "epoch:  79, avg_PSNR: 26.825784, time: 80.0\n",
      "epoch:  80, avg_PSNR: 26.834198, time: 80.2\n",
      "epoch:  81, avg_PSNR: 26.859283, time: 80.0\n",
      "epoch:  82, avg_PSNR: 26.873596, time: 79.8\n",
      "epoch:  83, avg_PSNR: 26.891682, time: 80.1\n",
      "epoch:  84, avg_PSNR: 26.901482, time: 80.0\n",
      "epoch:  85, avg_PSNR: 26.913164, time: 79.9\n",
      "epoch:  86, avg_PSNR: 26.927093, time: 80.2\n",
      "epoch:  87, avg_PSNR: 26.941107, time: 80.4\n",
      "epoch:  88, avg_PSNR: 26.964893, time: 79.8\n",
      "epoch:  89, avg_PSNR: 26.979481, time: 79.9\n",
      "epoch:  90, avg_PSNR: 26.989936, time: 79.9\n",
      "epoch:  91, avg_PSNR: 26.998106, time: 80.0\n",
      "epoch:  92, avg_PSNR: 27.017119, time: 80.1\n",
      "epoch:  93, avg_PSNR: 27.029201, time: 79.9\n",
      "epoch:  94, avg_PSNR: 27.049401, time: 79.8\n",
      "epoch:  95, avg_PSNR: 27.057336, time: 80.0\n",
      "epoch:  96, avg_PSNR: 27.077089, time: 80.0\n",
      "epoch:  97, avg_PSNR: 27.079702, time: 79.9\n",
      "epoch:  98, avg_PSNR: 27.089674, time: 80.2\n",
      "epoch:  99, avg_PSNR: 27.109988, time: 80.0\n"
     ]
    }
   ],
   "source": [
    "batch_size=model.batch_size\n",
    "print('batch_size: {}'.format(batch_size))\n",
    "total_iter = mnist.train.num_examples // batch_size\n",
    "for epoch in range(100):\n",
    "    start_time=time.time()\n",
    "    avg_psnr = 0\n",
    "    for batch in range(total_iter):\n",
    "        trImg, _= mnist.train.next_batch(batch_size)\n",
    "        trImg = np.reshape(trImg, [-1, 28, 28, 1])\n",
    "        LRImg = toLR(trImg)\n",
    "        HRImg = trImg\n",
    "        _, loss = sess.run([optm, model.LOSS], feed_dict={model.LRImg:LRImg, model.HRImg: HRImg})\n",
    "        psnr = 20*np.log10(1./np.sqrt(loss))\n",
    "        print (\"\\r batch: {}/{} ({:.1f}%) psnr: {:.5f}\".format(\n",
    "            batch, total_iter, batch*100/total_iter, psnr) ,end=\"\")\n",
    "        avg_psnr+=psnr\n",
    "    print ('\\repoch: %3d, avg_PSNR: %4f, time: %.1f' %(epoch, avg_psnr/total_iter, time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size: 32\n",
      "\r",
      " batch: 0/1718 (0.0%) psnr: 27.49039\r",
      " batch: 1/1718 (0.1%) psnr: 27.01609\r",
      " batch: 2/1718 (0.1%) psnr: 27.35629"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/scipy/misc/pilutil.py:482: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if issubdtype(ts, int):\n",
      "/usr/local/lib/python3.5/dist-packages/scipy/misc/pilutil.py:485: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  elif issubdtype(type(size), float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 100, avg_PSNR: 27.125705, time: 79.8\n",
      "epoch: 101, avg_PSNR: 27.138682, time: 80.1\n",
      "epoch: 102, avg_PSNR: 27.135821, time: 80.2\n",
      "epoch: 103, avg_PSNR: 27.159635, time: 79.9\n",
      "epoch: 104, avg_PSNR: 27.173721, time: 79.7\n",
      "epoch: 105, avg_PSNR: 27.178960, time: 80.0\n",
      "epoch: 106, avg_PSNR: 27.195805, time: 80.5\n",
      "epoch: 107, avg_PSNR: 27.203638, time: 80.1\n",
      "epoch: 108, avg_PSNR: 27.197724, time: 79.6\n",
      "epoch: 109, avg_PSNR: 27.227192, time: 80.1\n",
      "epoch: 110, avg_PSNR: 27.246450, time: 79.9\n",
      "epoch: 111, avg_PSNR: 27.256857, time: 79.9\n",
      "epoch: 112, avg_PSNR: 27.245435, time: 80.3\n",
      "epoch: 113, avg_PSNR: 27.272547, time: 80.3\n",
      "epoch: 114, avg_PSNR: 27.282662, time: 80.0\n",
      "epoch: 115, avg_PSNR: 27.282186, time: 80.1\n",
      "epoch: 116, avg_PSNR: 27.295709, time: 80.2\n",
      "epoch: 117, avg_PSNR: 27.315175, time: 79.8\n",
      "epoch: 118, avg_PSNR: 27.316673, time: 80.1\n",
      "epoch: 119, avg_PSNR: 27.331917, time: 80.2\n",
      "epoch: 120, avg_PSNR: 27.325836, time: 80.0\n",
      "epoch: 121, avg_PSNR: 27.350429, time: 80.5\n",
      "epoch: 122, avg_PSNR: 27.371229, time: 80.4\n",
      "epoch: 123, avg_PSNR: 27.363685, time: 80.1\n",
      "epoch: 124, avg_PSNR: 27.382806, time: 79.9\n",
      "epoch: 125, avg_PSNR: 27.380970, time: 80.0\n",
      "epoch: 126, avg_PSNR: 27.392577, time: 79.8\n",
      "epoch: 127, avg_PSNR: 27.420961, time: 79.7\n",
      "epoch: 128, avg_PSNR: 27.423217, time: 80.2\n",
      "epoch: 129, avg_PSNR: 27.423706, time: 80.5\n",
      "epoch: 130, avg_PSNR: 27.428116, time: 80.2\n",
      "epoch: 131, avg_PSNR: 27.461128, time: 80.1\n",
      "epoch: 132, avg_PSNR: 27.438948, time: 79.9\n",
      "epoch: 133, avg_PSNR: 27.467573, time: 80.1\n",
      "epoch: 134, avg_PSNR: 27.464498, time: 80.2\n",
      "epoch: 135, avg_PSNR: 27.465901, time: 80.3\n",
      "epoch: 136, avg_PSNR: 27.487584, time: 80.5\n",
      "epoch: 137, avg_PSNR: 27.493362, time: 79.7\n",
      "epoch: 138, avg_PSNR: 27.501126, time: 79.7\n",
      "epoch: 139, avg_PSNR: 27.513925, time: 80.2\n",
      "epoch: 140, avg_PSNR: 27.508591, time: 80.3\n",
      "epoch: 141, avg_PSNR: 27.543950, time: 79.9\n",
      "epoch: 142, avg_PSNR: 27.538232, time: 80.1\n",
      "epoch: 143, avg_PSNR: 27.550273, time: 80.3\n",
      "epoch: 144, avg_PSNR: 27.553013, time: 80.1\n",
      "epoch: 145, avg_PSNR: 27.546125, time: 79.9\n",
      "epoch: 146, avg_PSNR: 27.583699, time: 80.0\n",
      "epoch: 147, avg_PSNR: 27.579666, time: 80.0\n",
      "epoch: 148, avg_PSNR: 27.583906, time: 79.8\n",
      "epoch: 149, avg_PSNR: 27.583844, time: 79.9\n",
      "epoch: 150, avg_PSNR: 27.598494, time: 79.8\n",
      "epoch: 151, avg_PSNR: 27.621205, time: 80.3\n",
      "epoch: 152, avg_PSNR: 27.615299, time: 80.0\n",
      "epoch: 153, avg_PSNR: 27.625759, time: 80.0\n",
      "epoch: 154, avg_PSNR: 27.627953, time: 80.1\n",
      "epoch: 155, avg_PSNR: 27.646814, time: 79.9\n",
      "epoch: 156, avg_PSNR: 27.635761, time: 80.2\n",
      "epoch: 157, avg_PSNR: 27.652933, time: 79.9\n",
      "epoch: 158, avg_PSNR: 27.656939, time: 80.5\n",
      "epoch: 159, avg_PSNR: 27.664036, time: 80.2\n",
      "epoch: 160, avg_PSNR: 27.674504, time: 80.3\n",
      "epoch: 161, avg_PSNR: 27.667865, time: 80.1\n",
      "epoch: 162, avg_PSNR: 27.694839, time: 80.0\n",
      "epoch: 163, avg_PSNR: 27.697238, time: 80.1\n",
      "epoch: 164, avg_PSNR: 27.713022, time: 80.2\n",
      "epoch: 165, avg_PSNR: 27.708001, time: 80.1\n",
      "epoch: 166, avg_PSNR: 27.713420, time: 79.9\n",
      "epoch: 167, avg_PSNR: 27.716410, time: 79.9\n",
      "epoch: 168, avg_PSNR: 27.728421, time: 79.9\n",
      "epoch: 169, avg_PSNR: 27.734685, time: 80.1\n",
      "epoch: 170, avg_PSNR: 27.742564, time: 80.4\n",
      "epoch: 171, avg_PSNR: 27.754667, time: 80.1\n",
      "epoch: 172, avg_PSNR: 27.754339, time: 80.2\n",
      "epoch: 173, avg_PSNR: 27.760775, time: 80.2\n",
      "epoch: 174, avg_PSNR: 27.763156, time: 79.9\n",
      "epoch: 175, avg_PSNR: 27.781745, time: 80.2\n",
      "epoch: 176, avg_PSNR: 27.770979, time: 80.0\n",
      "epoch: 177, avg_PSNR: 27.798178, time: 80.5\n",
      "epoch: 178, avg_PSNR: 27.790613, time: 79.9\n",
      "epoch: 179, avg_PSNR: 27.810284, time: 80.0\n",
      "epoch: 180, avg_PSNR: 27.805189, time: 80.1\n",
      "epoch: 181, avg_PSNR: 27.808129, time: 80.2\n",
      "epoch: 182, avg_PSNR: 27.829472, time: 79.8\n",
      "epoch: 183, avg_PSNR: 27.823194, time: 80.0\n",
      "epoch: 184, avg_PSNR: 27.826793, time: 80.1\n",
      "epoch: 185, avg_PSNR: 27.830675, time: 80.3\n",
      "epoch: 186, avg_PSNR: 27.839483, time: 80.2\n",
      "epoch: 187, avg_PSNR: 27.845146, time: 79.8\n",
      "epoch: 188, avg_PSNR: 27.854958, time: 80.2\n",
      "epoch: 189, avg_PSNR: 27.855417, time: 80.3\n",
      "epoch: 190, avg_PSNR: 27.875630, time: 80.1\n",
      "epoch: 191, avg_PSNR: 27.874952, time: 80.5\n",
      "epoch: 192, avg_PSNR: 27.885000, time: 80.3\n",
      "epoch: 193, avg_PSNR: 27.883486, time: 80.2\n",
      "epoch: 194, avg_PSNR: 27.898330, time: 80.1\n",
      "epoch: 195, avg_PSNR: 27.896465, time: 80.1\n",
      "epoch: 196, avg_PSNR: 27.903079, time: 80.4\n",
      "epoch: 197, avg_PSNR: 27.907101, time: 80.2\n",
      "epoch: 198, avg_PSNR: 27.903790, time: 80.1\n",
      "epoch: 199, avg_PSNR: 27.920134, time: 79.8\n"
     ]
    }
   ],
   "source": [
    "batch_size=model.batch_size\n",
    "print('batch_size: {}'.format(batch_size))\n",
    "total_iter = mnist.train.num_examples // batch_size\n",
    "for epoch in range(100):\n",
    "    start_time=time.time()\n",
    "    avg_psnr = 0\n",
    "    for batch in range(total_iter):\n",
    "        trImg, _= mnist.train.next_batch(batch_size)\n",
    "        trImg = np.reshape(trImg, [-1, 28, 28, 1])\n",
    "        LRImg = toLR(trImg)\n",
    "        HRImg = trImg\n",
    "        _, loss = sess.run([optm, model.LOSS], feed_dict={model.LRImg:LRImg, model.HRImg: HRImg})\n",
    "        psnr = 20*np.log10(1./np.sqrt(loss))\n",
    "        print (\"\\r batch: {}/{} ({:.1f}%) psnr: {:.5f}\".format(\n",
    "            batch, total_iter, batch*100/total_iter, psnr) ,end=\"\")\n",
    "        avg_psnr+=psnr\n",
    "    print ('\\repoch: %3d, avg_PSNR: %4f, time: %.1f' %(epoch+100, avg_psnr/total_iter, time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size: 32\n",
      "\r",
      " batch: 0/1718 (0.0%) psnr: 27.94910\r",
      " batch: 1/1718 (0.1%) psnr: 28.20787\r",
      " batch: 2/1718 (0.1%) psnr: 27.98633\r",
      " batch: 3/1718 (0.2%) psnr: 27.92737"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/scipy/misc/pilutil.py:482: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if issubdtype(ts, int):\n",
      "/usr/local/lib/python3.5/dist-packages/scipy/misc/pilutil.py:485: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  elif issubdtype(type(size), float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 200, avg_PSNR: 27.926077, time: 80.5\n",
      "epoch: 201, avg_PSNR: 27.930530, time: 80.6\n",
      "epoch: 202, avg_PSNR: 27.937137, time: 80.6\n",
      "epoch: 203, avg_PSNR: 27.937143, time: 79.9\n",
      "epoch: 204, avg_PSNR: 27.937300, time: 80.1\n",
      "epoch: 205, avg_PSNR: 27.949446, time: 80.1\n",
      "epoch: 206, avg_PSNR: 27.956802, time: 80.1\n",
      "epoch: 207, avg_PSNR: 27.964714, time: 80.2\n",
      "epoch: 208, avg_PSNR: 27.965137, time: 80.0\n",
      "epoch: 209, avg_PSNR: 27.967767, time: 80.2\n",
      "epoch: 210, avg_PSNR: 27.959964, time: 80.3\n",
      "epoch: 211, avg_PSNR: 27.982698, time: 80.0\n",
      "epoch: 212, avg_PSNR: 27.980199, time: 80.4\n",
      "epoch: 213, avg_PSNR: 27.991029, time: 80.5\n",
      "epoch: 214, avg_PSNR: 28.010005, time: 80.0\n",
      "epoch: 215, avg_PSNR: 28.000265, time: 80.0\n",
      "epoch: 216, avg_PSNR: 28.004337, time: 80.1\n",
      "epoch: 217, avg_PSNR: 28.010365, time: 80.2\n",
      "epoch: 218, avg_PSNR: 28.024870, time: 79.8\n",
      "epoch: 219, avg_PSNR: 28.016889, time: 80.0\n",
      "epoch: 220, avg_PSNR: 28.017277, time: 80.1\n",
      "epoch: 221, avg_PSNR: 28.022201, time: 80.1\n",
      "epoch: 222, avg_PSNR: 28.048413, time: 80.3\n",
      "epoch: 223, avg_PSNR: 28.027112, time: 80.2\n",
      "epoch: 224, avg_PSNR: 28.037729, time: 80.2\n",
      "epoch: 225, avg_PSNR: 28.047099, time: 79.9\n",
      "epoch: 226, avg_PSNR: 28.045862, time: 80.3\n",
      "epoch: 227, avg_PSNR: 28.076863, time: 80.4\n",
      "epoch: 228, avg_PSNR: 28.053770, time: 80.1\n",
      "epoch: 229, avg_PSNR: 28.061938, time: 80.1\n",
      "epoch: 230, avg_PSNR: 28.079184, time: 80.6\n",
      "epoch: 231, avg_PSNR: 28.070322, time: 79.9\n",
      "epoch: 232, avg_PSNR: 28.092678, time: 80.3\n",
      "epoch: 233, avg_PSNR: 28.083159, time: 80.0\n",
      "epoch: 234, avg_PSNR: 28.077187, time: 80.4\n",
      "epoch: 235, avg_PSNR: 28.104230, time: 80.3\n",
      "epoch: 236, avg_PSNR: 28.086377, time: 80.1\n",
      "epoch: 237, avg_PSNR: 28.120951, time: 80.3\n",
      "epoch: 238, avg_PSNR: 28.100768, time: 80.1\n",
      "epoch: 239, avg_PSNR: 28.104649, time: 80.0\n",
      "epoch: 240, avg_PSNR: 28.121538, time: 80.3\n",
      "epoch: 241, avg_PSNR: 28.119535, time: 80.2\n",
      "epoch: 242, avg_PSNR: 28.113607, time: 80.6\n",
      "epoch: 243, avg_PSNR: 28.130595, time: 80.5\n",
      "epoch: 244, avg_PSNR: 28.147555, time: 80.0\n",
      "epoch: 245, avg_PSNR: 28.144077, time: 79.9\n",
      "epoch: 246, avg_PSNR: 28.137623, time: 80.5\n",
      "epoch: 247, avg_PSNR: 28.139054, time: 80.4\n",
      "epoch: 248, avg_PSNR: 28.144907, time: 80.1\n",
      "epoch: 249, avg_PSNR: 28.156408, time: 80.3\n",
      "epoch: 250, avg_PSNR: 28.142298, time: 80.4\n",
      "epoch: 251, avg_PSNR: 28.162357, time: 80.1\n",
      "epoch: 252, avg_PSNR: 28.153586, time: 80.5\n",
      "epoch: 253, avg_PSNR: 28.178409, time: 80.4\n",
      "epoch: 254, avg_PSNR: 28.176167, time: 80.4\n",
      "epoch: 255, avg_PSNR: 28.179198, time: 80.4\n",
      "epoch: 256, avg_PSNR: 28.176860, time: 80.3\n",
      "epoch: 257, avg_PSNR: 28.191123, time: 80.2\n",
      "epoch: 258, avg_PSNR: 28.181801, time: 80.5\n",
      "epoch: 259, avg_PSNR: 28.191598, time: 80.2\n",
      "epoch: 260, avg_PSNR: 28.192150, time: 80.3\n",
      "epoch: 261, avg_PSNR: 28.192844, time: 80.3\n",
      "epoch: 262, avg_PSNR: 28.222910, time: 80.4\n",
      "epoch: 263, avg_PSNR: 28.200547, time: 80.5\n",
      "epoch: 264, avg_PSNR: 28.206867, time: 80.6\n",
      "epoch: 265, avg_PSNR: 28.221464, time: 80.1\n",
      "epoch: 266, avg_PSNR: 28.214075, time: 80.2\n",
      "epoch: 267, avg_PSNR: 28.220810, time: 80.4\n",
      "epoch: 268, avg_PSNR: 28.227825, time: 80.6\n",
      "epoch: 269, avg_PSNR: 28.223051, time: 81.2\n",
      "epoch: 270, avg_PSNR: 28.237693, time: 81.1\n",
      "epoch: 271, avg_PSNR: 28.239943, time: 80.9\n",
      "epoch: 272, avg_PSNR: 28.220173, time: 80.7\n",
      "epoch: 273, avg_PSNR: 28.255442, time: 81.0\n",
      "epoch: 274, avg_PSNR: 28.239129, time: 80.5\n",
      "epoch: 275, avg_PSNR: 28.242498, time: 81.2\n",
      "epoch: 276, avg_PSNR: 28.251536, time: 81.1\n",
      "epoch: 277, avg_PSNR: 28.264005, time: 80.6\n",
      "epoch: 278, avg_PSNR: 28.267180, time: 80.9\n",
      "epoch: 279, avg_PSNR: 28.261294, time: 80.7\n",
      "epoch: 280, avg_PSNR: 28.277201, time: 80.6\n",
      "epoch: 281, avg_PSNR: 28.271156, time: 81.1\n",
      "epoch: 282, avg_PSNR: 28.282927, time: 81.1\n",
      "epoch: 283, avg_PSNR: 28.266631, time: 81.1\n",
      "epoch: 284, avg_PSNR: 28.292163, time: 80.6\n",
      "epoch: 285, avg_PSNR: 28.278645, time: 80.9\n",
      "epoch: 286, avg_PSNR: 28.298797, time: 81.0\n",
      "epoch: 287, avg_PSNR: 28.290514, time: 81.0\n",
      "epoch: 288, avg_PSNR: 28.301234, time: 80.9\n",
      "epoch: 289, avg_PSNR: 28.297429, time: 80.8\n",
      "epoch: 290, avg_PSNR: 28.300150, time: 80.8\n",
      "epoch: 291, avg_PSNR: 28.305065, time: 80.9\n",
      "epoch: 292, avg_PSNR: 28.314792, time: 81.2\n",
      "epoch: 293, avg_PSNR: 28.307636, time: 80.9\n",
      "epoch: 294, avg_PSNR: 28.338278, time: 80.8\n",
      "epoch: 295, avg_PSNR: 28.302880, time: 80.9\n",
      "epoch: 296, avg_PSNR: 28.320153, time: 80.8\n",
      "epoch: 297, avg_PSNR: 28.324097, time: 80.9\n",
      "epoch: 298, avg_PSNR: 28.331036, time: 80.7\n",
      "epoch: 299, avg_PSNR: 28.320375, time: 81.0\n"
     ]
    }
   ],
   "source": [
    "batch_size=model.batch_size\n",
    "print('batch_size: {}'.format(batch_size))\n",
    "total_iter = mnist.train.num_examples // batch_size\n",
    "for epoch in range(100):\n",
    "    start_time=time.time()\n",
    "    avg_psnr = 0\n",
    "    for batch in range(total_iter):\n",
    "        trImg, _= mnist.train.next_batch(batch_size)\n",
    "        trImg = np.reshape(trImg, [-1, 28, 28, 1])\n",
    "        LRImg = toLR(trImg)\n",
    "        HRImg = trImg\n",
    "        _, loss = sess.run([optm, model.LOSS], feed_dict={model.LRImg:LRImg, model.HRImg: HRImg})\n",
    "        psnr = 20*np.log10(1./np.sqrt(loss))\n",
    "        print (\"\\r batch: {}/{} ({:.1f}%) psnr: {:.5f}\".format(\n",
    "            batch, total_iter, batch*100/total_iter, psnr) ,end=\"\")\n",
    "        avg_psnr+=psnr\n",
    "    print ('\\repoch: %3d, avg_PSNR: %4f, time: %.1f' %(epoch+200, avg_psnr/total_iter, time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size: 32\n",
      "\r",
      " batch: 0/1718 (0.0%) psnr: 28.81323\r",
      " batch: 1/1718 (0.1%) psnr: 28.82086\r",
      " batch: 2/1718 (0.1%) psnr: 28.63118\r",
      " batch: 3/1718 (0.2%) psnr: 28.40714"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/scipy/misc/pilutil.py:482: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if issubdtype(ts, int):\n",
      "/usr/local/lib/python3.5/dist-packages/scipy/misc/pilutil.py:485: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  elif issubdtype(type(size), float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 300, avg_PSNR: 28.329815, time: 78.5\n",
      "epoch: 301, avg_PSNR: 28.343215, time: 78.6\n",
      "epoch: 302, avg_PSNR: 28.336094, time: 78.5\n",
      "epoch: 303, avg_PSNR: 28.338443, time: 78.5\n",
      "epoch: 304, avg_PSNR: 28.359268, time: 78.6\n",
      "epoch: 305, avg_PSNR: 28.344644, time: 78.6\n",
      "epoch: 306, avg_PSNR: 28.347026, time: 78.7\n",
      "epoch: 307, avg_PSNR: 28.368999, time: 78.7\n",
      "epoch: 308, avg_PSNR: 28.371029, time: 79.0\n",
      "epoch: 309, avg_PSNR: 28.354425, time: 78.5\n",
      "epoch: 310, avg_PSNR: 28.379899, time: 78.5\n",
      "epoch: 311, avg_PSNR: 28.371245, time: 78.5\n",
      "epoch: 312, avg_PSNR: 28.382220, time: 78.8\n",
      "epoch: 313, avg_PSNR: 28.376334, time: 78.6\n",
      "epoch: 314, avg_PSNR: 28.380449, time: 78.8\n",
      "epoch: 315, avg_PSNR: 28.381372, time: 78.6\n",
      "epoch: 316, avg_PSNR: 28.387650, time: 78.5\n",
      "epoch: 317, avg_PSNR: 28.393127, time: 78.8\n",
      "epoch: 318, avg_PSNR: 28.383185, time: 78.6\n",
      "epoch: 319, avg_PSNR: 28.404616, time: 78.8\n",
      "epoch: 320, avg_PSNR: 28.393545, time: 78.5\n",
      "epoch: 321, avg_PSNR: 28.408971, time: 78.7\n",
      "epoch: 322, avg_PSNR: 28.398241, time: 78.3\n",
      "epoch: 323, avg_PSNR: 28.402063, time: 78.7\n",
      "epoch: 324, avg_PSNR: 28.404491, time: 78.6\n",
      "epoch: 325, avg_PSNR: 28.417588, time: 78.1\n",
      "epoch: 326, avg_PSNR: 28.410403, time: 78.4\n",
      "epoch: 327, avg_PSNR: 28.403209, time: 78.3\n",
      "epoch: 328, avg_PSNR: 28.426652, time: 78.2\n",
      "epoch: 329, avg_PSNR: 28.418877, time: 78.5\n",
      "epoch: 330, avg_PSNR: 28.435294, time: 78.6\n",
      "epoch: 331, avg_PSNR: 28.419419, time: 78.8\n",
      "epoch: 332, avg_PSNR: 28.447954, time: 78.8\n",
      "epoch: 333, avg_PSNR: 28.423508, time: 78.6\n",
      "epoch: 334, avg_PSNR: 28.435591, time: 78.4\n",
      "epoch: 335, avg_PSNR: 28.438760, time: 78.5\n",
      "epoch: 336, avg_PSNR: 28.436939, time: 78.4\n",
      "epoch: 337, avg_PSNR: 28.443676, time: 78.5\n",
      "epoch: 338, avg_PSNR: 28.450363, time: 78.6\n",
      "epoch: 339, avg_PSNR: 28.453294, time: 78.7\n",
      "epoch: 340, avg_PSNR: 28.447824, time: 78.4\n",
      "epoch: 341, avg_PSNR: 28.447904, time: 78.5\n",
      "epoch: 342, avg_PSNR: 28.462317, time: 78.5\n",
      "epoch: 343, avg_PSNR: 28.455878, time: 78.4\n",
      "epoch: 344, avg_PSNR: 28.467729, time: 78.4\n",
      "epoch: 345, avg_PSNR: 28.468574, time: 78.5\n",
      "epoch: 346, avg_PSNR: 28.469297, time: 78.4\n",
      "epoch: 347, avg_PSNR: 28.479322, time: 78.5\n",
      "epoch: 348, avg_PSNR: 28.467983, time: 78.6\n",
      "epoch: 349, avg_PSNR: 28.492825, time: 79.1\n",
      "epoch: 350, avg_PSNR: 28.462555, time: 79.3\n",
      "epoch: 351, avg_PSNR: 28.500747, time: 80.0\n",
      "epoch: 352, avg_PSNR: 28.473735, time: 79.5\n",
      "epoch: 353, avg_PSNR: 28.498026, time: 79.5\n",
      "epoch: 354, avg_PSNR: 28.485748, time: 79.6\n",
      "epoch: 355, avg_PSNR: 28.507747, time: 79.7\n",
      "epoch: 356, avg_PSNR: 28.490242, time: 79.5\n",
      "epoch: 357, avg_PSNR: 28.494994, time: 79.3\n",
      "epoch: 358, avg_PSNR: 28.499322, time: 79.8\n",
      "epoch: 359, avg_PSNR: 28.499684, time: 79.6\n",
      "epoch: 360, avg_PSNR: 28.519949, time: 79.8\n",
      "epoch: 361, avg_PSNR: 28.515738, time: 79.8\n",
      "epoch: 362, avg_PSNR: 28.497681, time: 79.7\n",
      "epoch: 363, avg_PSNR: 28.515029, time: 79.9\n",
      "epoch: 364, avg_PSNR: 28.507041, time: 79.6\n",
      "epoch: 365, avg_PSNR: 28.530724, time: 79.9\n",
      "epoch: 366, avg_PSNR: 28.520324, time: 79.4\n",
      "epoch: 367, avg_PSNR: 28.517190, time: 80.0\n",
      "epoch: 368, avg_PSNR: 28.527037, time: 78.9\n",
      "epoch: 369, avg_PSNR: 28.533625, time: 79.6\n",
      "epoch: 370, avg_PSNR: 28.522972, time: 79.5\n",
      "epoch: 371, avg_PSNR: 28.539387, time: 79.5\n",
      "epoch: 372, avg_PSNR: 28.529406, time: 79.4\n",
      "epoch: 373, avg_PSNR: 28.545516, time: 79.5\n",
      "epoch: 374, avg_PSNR: 28.535672, time: 79.4\n",
      "epoch: 375, avg_PSNR: 28.545971, time: 79.4\n",
      "epoch: 376, avg_PSNR: 28.537985, time: 79.6\n",
      "epoch: 377, avg_PSNR: 28.558016, time: 79.3\n",
      "epoch: 378, avg_PSNR: 28.540834, time: 79.8\n",
      "epoch: 379, avg_PSNR: 28.552165, time: 79.5\n",
      "epoch: 380, avg_PSNR: 28.559413, time: 79.8\n",
      "epoch: 381, avg_PSNR: 28.577824, time: 79.5\n",
      "epoch: 382, avg_PSNR: 28.567177, time: 79.4\n",
      "epoch: 383, avg_PSNR: 28.561379, time: 79.6\n",
      "epoch: 384, avg_PSNR: 28.561590, time: 79.7\n",
      "epoch: 385, avg_PSNR: 28.573258, time: 79.5\n",
      "epoch: 386, avg_PSNR: 28.571244, time: 79.6\n",
      "epoch: 387, avg_PSNR: 28.568048, time: 79.6\n",
      "epoch: 388, avg_PSNR: 28.578439, time: 79.6\n",
      "epoch: 389, avg_PSNR: 28.590496, time: 79.3\n",
      "epoch: 390, avg_PSNR: 28.582990, time: 79.5\n",
      "epoch: 391, avg_PSNR: 28.590209, time: 79.5\n",
      "epoch: 392, avg_PSNR: 28.568502, time: 79.7\n",
      "epoch: 393, avg_PSNR: 28.585074, time: 79.6\n",
      "epoch: 394, avg_PSNR: 28.596728, time: 79.7\n",
      "epoch: 395, avg_PSNR: 28.583426, time: 79.6\n",
      "epoch: 396, avg_PSNR: 28.598806, time: 79.4\n",
      "epoch: 397, avg_PSNR: 28.601392, time: 79.8\n",
      "epoch: 398, avg_PSNR: 28.602467, time: 79.5\n",
      "epoch: 399, avg_PSNR: 28.606672, time: 79.3\n"
     ]
    }
   ],
   "source": [
    "batch_size=model.batch_size\n",
    "print('batch_size: {}'.format(batch_size))\n",
    "total_iter = mnist.train.num_examples // batch_size\n",
    "for epoch in range(100):\n",
    "    start_time=time.time()\n",
    "    avg_psnr = 0\n",
    "    for batch in range(total_iter):\n",
    "        trImg, _= mnist.train.next_batch(batch_size)\n",
    "        trImg = np.reshape(trImg, [-1, 28, 28, 1])\n",
    "        LRImg = toLR(trImg)\n",
    "        HRImg = trImg\n",
    "        _, loss = sess.run([optm, model.LOSS], feed_dict={model.LRImg:LRImg, model.HRImg: HRImg})\n",
    "        psnr = 20*np.log10(1./np.sqrt(loss))\n",
    "        print (\"\\r batch: {}/{} ({:.1f}%) psnr: {:.5f}\".format(\n",
    "            batch, total_iter, batch*100/total_iter, psnr) ,end=\"\")\n",
    "        avg_psnr+=psnr\n",
    "    print ('\\repoch: %3d, avg_PSNR: %4f, time: %.1f' %(epoch+300, avg_psnr/total_iter, time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempted to use a closed Session.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-05a3ad5f6f45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLRImg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mLRImg\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHRImg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \u001b[0;31m# Check session.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_closed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Attempted to use a closed Session.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m       raise RuntimeError('The Session graph is empty.  Add operations to the '\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempted to use a closed Session."
     ]
    }
   ],
   "source": [
    "C=sess.run(model.out_layer, feed_dict={model.LRImg:LRImg})\n",
    "plt.figure(figsize=[15,10])\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(HRImg[0,:,:,0], cmap='gray')\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(LRImg[0,:,:,0], cmap='gray')\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(C[0,:,:,0], cmap='gray')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'checkpoints/SRCapsNet/PS_MNIST_psnr_27-92'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver=tf.train.Saver()\n",
    "saver.save(sess, 'checkpoints/SRCapsNet/PS_MNIST_psnr_27-92')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/scipy/misc/pilutil.py:482: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if issubdtype(ts, int):\n",
      "/usr/local/lib/python3.5/dist-packages/scipy/misc/pilutil.py:485: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  elif issubdtype(type(size), float):\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/scipy/misc/pilutil.py:482: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if issubdtype(ts, int):\n",
      "/usr/local/lib/python3.5/dist-packages/scipy/misc/pilutil.py:485: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  elif issubdtype(type(size), float):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7faa54755128>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faa546c3c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "showimg = mnist.test.images[0:32,:]\n",
    "hrimg = np.reshape(showimg, [-1, 28, 28, 1])\n",
    "lrimg = toLR(hrimg)\n",
    "srimg=sess.run(model.out_layer, feed_dict={model.LRImg:lrimg})\n",
    "index=3\n",
    "\n",
    "plt.figure(figsize=[20,5])\n",
    "plt.subplot(1,3,1)\n",
    "plt.axis('off')\n",
    "plt.title('LR')\n",
    "plt.imshow(lrimg[index,:,:,0], cmap='gray')\n",
    "plt.subplot(1,3,2)\n",
    "plt.axis('off')\n",
    "plt.title('HR')\n",
    "plt.imshow(hrimg[index,:,:,0], cmap='gray')\n",
    "plt.subplot(1,3,3)\n",
    "plt.axis('off')\n",
    "plt.title('SR')\n",
    "plt.imshow(srimg[index,:,:,0], cmap='gray')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
