{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SRCNN (MNIST)\n",
    "![image](https://i.imgur.com/a9dbceh.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "Training data set : 50000, Test data Set : 10000\n"
     ]
    }
   ],
   "source": [
    "import os, sys, time\n",
    "import numpy as np\n",
    "import scipy.ndimage, scipy.misc\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "slim = tf.contrib.slim\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"\n",
    "\n",
    "\n",
    "\n",
    "def unpickle(file):\n",
    "    with open(file, 'rb') as f:\n",
    "        data = pickle.load(f, encoding='latin1')\n",
    "        return data\n",
    "\n",
    "def load_cifar10_data(data_dir):\n",
    "    train_data = None\n",
    "    train_labels = []\n",
    "    \n",
    "    for i in range(1,6):\n",
    "        data_dic = unpickle(data_dir + \"/data_batch_{}\".format(i))\n",
    "        if i==1:\n",
    "            train_data = data_dic['data']\n",
    "        else:\n",
    "            train_data = np.vstack((train_data, data_dic['data']))\n",
    "        train_labels += data_dic['labels']\n",
    "    test_data_dic = unpickle(data_dir + \"/test_batch\")\n",
    "    test_data = test_data_dic['data']\n",
    "    test_labels = test_data_dic['labels']\n",
    "    \n",
    "    train_data = train_data.reshape((len(train_data), 3, 32, 32))\n",
    "    train_data = np.rollaxis(train_data, 1, 4)\n",
    "    train_labels = np.array(train_labels)\n",
    "    \n",
    "    test_data = test_data.reshape((len(test_data), 3, 32, 32))\n",
    "    test_data = np.rollaxis(test_data, 1, 4)\n",
    "    test_labels = np.array(test_labels)\n",
    "    \n",
    "    return train_data, train_labels, test_data, test_labels\n",
    "\n",
    "data_dir = '/ideaHome/Dropbox/SJ/ML/Cifar10/Data/cifar-10-batches-py'\n",
    "trImg, train_labels, teImg, test_labels = load_cifar10_data(data_dir)\n",
    "\n",
    "\n",
    "print(\"Training data set : %3d, Test data Set : %3d\" %(trImg.shape[0], teImg.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-8bf8ae5a5303>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def toLR(image, scale=2.):\n",
    "    if len(image.shape)==4:\n",
    "        num_sample = image.shape[0]\n",
    "        images = np.zeros([image.shape[0], int(image.shape[1]/scale), int(image.shape[2]/scale), image.shape[3]])\n",
    "        for i in range(num_sample):\n",
    "            images[i,:,:,0] = scipy.misc.imresize(image[i,:,:,0], 1/scale,'bicubic')\n",
    "        return images\n",
    "    else:\n",
    "        return scipy.misc.imresize(image, 1/scale, 'bicubic')\n",
    "    \n",
    "\n",
    "def Bicubic(image, scale=2):\n",
    "    if len(image.shape)==4:\n",
    "        bicImg=np.zeros([image.shape[0], image.shape[1]*scale, image.shape[2]*scale, image.shape[3]])\n",
    "        for i in range(image.shape[0]):\n",
    "            bicImg[i,:,:,:] = scipy.ndimage.interpolation.zoom(image[i,:,:,:], [scale, scale, 1], prefilter=False)\n",
    "    else:\n",
    "        bicImg = scipy.ndimage.interpolation.zoom(image, [scale,scale, 1], prefilter=False)\n",
    "    return bicImg\n",
    "\n",
    "def _phase_shift(I, r):\n",
    "    # Helper function with main phase shift operation\n",
    "    bsize, a, b, c = I.get_shape().as_list()\n",
    "    X = tf.reshape(I, (-1, a, b, r, r))\n",
    "    X = tf.transpose(X, (0, 1, 2, 4, 3))  # bsize, a, b, 1, 1\n",
    "    X = tf.split(X, a, 1)  # a, [bsize, b, r, r]\n",
    "    X = tf.concat([tf.squeeze(x) for x in X], axis=2)  # bsize, b, a*r, r\n",
    "    X = tf.split(X, b, 1)  # b, [bsize, a*r, r]\n",
    "    X = tf.concat([tf.squeeze(x) for x in X], axis=2)  # bsize, a*r, b*r\n",
    "    return tf.reshape(X, (-1, a*r, b*r, 1))\n",
    "\n",
    "def PS(X, r, color=False):\n",
    "  # Main OP that you can arbitrarily use in you tensorflow code\n",
    "    if color:\n",
    "        Xc = tf.split(X,3,3) #(3, 3, X)\n",
    "        X = tf.concat([_phase_shift(x, r) for x in Xc], axis=3)\n",
    "    else:\n",
    "        X = _phase_shift(X, r)\n",
    "    return X\n",
    "\n",
    "def squash(s, axis=-1, epsilon=1e-7, name=None):\n",
    "    with tf.name_scope(name, default_name=\"squash\"):\n",
    "        squared_norm = tf.reduce_sum(tf.square(s), axis=axis, keep_dims=True)\n",
    "        safe_norm = tf.sqrt(squared_norm + epsilon)\n",
    "        squash_factor = squared_norm / (1. + squared_norm)\n",
    "        unit_vector = s / safe_norm\n",
    "    return squash_factor * unit_vector\n",
    "\n",
    "def safe_norm(s, axis=-1, epsilon=1e-7, keep_dims=False, name=None):\n",
    "    with tf.name_scope(name, default_name=\"safe_norm\"):\n",
    "        squared_norm = tf.reduce_sum(tf.square(s), axis=axis,\n",
    "                                     keep_dims=keep_dims)\n",
    "        return tf.sqrt(squared_norm + epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SRCNN(object):\n",
    "    def __init__(self, mode):\n",
    "        self.LR_dim = (28,28,1)\n",
    "        self.HR_dim = (28,28,1)\n",
    "        self.batch_size = 32\n",
    "        self.mode = mode\n",
    "\n",
    "        print('The model is generated')\n",
    "        \n",
    "    def model(self, img):\n",
    "        with slim.arg_scope([slim.conv2d], stride=[1,1], activation_fn = tf.nn.relu, padding='SAME',\n",
    "                                                   weights_initializer=tf.contrib.layers.xavier_initializer()):\n",
    "            self.layer1 = slim.conv2d(inputs=img, num_outputs=64, kernel_size=[9,9], scope='layer1')\n",
    "            self.layer2 = slim.conv2d(inputs=self.layer1, num_outputs=32, kernel_size=[1,1], scope='layer2')\n",
    "            self.layer3 = slim.conv2d(inputs=self.layer2, num_outputs=1, kernel_size=[5,5], scope='layer', activation_fn=tf.nn.sigmoid)\n",
    "            out = self.layer3\n",
    "        return out\n",
    "    \n",
    "    def loss(self, SR, HR):\n",
    "        loss = tf.reduce_mean(tf.square(SR - HR))\n",
    "        return loss\n",
    "    \n",
    "    def build(self):\n",
    "        if self.mode == 'bicubic':\n",
    "            self.LRImg = tf.placeholder(tf.float32, [None, 28, 28, 1], 'LRImgBicubic')\n",
    "        elif self.mode == 'pixelshuffle':\n",
    "            self.LRImg = tf.placeholder(tf.float32, [None, 14, 14, 1], 'LRImgPixelShuffle')\n",
    "        else:\n",
    "            print ('undefined mode')\n",
    "        self.HRImg = tf.placeholder(tf.float32, [None, 28, 28, 1], 'HRImg')\n",
    "        self.SRImg = self.model(self.LRImg)\n",
    "        self.LOSS = self.loss(self.SRImg, self.HRImg)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def _phase_shift(I, r):\n",
    "        # Helper function with main phase shift operation\n",
    "        bsize, a, b, c = I.get_shape().as_list()\n",
    "        X = tf.reshape(I, (bsize, a, b, r, r))\n",
    "        X = tf.transpose(X, (0, 1, 2, 4, 3))  # bsize, a, b, 1, 1\n",
    "        X = tf.split(X, a, 1)  # a, [bsize, b, r, r]\n",
    "        X = tf.concat([tf.squeeze(x) for x in X], asix=2)  # bsize, b, a*r, r\n",
    "        X = tf.split(X, b, 1)  # b, [bsize, a*r, r]\n",
    "        X = tf.concat([tf.squeeze(x) for x in X], axis=2)  # bsize, a*r, b*r\n",
    "        return tf.reshape(X, (bsize, a*r, b*r, 1))\n",
    "\n",
    "    def PS(X, r, color=False):\n",
    "      # Main OP that you can arbitrarily use in you tensorflow code\n",
    "        if color:\n",
    "            Xc = tf.split(X,3,3) #(3, 3, X)\n",
    "            X = tf.concat([_phase_shift(x, r) for x in Xc], axis=3)\n",
    "        else:\n",
    "            X = _phase_shift(X, r)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is generated\n",
      "---------\n",
      "Variables: name (type shape) [size]\n",
      "---------\n",
      "layer1/weights:0 (float32_ref 9x9x1x64) [5184, bytes: 20736]\n",
      "layer1/biases:0 (float32_ref 64) [64, bytes: 256]\n",
      "layer2/weights:0 (float32_ref 1x1x64x32) [2048, bytes: 8192]\n",
      "layer2/biases:0 (float32_ref 32) [32, bytes: 128]\n",
      "layer/weights:0 (float32_ref 5x5x32x1) [800, bytes: 3200]\n",
      "layer/biases:0 (float32_ref 1) [1, bytes: 4]\n",
      "Total size of variables: 8129\n",
      "Total bytes of variables: 32516\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8129, 32516)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "model = SRCNN('bicubic')\n",
    "model.build()\n",
    "\n",
    "t_vars = tf.trainable_variables()\n",
    "slim.model_analyzer.analyze_vars(t_vars, print_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = tf.placeholder(tf.float32, shape=[])\n",
    "optm = tf.train.AdamOptimizer(learning_rate=lr).minimize(model.LOSS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config) \n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/SRCNN/MNIST_psnr_21-09\n"
     ]
    }
   ],
   "source": [
    "saver=tf.train.Saver()\n",
    "saver.restore(sess, 'checkpoints/SRCNN/MNIST_psnr_21-09')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/scipy/misc/pilutil.py:482: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if issubdtype(ts, int):\n",
      "/usr/local/lib/python3.5/dist-packages/scipy/misc/pilutil.py:485: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  elif issubdtype(type(size), float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   0, avg_PSNR: 17.157638, time for epoch: 36.31\n",
      "epoch:   1, avg_PSNR: 21.546397, time for epoch: 35.86\n",
      "epoch:   2, avg_PSNR: 23.299965, time for epoch: 36.01\n",
      "epoch:   3, avg_PSNR: 24.212356, time for epoch: 35.70\n",
      "epoch:   4, avg_PSNR: 24.716440, time for epoch: 35.98\n",
      "epoch:   5, avg_PSNR: 25.029932, time for epoch: 35.60\n",
      "epoch:   6, avg_PSNR: 25.256791, time for epoch: 35.71\n",
      "epoch:   7, avg_PSNR: 25.428232, time for epoch: 35.90\n",
      "epoch:   8, avg_PSNR: 25.580472, time for epoch: 35.89\n",
      "epoch:   9, avg_PSNR: 25.685334, time for epoch: 35.98\n",
      "epoch:  10, avg_PSNR: 25.779876, time for epoch: 35.38\n",
      "epoch:  11, avg_PSNR: 25.874499, time for epoch: 35.98\n",
      "epoch:  12, avg_PSNR: 25.941792, time for epoch: 35.84\n",
      "epoch:  13, avg_PSNR: 26.008818, time for epoch: 36.17\n",
      "epoch:  14, avg_PSNR: 26.048286, time for epoch: 35.93\n",
      "epoch:  15, avg_PSNR: 26.111430, time for epoch: 36.06\n",
      "epoch:  16, avg_PSNR: 26.164225, time for epoch: 35.48\n",
      "epoch:  17, avg_PSNR: 26.187014, time for epoch: 35.50\n",
      "epoch:  18, avg_PSNR: 26.222533, time for epoch: 35.98\n",
      "epoch:  19, avg_PSNR: 26.270934, time for epoch: 35.19\n",
      "epoch:  20, avg_PSNR: 26.293416, time for epoch: 35.90\n",
      "epoch:  21, avg_PSNR: 26.322012, time for epoch: 35.69\n",
      "epoch:  22, avg_PSNR: 26.355335, time for epoch: 35.74\n",
      "epoch:  23, avg_PSNR: 26.381293, time for epoch: 35.52\n",
      "epoch:  24, avg_PSNR: 26.402481, time for epoch: 35.91\n",
      "epoch:  25, avg_PSNR: 26.442267, time for epoch: 36.05\n",
      "epoch:  26, avg_PSNR: 26.457760, time for epoch: 35.57\n",
      "epoch:  27, avg_PSNR: 26.470089, time for epoch: 35.84\n",
      "epoch:  28, avg_PSNR: 26.494696, time for epoch: 35.06\n",
      "epoch:  29, avg_PSNR: 26.524326, time for epoch: 35.68\n",
      "epoch:  30, avg_PSNR: 26.545815, time for epoch: 36.37\n",
      "epoch:  31, avg_PSNR: 26.549962, time for epoch: 36.23\n",
      "epoch:  32, avg_PSNR: 26.573165, time for epoch: 35.50\n",
      "epoch:  33, avg_PSNR: 26.589225, time for epoch: 35.82\n",
      "epoch:  34, avg_PSNR: 26.607245, time for epoch: 35.77\n",
      "epoch:  35, avg_PSNR: 26.609652, time for epoch: 35.68\n",
      "epoch:  36, avg_PSNR: 26.636905, time for epoch: 35.76\n",
      "epoch:  37, avg_PSNR: 26.647518, time for epoch: 35.54\n",
      "epoch:  38, avg_PSNR: 26.645457, time for epoch: 35.88\n",
      "epoch:  39, avg_PSNR: 26.681958, time for epoch: 35.62\n",
      "epoch:  40, avg_PSNR: 26.688235, time for epoch: 35.64\n",
      "epoch:  41, avg_PSNR: 26.704525, time for epoch: 35.80\n",
      "epoch:  42, avg_PSNR: 26.708590, time for epoch: 35.53\n",
      "epoch:  43, avg_PSNR: 26.720278, time for epoch: 35.72\n",
      "epoch:  44, avg_PSNR: 26.742536, time for epoch: 35.49\n",
      "epoch:  45, avg_PSNR: 26.738458, time for epoch: 35.57\n",
      "epoch:  46, avg_PSNR: 26.755580, time for epoch: 35.86\n",
      "epoch:  47, avg_PSNR: 26.768256, time for epoch: 35.72\n",
      "epoch:  48, avg_PSNR: 26.781179, time for epoch: 35.76\n",
      "epoch:  49, avg_PSNR: 26.797348, time for epoch: 35.89\n",
      "epoch:  50, avg_PSNR: 26.790496, time for epoch: 35.55\n",
      "epoch:  51, avg_PSNR: 26.802641, time for epoch: 35.64\n",
      "epoch:  52, avg_PSNR: 26.816673, time for epoch: 35.73\n",
      "epoch:  53, avg_PSNR: 26.826464, time for epoch: 35.92\n",
      "epoch:  54, avg_PSNR: 26.835263, time for epoch: 35.64\n",
      "epoch:  55, avg_PSNR: 26.842516, time for epoch: 35.80\n",
      "epoch:  56, avg_PSNR: 26.855319, time for epoch: 35.72\n",
      "epoch:  57, avg_PSNR: 26.852023, time for epoch: 35.33\n",
      "epoch:  58, avg_PSNR: 26.875539, time for epoch: 35.55\n",
      "epoch:  59, avg_PSNR: 26.877292, time for epoch: 35.33\n",
      "epoch:  60, avg_PSNR: 26.890335, time for epoch: 35.56\n",
      "epoch:  61, avg_PSNR: 26.892799, time for epoch: 35.82\n",
      "epoch:  62, avg_PSNR: 26.898217, time for epoch: 35.89\n",
      "epoch:  63, avg_PSNR: 26.907557, time for epoch: 35.66\n",
      "epoch:  64, avg_PSNR: 26.922563, time for epoch: 36.18\n",
      "epoch:  65, avg_PSNR: 26.914840, time for epoch: 35.83\n",
      "epoch:  66, avg_PSNR: 26.930735, time for epoch: 35.59\n",
      "epoch:  67, avg_PSNR: 26.943000, time for epoch: 35.77\n",
      "epoch:  68, avg_PSNR: 26.937978, time for epoch: 36.12\n",
      "epoch:  69, avg_PSNR: 26.959373, time for epoch: 35.90\n",
      "epoch:  70, avg_PSNR: 26.961318, time for epoch: 35.70\n",
      "epoch:  71, avg_PSNR: 26.953133, time for epoch: 35.91\n",
      "epoch:  72, avg_PSNR: 26.983865, time for epoch: 35.73\n",
      "epoch:  73, avg_PSNR: 26.965501, time for epoch: 36.05\n",
      "epoch:  74, avg_PSNR: 26.983922, time for epoch: 35.93\n",
      "epoch:  75, avg_PSNR: 26.988266, time for epoch: 35.76\n",
      "epoch:  76, avg_PSNR: 26.996662, time for epoch: 35.67\n",
      "epoch:  77, avg_PSNR: 27.009618, time for epoch: 35.92\n",
      "epoch:  78, avg_PSNR: 26.998622, time for epoch: 36.19\n",
      "epoch:  79, avg_PSNR: 27.019939, time for epoch: 35.69\n",
      "epoch:  80, avg_PSNR: 27.019633, time for epoch: 36.20\n",
      "epoch:  81, avg_PSNR: 27.020867, time for epoch: 35.66\n",
      "epoch:  82, avg_PSNR: 27.039880, time for epoch: 35.85\n",
      "epoch:  83, avg_PSNR: 27.028454, time for epoch: 35.91\n",
      "epoch:  84, avg_PSNR: 27.042277, time for epoch: 35.86\n",
      "epoch:  85, avg_PSNR: 27.044778, time for epoch: 35.83\n",
      "epoch:  86, avg_PSNR: 27.054198, time for epoch: 35.96\n",
      "epoch:  87, avg_PSNR: 27.054564, time for epoch: 35.63\n",
      "epoch:  88, avg_PSNR: 27.078376, time for epoch: 35.75\n",
      "epoch:  89, avg_PSNR: 27.056220, time for epoch: 35.77\n",
      "epoch:  90, avg_PSNR: 27.086184, time for epoch: 35.96\n",
      "epoch:  91, avg_PSNR: 27.063932, time for epoch: 36.03\n",
      "epoch:  92, avg_PSNR: 27.083872, time for epoch: 35.95\n",
      "epoch:  93, avg_PSNR: 27.094209, time for epoch: 35.74\n",
      "epoch:  94, avg_PSNR: 27.094465, time for epoch: 35.92\n",
      "epoch:  95, avg_PSNR: 27.106279, time for epoch: 35.91\n",
      "epoch:  96, avg_PSNR: 27.098492, time for epoch: 35.91\n",
      "epoch:  97, avg_PSNR: 27.104290, time for epoch: 35.85\n",
      "epoch:  98, avg_PSNR: 27.115912, time for epoch: 36.03\n",
      "epoch:  99, avg_PSNR: 27.114767, time for epoch: 35.80\n",
      "epoch: 100, avg_PSNR: 27.132713, time for epoch: 35.71\n",
      "epoch: 101, avg_PSNR: 27.126377, time for epoch: 36.00\n",
      "epoch: 102, avg_PSNR: 27.121237, time for epoch: 35.66\n",
      "epoch: 103, avg_PSNR: 27.141845, time for epoch: 35.97\n",
      "epoch: 104, avg_PSNR: 27.139318, time for epoch: 35.98\n",
      "epoch: 105, avg_PSNR: 27.147586, time for epoch: 35.95\n",
      "epoch: 106, avg_PSNR: 27.146314, time for epoch: 35.88\n",
      "epoch: 107, avg_PSNR: 27.154457, time for epoch: 35.63\n",
      "epoch: 108, avg_PSNR: 27.154638, time for epoch: 35.80\n",
      "epoch: 109, avg_PSNR: 27.160743, time for epoch: 36.17\n",
      "epoch: 110, avg_PSNR: 27.167344, time for epoch: 35.93\n",
      "epoch: 111, avg_PSNR: 27.168753, time for epoch: 36.25\n",
      "epoch: 112, avg_PSNR: 27.180346, time for epoch: 35.85\n",
      "epoch: 113, avg_PSNR: 27.168782, time for epoch: 36.00\n",
      "epoch: 114, avg_PSNR: 27.183308, time for epoch: 35.86\n",
      "epoch: 115, avg_PSNR: 27.189942, time for epoch: 35.71\n",
      "epoch: 116, avg_PSNR: 27.191056, time for epoch: 35.68\n",
      "epoch: 117, avg_PSNR: 27.186716, time for epoch: 35.68\n",
      "epoch: 118, avg_PSNR: 27.206247, time for epoch: 36.20\n",
      "epoch: 119, avg_PSNR: 27.199114, time for epoch: 35.78\n",
      "epoch: 120, avg_PSNR: 27.208794, time for epoch: 36.20\n",
      "epoch: 121, avg_PSNR: 27.199958, time for epoch: 35.76\n",
      "epoch: 122, avg_PSNR: 27.208494, time for epoch: 36.06\n",
      "epoch: 123, avg_PSNR: 27.233118, time for epoch: 36.06\n",
      "epoch: 124, avg_PSNR: 27.213636, time for epoch: 35.95\n",
      "epoch: 125, avg_PSNR: 27.207433, time for epoch: 35.88\n",
      "epoch: 126, avg_PSNR: 27.231868, time for epoch: 35.69\n",
      "epoch: 127, avg_PSNR: 27.239248, time for epoch: 35.74\n",
      "epoch: 128, avg_PSNR: 27.229086, time for epoch: 35.62\n",
      "epoch: 129, avg_PSNR: 27.243161, time for epoch: 35.82\n",
      "epoch: 130, avg_PSNR: 27.237574, time for epoch: 35.86\n",
      "epoch: 131, avg_PSNR: 27.245550, time for epoch: 36.03\n",
      "epoch: 132, avg_PSNR: 27.246258, time for epoch: 35.95\n",
      "epoch: 133, avg_PSNR: 27.254922, time for epoch: 35.95\n",
      "epoch: 134, avg_PSNR: 27.241747, time for epoch: 36.10\n",
      "epoch: 135, avg_PSNR: 27.263774, time for epoch: 35.93\n",
      "epoch: 136, avg_PSNR: 27.248435, time for epoch: 35.66\n",
      "epoch: 137, avg_PSNR: 27.274193, time for epoch: 38.84\n",
      "epoch: 138, avg_PSNR: 27.262674, time for epoch: 39.25\n",
      "epoch: 139, avg_PSNR: 27.260350, time for epoch: 39.13\n",
      "epoch: 140, avg_PSNR: 27.277692, time for epoch: 39.36\n",
      "epoch: 141, avg_PSNR: 27.270007, time for epoch: 39.26\n",
      "epoch: 142, avg_PSNR: 27.273805, time for epoch: 39.04\n",
      "epoch: 143, avg_PSNR: 27.282996, time for epoch: 39.13\n",
      "epoch: 144, avg_PSNR: 27.285721, time for epoch: 39.18\n",
      "epoch: 145, avg_PSNR: 27.289481, time for epoch: 38.89\n",
      "epoch: 146, avg_PSNR: 27.271502, time for epoch: 39.16\n",
      "epoch: 147, avg_PSNR: 27.310542, time for epoch: 39.60\n",
      "epoch: 148, avg_PSNR: 27.292243, time for epoch: 39.11\n",
      "epoch: 149, avg_PSNR: 27.301325, time for epoch: 38.94\n",
      "epoch: 150, avg_PSNR: 27.306647, time for epoch: 39.47\n",
      "epoch: 151, avg_PSNR: 27.302926, time for epoch: 39.39\n",
      "epoch: 152, avg_PSNR: 27.315737, time for epoch: 39.13\n",
      "epoch: 153, avg_PSNR: 27.305959, time for epoch: 39.35\n",
      "epoch: 154, avg_PSNR: 27.311372, time for epoch: 39.41\n",
      "epoch: 155, avg_PSNR: 27.321134, time for epoch: 39.11\n",
      "epoch: 156, avg_PSNR: 27.326334, time for epoch: 39.12\n",
      "epoch: 157, avg_PSNR: 27.314584, time for epoch: 39.63\n",
      "epoch: 158, avg_PSNR: 27.337555, time for epoch: 39.20\n",
      "epoch: 159, avg_PSNR: 27.317385, time for epoch: 39.24\n",
      "epoch: 160, avg_PSNR: 27.341489, time for epoch: 39.46\n",
      "epoch: 161, avg_PSNR: 27.329755, time for epoch: 39.36\n",
      "epoch: 162, avg_PSNR: 27.328916, time for epoch: 39.57\n",
      "epoch: 163, avg_PSNR: 27.340008, time for epoch: 39.36\n",
      "epoch: 164, avg_PSNR: 27.347256, time for epoch: 39.05\n",
      "epoch: 165, avg_PSNR: 27.340262, time for epoch: 39.33\n",
      "epoch: 166, avg_PSNR: 27.349518, time for epoch: 39.36\n",
      "epoch: 167, avg_PSNR: 27.352722, time for epoch: 38.85\n",
      "epoch: 168, avg_PSNR: 27.341241, time for epoch: 39.14\n",
      "epoch: 169, avg_PSNR: 27.357283, time for epoch: 39.02\n",
      "epoch: 170, avg_PSNR: 27.355207, time for epoch: 39.38\n",
      "epoch: 171, avg_PSNR: 27.360796, time for epoch: 39.13\n",
      "epoch: 172, avg_PSNR: 27.364594, time for epoch: 39.20\n",
      "epoch: 173, avg_PSNR: 27.364882, time for epoch: 39.32\n",
      "epoch: 174, avg_PSNR: 27.365838, time for epoch: 39.26\n",
      "epoch: 175, avg_PSNR: 27.363410, time for epoch: 39.26\n",
      "epoch: 176, avg_PSNR: 27.371220, time for epoch: 39.40\n",
      "epoch: 177, avg_PSNR: 27.383774, time for epoch: 39.25\n",
      "epoch: 178, avg_PSNR: 27.377110, time for epoch: 39.12\n",
      "epoch: 179, avg_PSNR: 27.377337, time for epoch: 39.55\n",
      "epoch: 180, avg_PSNR: 27.374876, time for epoch: 39.01\n",
      "epoch: 181, avg_PSNR: 27.371441, time for epoch: 39.08\n",
      "epoch: 182, avg_PSNR: 27.400920, time for epoch: 39.16\n",
      "epoch: 183, avg_PSNR: 27.387191, time for epoch: 39.18\n",
      "epoch: 184, avg_PSNR: 27.390397, time for epoch: 39.36\n",
      "epoch: 185, avg_PSNR: 27.384014, time for epoch: 38.75\n",
      "epoch: 186, avg_PSNR: 27.396821, time for epoch: 39.47\n",
      "epoch: 187, avg_PSNR: 27.382926, time for epoch: 39.22\n",
      "epoch: 188, avg_PSNR: 27.402294, time for epoch: 39.17\n",
      "epoch: 189, avg_PSNR: 27.396581, time for epoch: 39.50\n",
      "epoch: 190, avg_PSNR: 27.412068, time for epoch: 39.22\n",
      "epoch: 191, avg_PSNR: 27.406444, time for epoch: 39.34\n",
      "epoch: 192, avg_PSNR: 27.407862, time for epoch: 39.28\n",
      "epoch: 193, avg_PSNR: 27.409568, time for epoch: 39.31\n",
      "epoch: 194, avg_PSNR: 27.405251, time for epoch: 39.42\n",
      "epoch: 195, avg_PSNR: 27.415454, time for epoch: 39.39\n",
      "epoch: 196, avg_PSNR: 27.413210, time for epoch: 39.42\n",
      "epoch: 197, avg_PSNR: 27.417904, time for epoch: 39.64\n",
      "epoch: 198, avg_PSNR: 27.428858, time for epoch: 39.62\n",
      "epoch: 199, avg_PSNR: 27.421085, time for epoch: 39.55\n",
      "epoch: 200, avg_PSNR: 27.411789, time for epoch: 39.65\n",
      "epoch: 201, avg_PSNR: 27.430332, time for epoch: 39.62\n",
      "epoch: 202, avg_PSNR: 27.432761, time for epoch: 39.38\n",
      "epoch: 203, avg_PSNR: 27.422868, time for epoch: 39.55\n",
      "epoch: 204, avg_PSNR: 27.437181, time for epoch: 39.22\n",
      "epoch: 205, avg_PSNR: 27.431661, time for epoch: 39.44\n",
      "epoch: 206, avg_PSNR: 27.434669, time for epoch: 40.06\n",
      "epoch: 207, avg_PSNR: 27.435763, time for epoch: 39.41\n",
      "epoch: 208, avg_PSNR: 27.436808, time for epoch: 39.94\n",
      "epoch: 209, avg_PSNR: 27.455122, time for epoch: 39.63\n",
      "epoch: 210, avg_PSNR: 27.437906, time for epoch: 39.91\n",
      "epoch: 211, avg_PSNR: 27.442202, time for epoch: 39.38\n",
      "epoch: 212, avg_PSNR: 27.446038, time for epoch: 39.32\n",
      "epoch: 213, avg_PSNR: 27.450997, time for epoch: 39.06\n",
      "epoch: 214, avg_PSNR: 27.460212, time for epoch: 39.43\n",
      "epoch: 215, avg_PSNR: 27.446139, time for epoch: 39.59\n",
      "epoch: 216, avg_PSNR: 27.454116, time for epoch: 39.15\n",
      "epoch: 217, avg_PSNR: 27.459104, time for epoch: 39.21\n",
      "epoch: 218, avg_PSNR: 27.462664, time for epoch: 39.18\n",
      "epoch: 219, avg_PSNR: 27.458840, time for epoch: 39.24\n",
      "epoch: 220, avg_PSNR: 27.471806, time for epoch: 39.79\n",
      "epoch: 221, avg_PSNR: 27.462708, time for epoch: 39.34\n",
      "epoch: 222, avg_PSNR: 27.462483, time for epoch: 39.17\n",
      "epoch: 223, avg_PSNR: 27.473924, time for epoch: 39.43\n",
      "epoch: 224, avg_PSNR: 27.461306, time for epoch: 39.21\n",
      "epoch: 225, avg_PSNR: 27.479607, time for epoch: 39.09\n",
      "epoch: 226, avg_PSNR: 27.472996, time for epoch: 39.47\n",
      "epoch: 227, avg_PSNR: 27.476985, time for epoch: 39.05\n",
      "epoch: 228, avg_PSNR: 27.475945, time for epoch: 39.12\n",
      "epoch: 229, avg_PSNR: 27.480452, time for epoch: 39.20\n",
      "epoch: 230, avg_PSNR: 27.485630, time for epoch: 39.44\n",
      "epoch: 231, avg_PSNR: 27.479874, time for epoch: 39.29\n",
      "epoch: 232, avg_PSNR: 27.483855, time for epoch: 39.56\n",
      "epoch: 233, avg_PSNR: 27.480139, time for epoch: 39.24\n",
      "epoch: 234, avg_PSNR: 27.494957, time for epoch: 39.26\n",
      "epoch: 235, avg_PSNR: 27.485916, time for epoch: 38.91\n",
      "epoch: 236, avg_PSNR: 27.489469, time for epoch: 39.61\n",
      "epoch: 237, avg_PSNR: 27.496129, time for epoch: 39.57\n",
      "epoch: 238, avg_PSNR: 27.494868, time for epoch: 39.32\n",
      "epoch: 239, avg_PSNR: 27.496375, time for epoch: 39.06\n",
      "epoch: 240, avg_PSNR: 27.498685, time for epoch: 39.40\n",
      "epoch: 241, avg_PSNR: 27.499823, time for epoch: 39.37\n",
      "epoch: 242, avg_PSNR: 27.498597, time for epoch: 39.24\n",
      "epoch: 243, avg_PSNR: 27.510118, time for epoch: 39.29\n",
      "epoch: 244, avg_PSNR: 27.500059, time for epoch: 39.36\n",
      "epoch: 245, avg_PSNR: 27.510713, time for epoch: 38.97\n",
      "epoch: 246, avg_PSNR: 27.505501, time for epoch: 39.59\n",
      "epoch: 247, avg_PSNR: 27.504851, time for epoch: 39.57\n",
      "epoch: 248, avg_PSNR: 27.514287, time for epoch: 39.16\n",
      "epoch: 249, avg_PSNR: 27.508330, time for epoch: 39.16\n",
      "epoch: 250, avg_PSNR: 27.517317, time for epoch: 39.02\n",
      "epoch: 251, avg_PSNR: 27.520480, time for epoch: 39.15\n",
      "epoch: 252, avg_PSNR: 27.518723, time for epoch: 39.45\n",
      "epoch: 253, avg_PSNR: 27.514360, time for epoch: 39.36\n",
      "epoch: 254, avg_PSNR: 27.514756, time for epoch: 39.16\n",
      "epoch: 255, avg_PSNR: 27.523822, time for epoch: 39.30\n",
      "epoch: 256, avg_PSNR: 27.522560, time for epoch: 39.10\n",
      "epoch: 257, avg_PSNR: 27.528884, time for epoch: 39.44\n",
      "epoch: 258, avg_PSNR: 27.517588, time for epoch: 39.42\n",
      "epoch: 259, avg_PSNR: 27.531742, time for epoch: 39.45\n",
      "epoch: 260, avg_PSNR: 27.529930, time for epoch: 39.34\n",
      "epoch: 261, avg_PSNR: 27.529001, time for epoch: 39.05\n",
      "epoch: 262, avg_PSNR: 27.533207, time for epoch: 39.11\n",
      "epoch: 263, avg_PSNR: 27.537049, time for epoch: 39.32\n",
      "epoch: 264, avg_PSNR: 27.537110, time for epoch: 39.54\n",
      "epoch: 265, avg_PSNR: 27.539949, time for epoch: 39.33\n",
      "epoch: 266, avg_PSNR: 27.537474, time for epoch: 39.38\n",
      "epoch: 267, avg_PSNR: 27.550204, time for epoch: 39.17\n",
      "epoch: 268, avg_PSNR: 27.540067, time for epoch: 39.14\n",
      "epoch: 269, avg_PSNR: 27.539318, time for epoch: 39.33\n",
      "epoch: 270, avg_PSNR: 27.546821, time for epoch: 39.74\n",
      "epoch: 271, avg_PSNR: 27.550036, time for epoch: 39.24\n",
      "epoch: 272, avg_PSNR: 27.548359, time for epoch: 39.50\n",
      "epoch: 273, avg_PSNR: 27.550941, time for epoch: 39.17\n",
      "epoch: 274, avg_PSNR: 27.554866, time for epoch: 39.14\n",
      "epoch: 275, avg_PSNR: 27.543857, time for epoch: 39.15\n",
      "epoch: 276, avg_PSNR: 27.551097, time for epoch: 39.26\n",
      "epoch: 277, avg_PSNR: 27.559331, time for epoch: 39.32\n",
      "epoch: 278, avg_PSNR: 27.559845, time for epoch: 39.21\n",
      "epoch: 279, avg_PSNR: 27.561428, time for epoch: 39.17\n",
      "epoch: 280, avg_PSNR: 27.549136, time for epoch: 39.12\n",
      "epoch: 281, avg_PSNR: 27.562889, time for epoch: 40.86\n",
      "epoch: 282, avg_PSNR: 27.560193, time for epoch: 38.83\n",
      "epoch: 283, avg_PSNR: 27.572305, time for epoch: 38.58\n",
      "epoch: 284, avg_PSNR: 27.569000, time for epoch: 39.33\n",
      "epoch: 285, avg_PSNR: 27.564673, time for epoch: 39.13\n",
      "epoch: 286, avg_PSNR: 27.565059, time for epoch: 38.99\n",
      "epoch: 287, avg_PSNR: 27.579006, time for epoch: 38.80\n",
      "epoch: 288, avg_PSNR: 27.560839, time for epoch: 39.01\n",
      "epoch: 289, avg_PSNR: 27.578233, time for epoch: 38.68\n",
      "epoch: 290, avg_PSNR: 27.572255, time for epoch: 38.61\n",
      "epoch: 291, avg_PSNR: 27.568188, time for epoch: 39.07\n",
      "epoch: 292, avg_PSNR: 27.583562, time for epoch: 38.65\n",
      "epoch: 293, avg_PSNR: 27.572264, time for epoch: 39.37\n",
      "epoch: 294, avg_PSNR: 27.580737, time for epoch: 39.10\n",
      "epoch: 295, avg_PSNR: 27.584713, time for epoch: 39.02\n",
      "epoch: 296, avg_PSNR: 27.587455, time for epoch: 38.98\n",
      "epoch: 297, avg_PSNR: 27.572774, time for epoch: 38.89\n",
      "epoch: 298, avg_PSNR: 27.589563, time for epoch: 38.96\n",
      "epoch: 299, avg_PSNR: 27.598715, time for epoch: 38.66\n",
      "epoch: 300, avg_PSNR: 27.579708, time for epoch: 39.03\n",
      "epoch: 301, avg_PSNR: 27.586955, time for epoch: 38.87\n",
      "epoch: 302, avg_PSNR: 27.586160, time for epoch: 39.27\n",
      "epoch: 303, avg_PSNR: 27.595031, time for epoch: 38.88\n",
      "epoch: 304, avg_PSNR: 27.591897, time for epoch: 39.17\n",
      "epoch: 305, avg_PSNR: 27.593421, time for epoch: 39.32\n",
      "epoch: 306, avg_PSNR: 27.599005, time for epoch: 39.46\n",
      "epoch: 307, avg_PSNR: 27.588287, time for epoch: 39.29\n",
      "epoch: 308, avg_PSNR: 27.598115, time for epoch: 39.51\n",
      "epoch: 309, avg_PSNR: 27.601027, time for epoch: 39.32\n",
      "epoch: 310, avg_PSNR: 27.593319, time for epoch: 39.55\n",
      "epoch: 311, avg_PSNR: 27.613403, time for epoch: 39.35\n",
      "epoch: 312, avg_PSNR: 27.603502, time for epoch: 39.28\n",
      "epoch: 313, avg_PSNR: 27.599798, time for epoch: 39.03\n",
      "epoch: 314, avg_PSNR: 27.605486, time for epoch: 39.61\n",
      "epoch: 315, avg_PSNR: 27.605455, time for epoch: 39.55\n",
      "epoch: 316, avg_PSNR: 27.612155, time for epoch: 39.26\n",
      "epoch: 317, avg_PSNR: 27.598709, time for epoch: 39.00\n",
      "epoch: 318, avg_PSNR: 27.621289, time for epoch: 38.74\n",
      "epoch: 319, avg_PSNR: 27.610846, time for epoch: 39.07\n",
      "epoch: 320, avg_PSNR: 27.614267, time for epoch: 39.11\n",
      "epoch: 321, avg_PSNR: 27.605566, time for epoch: 39.15\n",
      "epoch: 322, avg_PSNR: 27.628949, time for epoch: 38.88\n",
      "epoch: 323, avg_PSNR: 27.611017, time for epoch: 39.31\n",
      "epoch: 324, avg_PSNR: 27.620240, time for epoch: 39.23\n",
      "epoch: 325, avg_PSNR: 27.617862, time for epoch: 39.26\n",
      "epoch: 326, avg_PSNR: 27.622890, time for epoch: 39.30\n",
      "epoch: 327, avg_PSNR: 27.618419, time for epoch: 39.11\n",
      "epoch: 328, avg_PSNR: 27.629718, time for epoch: 38.86\n",
      "epoch: 329, avg_PSNR: 27.624837, time for epoch: 38.89\n",
      "epoch: 330, avg_PSNR: 27.623957, time for epoch: 39.10\n",
      "epoch: 331, avg_PSNR: 27.625347, time for epoch: 39.00\n",
      "epoch: 332, avg_PSNR: 27.633828, time for epoch: 39.05\n",
      "epoch: 333, avg_PSNR: 27.631030, time for epoch: 38.98\n",
      "epoch: 334, avg_PSNR: 27.631121, time for epoch: 39.29\n",
      "epoch: 335, avg_PSNR: 27.629869, time for epoch: 39.11\n",
      "epoch: 336, avg_PSNR: 27.631835, time for epoch: 39.18\n",
      "epoch: 337, avg_PSNR: 27.634994, time for epoch: 39.41\n",
      "epoch: 338, avg_PSNR: 27.633717, time for epoch: 39.15\n",
      "epoch: 339, avg_PSNR: 27.633517, time for epoch: 39.45\n",
      "epoch: 340, avg_PSNR: 27.643821, time for epoch: 39.21\n",
      "epoch: 341, avg_PSNR: 27.635044, time for epoch: 39.40\n",
      "epoch: 342, avg_PSNR: 27.645393, time for epoch: 39.26\n",
      "epoch: 343, avg_PSNR: 27.644629, time for epoch: 39.29\n",
      "epoch: 344, avg_PSNR: 27.640667, time for epoch: 39.39\n",
      "epoch: 345, avg_PSNR: 27.643370, time for epoch: 39.30\n",
      "epoch: 346, avg_PSNR: 27.641256, time for epoch: 39.72\n",
      "epoch: 347, avg_PSNR: 27.651640, time for epoch: 39.26\n",
      "epoch: 348, avg_PSNR: 27.643155, time for epoch: 39.23\n",
      "epoch: 349, avg_PSNR: 27.649544, time for epoch: 38.99\n",
      "epoch: 350, avg_PSNR: 27.648856, time for epoch: 39.15\n",
      "epoch: 351, avg_PSNR: 27.658434, time for epoch: 39.20\n",
      "epoch: 352, avg_PSNR: 27.649712, time for epoch: 38.92\n",
      "epoch: 353, avg_PSNR: 27.647964, time for epoch: 39.28\n",
      "epoch: 354, avg_PSNR: 27.650792, time for epoch: 39.16\n",
      "epoch: 355, avg_PSNR: 27.659427, time for epoch: 39.02\n",
      "epoch: 356, avg_PSNR: 27.652316, time for epoch: 38.95\n",
      "epoch: 357, avg_PSNR: 27.661071, time for epoch: 39.27\n",
      "epoch: 358, avg_PSNR: 27.657692, time for epoch: 39.21\n",
      "epoch: 359, avg_PSNR: 27.657293, time for epoch: 39.05\n",
      "epoch: 360, avg_PSNR: 27.668040, time for epoch: 39.08\n",
      "epoch: 361, avg_PSNR: 27.664701, time for epoch: 39.21\n",
      "epoch: 362, avg_PSNR: 27.652548, time for epoch: 38.97\n",
      "epoch: 363, avg_PSNR: 27.662572, time for epoch: 39.21\n",
      "epoch: 364, avg_PSNR: 27.677105, time for epoch: 39.26\n",
      "epoch: 365, avg_PSNR: 27.657786, time for epoch: 39.22\n",
      "epoch: 366, avg_PSNR: 27.675512, time for epoch: 38.98\n",
      "epoch: 367, avg_PSNR: 27.670127, time for epoch: 39.09\n",
      "epoch: 368, avg_PSNR: 27.665454, time for epoch: 39.16\n",
      "epoch: 369, avg_PSNR: 27.677255, time for epoch: 39.06\n",
      "epoch: 370, avg_PSNR: 27.670238, time for epoch: 39.08\n",
      "epoch: 371, avg_PSNR: 27.678617, time for epoch: 39.25\n",
      "epoch: 372, avg_PSNR: 27.669162, time for epoch: 39.43\n",
      "epoch: 373, avg_PSNR: 27.670062, time for epoch: 39.22\n",
      "epoch: 374, avg_PSNR: 27.685872, time for epoch: 39.55\n",
      "epoch: 375, avg_PSNR: 27.676048, time for epoch: 39.18\n",
      "epoch: 376, avg_PSNR: 27.677111, time for epoch: 39.22\n",
      "epoch: 377, avg_PSNR: 27.677191, time for epoch: 39.17\n",
      "epoch: 378, avg_PSNR: 27.680840, time for epoch: 39.14\n",
      "epoch: 379, avg_PSNR: 27.674653, time for epoch: 39.58\n",
      "epoch: 380, avg_PSNR: 27.693474, time for epoch: 38.90\n",
      "epoch: 381, avg_PSNR: 27.687022, time for epoch: 39.14\n",
      "epoch: 382, avg_PSNR: 27.684376, time for epoch: 39.02\n",
      "epoch: 383, avg_PSNR: 27.684446, time for epoch: 39.09\n",
      "epoch: 384, avg_PSNR: 27.691289, time for epoch: 39.36\n",
      "epoch: 385, avg_PSNR: 27.691850, time for epoch: 39.15\n",
      "epoch: 386, avg_PSNR: 27.687548, time for epoch: 39.06\n",
      "epoch: 387, avg_PSNR: 27.696733, time for epoch: 39.45\n",
      "epoch: 388, avg_PSNR: 27.690236, time for epoch: 39.43\n",
      "epoch: 389, avg_PSNR: 27.697556, time for epoch: 38.90\n",
      "epoch: 390, avg_PSNR: 27.686503, time for epoch: 39.25\n",
      "epoch: 391, avg_PSNR: 27.697079, time for epoch: 39.34\n",
      "epoch: 392, avg_PSNR: 27.695478, time for epoch: 39.16\n",
      "epoch: 393, avg_PSNR: 27.695583, time for epoch: 39.59\n",
      "epoch: 394, avg_PSNR: 27.683322, time for epoch: 39.70\n",
      "epoch: 395, avg_PSNR: 27.718537, time for epoch: 39.45\n",
      "epoch: 396, avg_PSNR: 27.690436, time for epoch: 39.15\n",
      "epoch: 397, avg_PSNR: 27.693160, time for epoch: 39.17\n",
      "epoch: 398, avg_PSNR: 27.710818, time for epoch: 39.38\n",
      "epoch: 399, avg_PSNR: 27.698090, time for epoch: 39.24\n",
      "epoch: 400, avg_PSNR: 27.704691, time for epoch: 39.13\n",
      "epoch: 401, avg_PSNR: 27.713935, time for epoch: 39.04\n",
      "epoch: 402, avg_PSNR: 27.699261, time for epoch: 39.49\n",
      "epoch: 403, avg_PSNR: 27.710470, time for epoch: 39.58\n",
      "epoch: 404, avg_PSNR: 27.714057, time for epoch: 39.17\n",
      "epoch: 405, avg_PSNR: 27.699535, time for epoch: 39.33\n",
      "epoch: 406, avg_PSNR: 27.714203, time for epoch: 39.34\n",
      "epoch: 407, avg_PSNR: 27.723593, time for epoch: 38.91\n",
      "epoch: 408, avg_PSNR: 27.697250, time for epoch: 39.38\n",
      "epoch: 409, avg_PSNR: 27.723664, time for epoch: 39.67\n",
      "epoch: 410, avg_PSNR: 27.704859, time for epoch: 39.13\n",
      "epoch: 411, avg_PSNR: 27.721616, time for epoch: 39.56\n",
      "epoch: 412, avg_PSNR: 27.721957, time for epoch: 38.79\n",
      "epoch: 413, avg_PSNR: 27.712138, time for epoch: 39.99\n",
      "epoch: 414, avg_PSNR: 27.715991, time for epoch: 39.42\n",
      "epoch: 415, avg_PSNR: 27.722619, time for epoch: 39.27\n",
      "epoch: 416, avg_PSNR: 27.727009, time for epoch: 39.20\n",
      "epoch: 417, avg_PSNR: 27.714364, time for epoch: 39.56\n",
      "epoch: 418, avg_PSNR: 27.722242, time for epoch: 39.36\n",
      "epoch: 419, avg_PSNR: 27.727027, time for epoch: 39.51\n",
      "epoch: 420, avg_PSNR: 27.727157, time for epoch: 39.24\n",
      "epoch: 421, avg_PSNR: 27.718259, time for epoch: 39.11\n",
      "epoch: 422, avg_PSNR: 27.727074, time for epoch: 39.55\n",
      "epoch: 423, avg_PSNR: 27.723367, time for epoch: 39.32\n",
      "epoch: 424, avg_PSNR: 27.732796, time for epoch: 39.14\n",
      "epoch: 425, avg_PSNR: 27.726503, time for epoch: 38.94\n",
      "epoch: 426, avg_PSNR: 27.725452, time for epoch: 39.33\n",
      "epoch: 427, avg_PSNR: 27.732427, time for epoch: 39.49\n",
      "epoch: 428, avg_PSNR: 27.731595, time for epoch: 39.03\n",
      "epoch: 429, avg_PSNR: 27.735801, time for epoch: 39.10\n",
      "epoch: 430, avg_PSNR: 27.732065, time for epoch: 39.60\n",
      "epoch: 431, avg_PSNR: 27.737854, time for epoch: 39.42\n",
      "epoch: 432, avg_PSNR: 27.735770, time for epoch: 39.63\n",
      "epoch: 433, avg_PSNR: 27.736554, time for epoch: 39.29\n",
      "epoch: 434, avg_PSNR: 27.733714, time for epoch: 39.18\n",
      "epoch: 435, avg_PSNR: 27.737137, time for epoch: 39.04\n",
      "epoch: 436, avg_PSNR: 27.743206, time for epoch: 39.41\n",
      "epoch: 437, avg_PSNR: 27.737189, time for epoch: 39.46\n",
      "epoch: 438, avg_PSNR: 27.736934, time for epoch: 39.19\n",
      "epoch: 439, avg_PSNR: 27.748757, time for epoch: 39.20\n",
      "epoch: 440, avg_PSNR: 27.732888, time for epoch: 39.54\n",
      "epoch: 441, avg_PSNR: 27.741478, time for epoch: 39.11\n",
      "epoch: 442, avg_PSNR: 27.759396, time for epoch: 39.33\n",
      "epoch: 443, avg_PSNR: 27.732100, time for epoch: 39.10\n",
      "epoch: 444, avg_PSNR: 27.747919, time for epoch: 38.96\n",
      "epoch: 445, avg_PSNR: 27.746940, time for epoch: 39.19\n",
      "epoch: 446, avg_PSNR: 27.752323, time for epoch: 39.20\n",
      "epoch: 447, avg_PSNR: 27.741418, time for epoch: 39.27\n",
      "epoch: 448, avg_PSNR: 27.754774, time for epoch: 39.38\n",
      "epoch: 449, avg_PSNR: 27.752607, time for epoch: 39.18\n",
      "epoch: 450, avg_PSNR: 27.756882, time for epoch: 39.30\n",
      "epoch: 451, avg_PSNR: 27.743352, time for epoch: 39.62\n",
      "epoch: 452, avg_PSNR: 27.759067, time for epoch: 39.13\n",
      "epoch: 453, avg_PSNR: 27.749508, time for epoch: 39.34\n",
      "epoch: 454, avg_PSNR: 27.758663, time for epoch: 39.21\n",
      "epoch: 455, avg_PSNR: 27.760040, time for epoch: 39.10\n",
      "epoch: 456, avg_PSNR: 27.756030, time for epoch: 39.33\n",
      "epoch: 457, avg_PSNR: 27.758129, time for epoch: 39.20\n",
      "epoch: 458, avg_PSNR: 27.761313, time for epoch: 39.02\n",
      "epoch: 459, avg_PSNR: 27.765137, time for epoch: 38.91\n",
      "epoch: 460, avg_PSNR: 27.749137, time for epoch: 39.15\n",
      "epoch: 461, avg_PSNR: 27.771770, time for epoch: 38.99\n",
      "epoch: 462, avg_PSNR: 27.759136, time for epoch: 39.11\n",
      "epoch: 463, avg_PSNR: 27.770495, time for epoch: 38.96\n",
      "epoch: 464, avg_PSNR: 27.762417, time for epoch: 39.34\n",
      "epoch: 465, avg_PSNR: 27.765336, time for epoch: 39.17\n",
      "epoch: 466, avg_PSNR: 27.766382, time for epoch: 39.05\n",
      "epoch: 467, avg_PSNR: 27.768459, time for epoch: 39.36\n",
      "epoch: 468, avg_PSNR: 27.766537, time for epoch: 39.10\n",
      "epoch: 469, avg_PSNR: 27.771287, time for epoch: 38.93\n",
      "epoch: 470, avg_PSNR: 27.777012, time for epoch: 39.23\n",
      "epoch: 471, avg_PSNR: 27.768431, time for epoch: 39.60\n",
      "epoch: 472, avg_PSNR: 27.778287, time for epoch: 39.16\n",
      "epoch: 473, avg_PSNR: 27.763808, time for epoch: 39.05\n",
      "epoch: 474, avg_PSNR: 27.775690, time for epoch: 39.24\n",
      "epoch: 475, avg_PSNR: 27.779888, time for epoch: 39.00\n",
      "epoch: 476, avg_PSNR: 27.773208, time for epoch: 39.42\n",
      "epoch: 477, avg_PSNR: 27.771100, time for epoch: 39.09\n",
      "epoch: 478, avg_PSNR: 27.773538, time for epoch: 39.07\n",
      "epoch: 479, avg_PSNR: 27.772669, time for epoch: 39.45\n",
      "epoch: 480, avg_PSNR: 27.785923, time for epoch: 39.58\n",
      "epoch: 481, avg_PSNR: 27.782378, time for epoch: 39.33\n",
      "epoch: 482, avg_PSNR: 27.770112, time for epoch: 39.40\n",
      "epoch: 483, avg_PSNR: 27.788260, time for epoch: 39.14\n",
      "epoch: 484, avg_PSNR: 27.775304, time for epoch: 38.90\n",
      "epoch: 485, avg_PSNR: 27.796005, time for epoch: 39.08\n",
      "epoch: 486, avg_PSNR: 27.776668, time for epoch: 38.96\n",
      "epoch: 487, avg_PSNR: 27.780912, time for epoch: 39.35\n",
      "epoch: 488, avg_PSNR: 27.789751, time for epoch: 39.19\n",
      "epoch: 489, avg_PSNR: 27.782011, time for epoch: 39.20\n",
      "epoch: 490, avg_PSNR: 27.790089, time for epoch: 39.19\n",
      "epoch: 491, avg_PSNR: 27.789233, time for epoch: 39.31\n",
      "epoch: 492, avg_PSNR: 27.791446, time for epoch: 39.42\n",
      "epoch: 493, avg_PSNR: 27.775259, time for epoch: 39.15\n",
      "epoch: 494, avg_PSNR: 27.800584, time for epoch: 39.17\n",
      "epoch: 495, avg_PSNR: 27.779259, time for epoch: 39.15\n",
      "epoch: 496, avg_PSNR: 27.803923, time for epoch: 39.09\n",
      "epoch: 497, avg_PSNR: 27.785628, time for epoch: 40.54\n",
      "epoch: 498, avg_PSNR: 27.789599, time for epoch: 38.76\n",
      "epoch: 499, avg_PSNR: 27.797291, time for epoch: 38.84\n"
     ]
    }
   ],
   "source": [
    "batch_size=32\n",
    "total_iter = int(trImg.shape[0]/batch_size)-1\n",
    "learing_rate = 1e-5\n",
    "for epoch in range(500):\n",
    "    avg_psnr = 0\n",
    "    cnt=0\n",
    "    start_time = time.time()\n",
    "    for batch in range(total_iter):\n",
    "        trImg, _= mnist.train.next_batch(batch_size)\n",
    "        trImg = np.reshape(trImg, [-1, 28, 28, 1])\n",
    "        LRImg = Bicubic(toLR(trImg))\n",
    "        HRImg = trImg\n",
    "        cnt+=1\n",
    "        \n",
    "        _, loss = sess.run([optm, model.LOSS], feed_dict={model.LRImg:LRImg, model.HRImg: HRImg, lr:learing_rate})\n",
    "        psnr = 20*np.log10(1./np.sqrt(loss))\n",
    "        print (\"\\rbatch: {}/{} ({:.1f}%) psnr: {:.5f}\".format(batch, total_iter, batch*100/total_iter, psnr), end=\"\")\n",
    "        avg_psnr+=psnr\n",
    "    if epoch % 10 == 5:\n",
    "        learing_rate*=1\n",
    "    print ('\\repoch: %3d, avg_PSNR: %4f, time for epoch: %.2f' %(epoch, avg_psnr/(cnt+1e-8), time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'checkpoints/SRCNN/MNIST_psnr_21-09'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "saver.save(sess, 'checkpoints/SRCNN/MNIST_psnr_21-09')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/scipy/misc/pilutil.py:482: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if issubdtype(ts, int):\n",
      "/usr/local/lib/python3.5/dist-packages/scipy/misc/pilutil.py:485: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  elif issubdtype(type(size), float):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f358278a828>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3582864390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "showimg = mnist.test.images[0:32,:]\n",
    "hrimg = np.reshape(showimg, [-1, 28, 28, 1])\n",
    "lrimg = toLR(hrimg)\n",
    "lrimgbi=Bicubic(lrimg)\n",
    "srimg=sess.run(model.layer3, feed_dict={model.LRImg:lrimgbi})\n",
    "index=3\n",
    "\n",
    "plt.figure(figsize=[20,5])\n",
    "plt.subplot(1,3,1)\n",
    "plt.axis('off')\n",
    "plt.title('LR')\n",
    "plt.imshow(lrimg[index,:,:,0], cmap='gray')\n",
    "plt.subplot(1,3,2)\n",
    "plt.axis('off')\n",
    "plt.title('HR')\n",
    "plt.imshow(hrimg[index,:,:,0], cmap='gray')\n",
    "plt.subplot(1,3,3)\n",
    "plt.axis('off')\n",
    "plt.title('SR')\n",
    "plt.imshow(srimg[index,:,:,0], cmap='gray')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
