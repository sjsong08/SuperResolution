{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SRCapsNet - FCN (MNIST)\n",
    "![image](https://i.imgur.com/bGYVlDC.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "Training data set : 50000, Test data Set : 10000\n"
     ]
    }
   ],
   "source": [
    "import os, sys, time\n",
    "import numpy as np\n",
    "import scipy.ndimage, scipy.misc\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "slim = tf.contrib.slim\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"\n",
    "\n",
    "\n",
    "\n",
    "def unpickle(file):\n",
    "    with open(file, 'rb') as f:\n",
    "        data = pickle.load(f, encoding='latin1')\n",
    "        return data\n",
    "\n",
    "def load_cifar10_data(data_dir):\n",
    "    train_data = None\n",
    "    train_labels = []\n",
    "    \n",
    "    for i in range(1,6):\n",
    "        data_dic = unpickle(data_dir + \"/data_batch_{}\".format(i))\n",
    "        if i==1:\n",
    "            train_data = data_dic['data']\n",
    "        else:\n",
    "            train_data = np.vstack((train_data, data_dic['data']))\n",
    "        train_labels += data_dic['labels']\n",
    "    test_data_dic = unpickle(data_dir + \"/test_batch\")\n",
    "    test_data = test_data_dic['data']\n",
    "    test_labels = test_data_dic['labels']\n",
    "    \n",
    "    train_data = train_data.reshape((len(train_data), 3, 32, 32))\n",
    "    train_data = np.rollaxis(train_data, 1, 4)\n",
    "    train_labels = np.array(train_labels)\n",
    "    \n",
    "    test_data = test_data.reshape((len(test_data), 3, 32, 32))\n",
    "    test_data = np.rollaxis(test_data, 1, 4)\n",
    "    test_labels = np.array(test_labels)\n",
    "    \n",
    "    return train_data, train_labels, test_data, test_labels\n",
    "\n",
    "data_dir = '/ideaHome/Dropbox/SJ/ML/Cifar10/Data/cifar-10-batches-py'\n",
    "trImg, train_labels, teImg, test_labels = load_cifar10_data(data_dir)\n",
    "\n",
    "\n",
    "print(\"Training data set : %3d, Test data Set : %3d\" %(trImg.shape[0], teImg.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-8bf8ae5a5303>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def toLR(image, scale=2.):\n",
    "    if len(image.shape)==4:\n",
    "        num_sample = image.shape[0]\n",
    "        images = np.zeros([image.shape[0], int(image.shape[1]/scale), int(image.shape[2]/scale), image.shape[3]])\n",
    "        for i in range(num_sample):\n",
    "            images[i,:,:,0] = scipy.misc.imresize(image[i,:,:,0], 1/scale,'bicubic')\n",
    "        return images\n",
    "    else:\n",
    "        return scipy.misc.imresize(image, 1/scale, 'bicubic')\n",
    "    \n",
    "\n",
    "def Bicubic(image, scale=2):\n",
    "    if len(image.shape)==4:\n",
    "        bicImg=np.zeros([image.shape[0], image.shape[1]*scale, image.shape[2]*scale, image.shape[3]])\n",
    "        for i in range(image.shape[0]):\n",
    "            bicImg[i,:,:,:] = scipy.ndimage.interpolation.zoom(image[i,:,:,:], [scale, scale, 1], prefilter=False)\n",
    "    else:\n",
    "        bicImg = scipy.ndimage.interpolation.zoom(image, [scale,scale, 1], prefilter=False)\n",
    "    return bicImg\n",
    "\n",
    "def _phase_shift(I, r):\n",
    "    # Helper function with main phase shift operation\n",
    "    bsize, a, b, c = I.get_shape().as_list()\n",
    "    X = tf.reshape(I, (-1, a, b, r, r))\n",
    "    X = tf.transpose(X, (0, 1, 2, 4, 3))  # bsize, a, b, 1, 1\n",
    "    X = tf.split(X, a, 1)  # a, [bsize, b, r, r]\n",
    "    X = tf.concat([tf.squeeze(x) for x in X], axis=2)  # bsize, b, a*r, r\n",
    "    X = tf.split(X, b, 1)  # b, [bsize, a*r, r]\n",
    "    X = tf.concat([tf.squeeze(x) for x in X], axis=2)  # bsize, a*r, b*r\n",
    "    return tf.reshape(X, (-1, a*r, b*r, 1))\n",
    "\n",
    "def PS(X, r, color=False):\n",
    "  # Main OP that you can arbitrarily use in you tensorflow code\n",
    "    if color:\n",
    "        Xc = tf.split(X,3,3) #(3, 3, X)\n",
    "        X = tf.concat([_phase_shift(x, r) for x in Xc], axis=3)\n",
    "    else:\n",
    "        X = _phase_shift(X, r)\n",
    "    return X\n",
    "\n",
    "def squash(s, axis=-1, epsilon=1e-7, name=None):\n",
    "    with tf.name_scope(name, default_name=\"squash\"):\n",
    "        squared_norm = tf.reduce_sum(tf.square(s), axis=axis, keep_dims=True)\n",
    "        safe_norm = tf.sqrt(squared_norm + epsilon)\n",
    "        squash_factor = squared_norm / (1. + squared_norm)\n",
    "        unit_vector = s / safe_norm\n",
    "    return squash_factor * unit_vector\n",
    "\n",
    "def safe_norm(s, axis=-1, epsilon=1e-7, keep_dims=False, name=None):\n",
    "    with tf.name_scope(name, default_name=\"safe_norm\"):\n",
    "        squared_norm = tf.reduce_sum(tf.square(s), axis=axis,\n",
    "                                     keep_dims=keep_dims)\n",
    "        return tf.sqrt(squared_norm + epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/scipy/misc/pilutil.py:482: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if issubdtype(ts, int):\n",
      "/usr/local/lib/python3.5/dist-packages/scipy/misc/pilutil.py:485: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  elif issubdtype(type(size), float):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8dfad66a20>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8dfae767f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "testSample = np.reshape(mnist.train.images[0,:], [1,28,28,1])\n",
    "\n",
    "LRtestSample = toLR(testSample)\n",
    "\n",
    "UPtestSample = Bicubic(LRtestSample, 2)\n",
    "plt.figure(figsize=[20.,10])\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(testSample[0,:,:,0], cmap='gray')\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(LRtestSample[0,:,:,0], cmap='gray')\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(UPtestSample[0,:,:,0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SRCapsNet(object):\n",
    "    def __init__(self, mode):\n",
    "        self.LR_dim = (28,28,1)\n",
    "        self.HR_dim = (28,28,1)\n",
    "        self.batch_size = 16\n",
    "        self.mode = mode\n",
    "        \n",
    "        self.routing_iter = 2\n",
    "        self.caps1_num = 28*28*32\n",
    "        self.caps1_dim = 8\n",
    "        self.caps2_vec = 10\n",
    "        self.caps2_num = 1*1*self.caps2_vec\n",
    "        self.caps2_dim = 16\n",
    "        \n",
    "        self.W_init = tf.random_normal(shape=(1, self.caps1_num, self.caps2_num, self.caps2_dim, self.caps1_dim), \n",
    "                                      stddev = 0.1, dtype=tf.float32, name='W_init')\n",
    "        self.W = tf.Variable(self.W_init, name='w')\n",
    "        \n",
    "        print('The model is generated')\n",
    "        \n",
    "    def model(self, img):\n",
    "        with slim.arg_scope([slim.conv2d],kernel_size=[5,5], stride=[1,1], activation_fn = tf.nn.leaky_relu,\n",
    "                            padding='same',weights_initializer=tf.contrib.layers.xavier_initializer()):\n",
    "            \n",
    "            self.conv1 = slim.conv2d(inputs=img, num_outputs=256, scope='conv1')\n",
    "            print(self.conv1)\n",
    "            self.conv2 = slim.conv2d(inputs=self.conv1, num_outputs=256, scope='conv2')\n",
    "        batch_size = tf.shape(img)[0]    \n",
    "        self.caps1 = tf.reshape(self.conv2, [batch_size, self.caps1_num, self.caps1_dim], name='caps1')\n",
    "        self.caps1_squash = squash(self.caps1, name='caps1_squash')\n",
    "            \n",
    "            \n",
    "        self.W_tiled = tf.tile(self.W, [batch_size, 1, 1, 1, 1], name='W_tiled')\n",
    "            \n",
    "        self.caps1_expanded = tf.expand_dims(self.caps1_squash, -1, name='caps1_expanded')\n",
    "        self.caps1_expanded2 = tf.expand_dims(self.caps1_expanded, 2, name='caps1_expanded2')\n",
    "        self.caps1_tiled = tf.tile(self.caps1_expanded2, [1, 1, self.caps2_num, 1, 1], name='caps1_tiled')\n",
    "        self.caps2_in = tf.matmul(self.W_tiled, self.caps1_tiled, name='caps2_in')\n",
    "        self.b_ij = tf.zeros([batch_size, self.caps1_num, self.caps2_num, 1, 1], name='b_ij')\n",
    "        for i in range(self.routing_iter):\n",
    "            if i>0:\n",
    "                self.b_ij = tf.add(self.b_ij, agreement)\n",
    "            self.c_ij = tf.nn.softmax(self.b_ij, dim=2, name='c_ij')\n",
    "            self.s_j = tf.reduce_sum(tf.multiply(self.c_ij, self.caps2_in), axis=1, keep_dims=True, name='s_j')\n",
    "            self.v_j = squash(self.s_j, axis=-2, name='v_j')\n",
    "            if i<self.routing_iter-1:\n",
    "                self.v_j_tiled = tf.tile(self.v_j, [1, self.caps1_num, 1, 1, 1], name='v_j_tiled')\n",
    "                agreement = tf.matmul(self.caps2_in, self.v_j_tiled, transpose_a=True, name='agreement')\n",
    "\n",
    "        self.caps2_out = self.v_j\n",
    "        self.caps2_reshape = tf.reshape(self.caps2_out, [-1, 10*16], name='caps2_reshape')\n",
    "        self.fc1 = slim.fully_connected(inputs=self.caps2_reshape, num_outputs=512, activation_fn=tf.nn.relu, scope='fc1')\n",
    "        self.fc2 = slim.fully_connected(inputs=self.fc1, num_outputs=1024, activation_fn=tf.nn.relu, scope='fc2')\n",
    "        self.fc3 = slim.fully_connected(inputs=self.fc2, num_outputs=784, activation_fn=tf.nn.sigmoid, scope='fc3')\n",
    "        self.out_layer = tf.reshape(self.fc3, [-1, 28, 28, 1])\n",
    "        #self.conv3 = slim.conv2d(inputs=self.caps2_reshape, num_outputs=12, scope='conv3', activation_fn=None)\n",
    "        #self.out_layer = PS(self.conv3, 2, True)\n",
    "\n",
    "        out = self.out_layer\n",
    "        return out\n",
    "    \n",
    "    def loss(self, SR, HR):\n",
    "        loss = tf.reduce_mean(tf.square(SR - HR), name='loss')\n",
    "        return loss\n",
    "    \n",
    "    def build(self):\n",
    "        if self.mode == 'bicubic':\n",
    "            self.LRImg = tf.placeholder(tf.float32, [None, 28, 28, 1], 'LRImgBicubic')\n",
    "        elif self.mode == 'pixelshuffle':\n",
    "            self.LRImg = tf.placeholder(tf.float32, [None, 14, 14, 1], 'LRImgPixelShuffle')\n",
    "        else:\n",
    "            print ('undefined mode')\n",
    "        self.HRImg = tf.placeholder(tf.float32, [None, 28, 28, 1], 'HRImg')\n",
    "        self.SRImg = self.model(self.LRImg)\n",
    "        self.LOSS = self.loss(self.SRImg, self.HRImg)\n",
    "    \n",
    "   \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is generated\n",
      "Tensor(\"conv1/LeakyRelu/Maximum:0\", shape=(?, 28, 28, 256), dtype=float32)\n",
      "WARNING:tensorflow:From <ipython-input-4-635a7b4a7c45>:43: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From <ipython-input-6-f2277d6a0cf8>:43: calling softmax (from tensorflow.python.ops.nn_ops) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n",
      "---------\n",
      "Variables: name (type shape) [size]\n",
      "---------\n",
      "w:0 (float32_ref 1x25088x10x16x8) [32112640, bytes: 128450560]\n",
      "conv1/weights:0 (float32_ref 5x5x1x256) [6400, bytes: 25600]\n",
      "conv1/biases:0 (float32_ref 256) [256, bytes: 1024]\n",
      "conv2/weights:0 (float32_ref 5x5x256x256) [1638400, bytes: 6553600]\n",
      "conv2/biases:0 (float32_ref 256) [256, bytes: 1024]\n",
      "fc1/weights:0 (float32_ref 160x512) [81920, bytes: 327680]\n",
      "fc1/biases:0 (float32_ref 512) [512, bytes: 2048]\n",
      "fc2/weights:0 (float32_ref 512x1024) [524288, bytes: 2097152]\n",
      "fc2/biases:0 (float32_ref 1024) [1024, bytes: 4096]\n",
      "fc3/weights:0 (float32_ref 1024x784) [802816, bytes: 3211264]\n",
      "fc3/biases:0 (float32_ref 784) [784, bytes: 3136]\n",
      "Total size of variables: 35169296\n",
      "Total bytes of variables: 140677184\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(35169296, 140677184)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "model = SRCapsNet('bicubic')\n",
    "model.build()\n",
    "\n",
    "t_vars = tf.trainable_variables()\n",
    "slim.model_analyzer.analyze_vars(t_vars, print_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optm = tf.train.AdamOptimizer(learning_rate=1e-3).minimize(model.LOSS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialization complete\n"
     ]
    }
   ],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config) \n",
    "sess.run(tf.global_variables_initializer())\n",
    "print('initialization complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/scipy/misc/pilutil.py:482: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if issubdtype(ts, int):\n",
      "/usr/local/lib/python3.5/dist-packages/scipy/misc/pilutil.py:485: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  elif issubdtype(type(size), float):\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[16,25088,10,16,1] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: caps2_in = BatchMatMul[T=DT_FLOAT, adj_x=false, adj_y=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](W_tiled, caps1_tiled)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: loss/_57 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_966_loss\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'caps2_in', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 832, in start\n    self._run_callback(self._callbacks.popleft())\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 605, in _run_callback\n    ret = callback()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 536, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-7-5a62f8806d63>\", line 3, in <module>\n    model.build()\n  File \"<ipython-input-6-f2277d6a0cf8>\", line 74, in build\n    self.SRImg = self.model(self.LRImg)\n  File \"<ipython-input-6-f2277d6a0cf8>\", line 38, in model\n    self.caps2_in = tf.matmul(self.W_tiled, self.caps1_tiled, name='caps2_in')\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py\", line 2071, in matmul\n    a, b, adj_x=adjoint_a, adj_y=adjoint_b, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 1236, in batch_mat_mul\n    \"BatchMatMul\", x=x, y=y, adj_x=adj_x, adj_y=adj_y, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 3290, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1654, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[16,25088,10,16,1] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: caps2_in = BatchMatMul[T=DT_FLOAT, adj_x=false, adj_y=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](W_tiled, caps1_tiled)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: loss/_57 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_966_loss\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    517\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[16,25088,10,16,1] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: caps2_in = BatchMatMul[T=DT_FLOAT, adj_x=false, adj_y=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](W_tiled, caps1_tiled)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: loss/_57 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_966_loss\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-6dd7df844a3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mLRImg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBicubic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrImg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mHRImg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrImg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moptm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLOSS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLRImg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mLRImg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHRImg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mHRImg\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mpsnr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         print (\"\\r batch: {}/{} ({:.1f}%) psnr: {:.5f}\".format(\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[16,25088,10,16,1] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: caps2_in = BatchMatMul[T=DT_FLOAT, adj_x=false, adj_y=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](W_tiled, caps1_tiled)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: loss/_57 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_966_loss\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'caps2_in', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 832, in start\n    self._run_callback(self._callbacks.popleft())\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 605, in _run_callback\n    ret = callback()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 536, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-7-5a62f8806d63>\", line 3, in <module>\n    model.build()\n  File \"<ipython-input-6-f2277d6a0cf8>\", line 74, in build\n    self.SRImg = self.model(self.LRImg)\n  File \"<ipython-input-6-f2277d6a0cf8>\", line 38, in model\n    self.caps2_in = tf.matmul(self.W_tiled, self.caps1_tiled, name='caps2_in')\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py\", line 2071, in matmul\n    a, b, adj_x=adjoint_a, adj_y=adjoint_b, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 1236, in batch_mat_mul\n    \"BatchMatMul\", x=x, y=y, adj_x=adj_x, adj_y=adj_y, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 3290, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1654, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[16,25088,10,16,1] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: caps2_in = BatchMatMul[T=DT_FLOAT, adj_x=false, adj_y=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](W_tiled, caps1_tiled)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: loss/_57 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_966_loss\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "batch_size=model.batch_size\n",
    "print('batch_size: {}'.format(batch_size))\n",
    "total_iter = mnist.train.num_examples // batch_size\n",
    "for epoch in range(100):\n",
    "    avg_psnr = 0\n",
    "    start_time=time.time()\n",
    "    for batch in range(total_iter):\n",
    "        trImg, _= mnist.train.next_batch(batch_size)\n",
    "        trImg = np.reshape(trImg, [-1, 28, 28, 1])\n",
    "        LRImg = Bicubic(toLR(trImg))\n",
    "        HRImg = trImg\n",
    "        _, loss = sess.run([optm, model.LOSS], feed_dict={model.LRImg:LRImg, model.HRImg: HRImg})\n",
    "        psnr = 20*np.log10(1./np.sqrt(loss))\n",
    "        print (\"\\r batch: {}/{} ({:.1f}%) psnr: {:.5f}\".format(\n",
    "            batch, total_iter, batch*100/total_iter, psnr) ,end=\"\")\n",
    "        avg_psnr+=psnr\n",
    "    print ('\\repoch: %3d, avg_PSNR: %4f, tiem: %.2f' %(epoch, avg_psnr/total_iter, time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'checkpoints/SRCapsNet/FCN_MNIST_psnr_23-15'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "saver.save(sess, 'checkpoints/SRCapsNet/FCN_MNIST_psnr_23-15')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/scipy/misc/pilutil.py:482: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if issubdtype(ts, int):\n",
      "/usr/local/lib/python3.5/dist-packages/scipy/misc/pilutil.py:485: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  elif issubdtype(type(size), float):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb07fb60fd0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb07fc47278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "showimg = mnist.test.images[0:32,:]\n",
    "hrimg = np.reshape(showimg, [-1, 28, 28, 1])\n",
    "lrimg = toLR(hrimg)\n",
    "lrimgbi=Bicubic(lrimg)\n",
    "srimg=sess.run(model.out_layer, feed_dict={model.LRImg:lrimgbi})\n",
    "index=3\n",
    "\n",
    "plt.figure(figsize=[20,5])\n",
    "plt.subplot(1,3,1)\n",
    "plt.axis('off')\n",
    "plt.title('LR')\n",
    "plt.imshow(lrimg[index,:,:,0], cmap='gray')\n",
    "plt.subplot(1,3,2)\n",
    "plt.axis('off')\n",
    "plt.title('HR')\n",
    "plt.imshow(hrimg[index,:,:,0], cmap='gray')\n",
    "plt.subplot(1,3,3)\n",
    "plt.axis('off')\n",
    "plt.title('SR')\n",
    "plt.imshow(srimg[index,:,:,0], cmap='gray')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
